{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up my own pipeline 786"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------\n",
      "Setting device to:  0\n",
      "Test:  cuda:0\n",
      "-----------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/feolalab/anaconda3/envs/NNEUCLID/lib/python3.9/site-packages/torch/__init__.py:747: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1712608883701/work/torch/csrc/tensor/python_tensor.cpp:431.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from core import *\n",
    "#config\n",
    "from config import *\n",
    "#CUDA\n",
    "cuda=0\n",
    "device=initCUDA(cuda)\n",
    "#supporting files\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1  1.00198  0.000370964  -0.0102491  0.000370964.1  1.00198.1  \\\n",
      "0  2  1.00138     0.000164   -0.006888      -0.000303    1.00194   \n",
      "1  3  1.00104     0.000081   -0.004466      -0.000219    1.00207   \n",
      "2  4  1.00089     0.000045   -0.002534      -0.000129    1.00212   \n",
      "3  5  1.00082     0.000015   -0.000823      -0.000042    1.00214   \n",
      "4  6  1.00082    -0.000015    0.000823       0.000042    1.00214   \n",
      "\n",
      "   -0.0102491.1  0.000866093  0.000866093.1  0.994611  \n",
      "0     -0.010181     0.000096       0.000846  0.995574  \n",
      "1     -0.010703     0.000090       0.000831  0.995760  \n",
      "2     -0.011051     0.000034       0.000829  0.995884  \n",
      "3     -0.011222     0.000012       0.000830  0.995929  \n",
      "4     -0.011222    -0.000012       0.000830  0.995929  \n"
     ]
    }
   ],
   "source": [
    "# Read just the first row as a DataFrame\n",
    "df_first = pd.read_csv(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube/jobs/outputs/F_last\")\n",
    "\n",
    "# If your file has a header row you want to treat as data, keep header=None.\n",
    "# If it already has column names in row 1 and you want those as column names:\n",
    "# df_first = pd.read_csv(\"file.txt\", nrows=1)\n",
    "\n",
    "print(df_first.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1330, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read position\n",
    "displacement_last = pd.read_csv(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube/jobs/outputs/displacement_last\")\n",
    "\n",
    "# Drop the first column, then convert to an (N×9) Python list:\n",
    "displacement =torch.tensor( displacement_last.iloc[:, 1:].to_numpy())   # shape = (N, 9)\n",
    "\n",
    "displacement.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([999, 9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Read position\n",
    "F_last = pd.read_csv(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube/jobs/outputs/F_last\")\n",
    "\n",
    "# Drop the first column, then convert to an (N×9) Python list:\n",
    "F_last = torch.tensor(F_last.iloc[:, 1:].to_numpy())   # shape = (N, 9))\n",
    "\n",
    "# Now `list_9` is a list of N rows, each row itself a list of length 9.\n",
    "F_last.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Read connectivity\n",
    "connectivity = pd.read_csv(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube/jobs/outputs/connectivity\")\n",
    "\n",
    "# Drop the first column, then convert to an (N×9) Python list:\n",
    "connectivity = connectivity.iloc[:, 1:] # shape = (N, 9))\n",
    "\n",
    "# Now `list_9` is a list of N rows, each row itself a list of length 9.\n",
    "connectivity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([  9,  10, 514, 513, 117, 118, 604, 603]),\n",
       " tensor([ 10,  11, 515, 514, 118, 119, 605, 604]),\n",
       " tensor([ 11,  12, 516, 515, 119, 120, 606, 605]),\n",
       " tensor([ 12,  13, 517, 516, 120, 121, 607, 606]),\n",
       " tensor([ 13,  14, 518, 517, 121, 122, 608, 607]),\n",
       " tensor([ 14,  15, 519, 518, 122, 123, 609, 608]),\n",
       " tensor([ 15,  16, 520, 519, 123, 124, 610, 609]),\n",
       " tensor([ 16,  17, 521, 520, 124, 125, 611, 610]),\n",
       " tensor([ 17,   2,  45, 521, 125,  18, 198, 611]),\n",
       " tensor([107, 513, 504, 106, 368, 603, 612, 367]),\n",
       " tensor([513, 514, 505, 504, 603, 604, 613, 612]),\n",
       " tensor([514, 515, 506, 505, 604, 605, 614, 613]),\n",
       " tensor([515, 516, 507, 506, 605, 606, 615, 614]),\n",
       " tensor([516, 517, 508, 507, 606, 607, 616, 615]),\n",
       " tensor([517, 518, 509, 508, 607, 608, 617, 616]),\n",
       " tensor([518, 519, 510, 509, 608, 609, 618, 617]),\n",
       " tensor([519, 520, 511, 510, 609, 610, 619, 618]),\n",
       " tensor([520, 521, 512, 511, 610, 611, 620, 619]),\n",
       " tensor([521,  45,  46, 512, 611, 198, 199, 620]),\n",
       " tensor([106, 504, 495, 105, 367, 612, 621, 366]),\n",
       " tensor([504, 505, 496, 495, 612, 613, 622, 621]),\n",
       " tensor([505, 506, 497, 496, 613, 614, 623, 622]),\n",
       " tensor([506, 507, 498, 497, 614, 615, 624, 623]),\n",
       " tensor([507, 508, 499, 498, 615, 616, 625, 624]),\n",
       " tensor([508, 509, 500, 499, 616, 617, 626, 625]),\n",
       " tensor([509, 510, 501, 500, 617, 618, 627, 626]),\n",
       " tensor([510, 511, 502, 501, 618, 619, 628, 627]),\n",
       " tensor([511, 512, 503, 502, 619, 620, 629, 628]),\n",
       " tensor([512,  46,  47, 503, 620, 199, 200, 629]),\n",
       " tensor([105, 495, 486, 104, 366, 621, 630, 365]),\n",
       " tensor([495, 496, 487, 486, 621, 622, 631, 630]),\n",
       " tensor([496, 497, 488, 487, 622, 623, 632, 631]),\n",
       " tensor([497, 498, 489, 488, 623, 624, 633, 632]),\n",
       " tensor([498, 499, 490, 489, 624, 625, 634, 633]),\n",
       " tensor([499, 500, 491, 490, 625, 626, 635, 634]),\n",
       " tensor([500, 501, 492, 491, 626, 627, 636, 635]),\n",
       " tensor([501, 502, 493, 492, 627, 628, 637, 636]),\n",
       " tensor([502, 503, 494, 493, 628, 629, 638, 637]),\n",
       " tensor([503,  47,  48, 494, 629, 200, 201, 638]),\n",
       " tensor([104, 486, 477, 103, 365, 630, 639, 364]),\n",
       " tensor([486, 487, 478, 477, 630, 631, 640, 639]),\n",
       " tensor([487, 488, 479, 478, 631, 632, 641, 640]),\n",
       " tensor([488, 489, 480, 479, 632, 633, 642, 641]),\n",
       " tensor([489, 490, 481, 480, 633, 634, 643, 642]),\n",
       " tensor([490, 491, 482, 481, 634, 635, 644, 643]),\n",
       " tensor([491, 492, 483, 482, 635, 636, 645, 644]),\n",
       " tensor([492, 493, 484, 483, 636, 637, 646, 645]),\n",
       " tensor([493, 494, 485, 484, 637, 638, 647, 646]),\n",
       " tensor([494,  48,  49, 485, 638, 201, 202, 647]),\n",
       " tensor([103, 477, 468, 102, 364, 639, 648, 363]),\n",
       " tensor([477, 478, 469, 468, 639, 640, 649, 648]),\n",
       " tensor([478, 479, 470, 469, 640, 641, 650, 649]),\n",
       " tensor([479, 480, 471, 470, 641, 642, 651, 650]),\n",
       " tensor([480, 481, 472, 471, 642, 643, 652, 651]),\n",
       " tensor([481, 482, 473, 472, 643, 644, 653, 652]),\n",
       " tensor([482, 483, 474, 473, 644, 645, 654, 653]),\n",
       " tensor([483, 484, 475, 474, 645, 646, 655, 654]),\n",
       " tensor([484, 485, 476, 475, 646, 647, 656, 655]),\n",
       " tensor([485,  49,  50, 476, 647, 202, 203, 656]),\n",
       " tensor([102, 468, 459, 101, 363, 648, 657, 362]),\n",
       " tensor([468, 469, 460, 459, 648, 649, 658, 657]),\n",
       " tensor([469, 470, 461, 460, 649, 650, 659, 658]),\n",
       " tensor([470, 471, 462, 461, 650, 651, 660, 659]),\n",
       " tensor([471, 472, 463, 462, 651, 652, 661, 660]),\n",
       " tensor([472, 473, 464, 463, 652, 653, 662, 661]),\n",
       " tensor([473, 474, 465, 464, 653, 654, 663, 662]),\n",
       " tensor([474, 475, 466, 465, 654, 655, 664, 663]),\n",
       " tensor([475, 476, 467, 466, 655, 656, 665, 664]),\n",
       " tensor([476,  50,  51, 467, 656, 203, 204, 665]),\n",
       " tensor([101, 459, 450, 100, 362, 657, 666, 361]),\n",
       " tensor([459, 460, 451, 450, 657, 658, 667, 666]),\n",
       " tensor([460, 461, 452, 451, 658, 659, 668, 667]),\n",
       " tensor([461, 462, 453, 452, 659, 660, 669, 668]),\n",
       " tensor([462, 463, 454, 453, 660, 661, 670, 669]),\n",
       " tensor([463, 464, 455, 454, 661, 662, 671, 670]),\n",
       " tensor([464, 465, 456, 455, 662, 663, 672, 671]),\n",
       " tensor([465, 466, 457, 456, 663, 664, 673, 672]),\n",
       " tensor([466, 467, 458, 457, 664, 665, 674, 673]),\n",
       " tensor([467,  51,  52, 458, 665, 204, 205, 674]),\n",
       " tensor([100, 450, 441,  99, 361, 666, 675, 360]),\n",
       " tensor([450, 451, 442, 441, 666, 667, 676, 675]),\n",
       " tensor([451, 452, 443, 442, 667, 668, 677, 676]),\n",
       " tensor([452, 453, 444, 443, 668, 669, 678, 677]),\n",
       " tensor([453, 454, 445, 444, 669, 670, 679, 678]),\n",
       " tensor([454, 455, 446, 445, 670, 671, 680, 679]),\n",
       " tensor([455, 456, 447, 446, 671, 672, 681, 680]),\n",
       " tensor([456, 457, 448, 447, 672, 673, 682, 681]),\n",
       " tensor([457, 458, 449, 448, 673, 674, 683, 682]),\n",
       " tensor([458,  52,  53, 449, 674, 205, 206, 683]),\n",
       " tensor([ 99, 441,  80,   4, 360, 675, 287,  81]),\n",
       " tensor([441, 442,  79,  80, 675, 676, 286, 287]),\n",
       " tensor([442, 443,  78,  79, 676, 677, 285, 286]),\n",
       " tensor([443, 444,  77,  78, 677, 678, 284, 285]),\n",
       " tensor([444, 445,  76,  77, 678, 679, 283, 284]),\n",
       " tensor([445, 446,  75,  76, 679, 680, 282, 283]),\n",
       " tensor([446, 447,  74,  75, 680, 681, 281, 282]),\n",
       " tensor([447, 448,  73,  74, 681, 682, 280, 281]),\n",
       " tensor([448, 449,  72,  73, 682, 683, 279, 280]),\n",
       " tensor([449,  53,   3,  72, 683, 206,  54, 279]),\n",
       " tensor([ 44, 117, 603, 368,  43, 126, 684, 377]),\n",
       " tensor([117, 118, 604, 603, 126, 127, 685, 684]),\n",
       " tensor([118, 119, 605, 604, 127, 128, 686, 685]),\n",
       " tensor([119, 120, 606, 605, 128, 129, 687, 686]),\n",
       " tensor([120, 121, 607, 606, 129, 130, 688, 687]),\n",
       " tensor([121, 122, 608, 607, 130, 131, 689, 688]),\n",
       " tensor([122, 123, 609, 608, 131, 132, 690, 689]),\n",
       " tensor([123, 124, 610, 609, 132, 133, 691, 690]),\n",
       " tensor([124, 125, 611, 610, 133, 134, 692, 691]),\n",
       " tensor([125,  18, 198, 611, 134,  19, 207, 692]),\n",
       " tensor([368, 603, 612, 367, 377, 684, 693, 376]),\n",
       " tensor([603, 604, 613, 612, 684, 685, 694, 693]),\n",
       " tensor([604, 605, 614, 613, 685, 686, 695, 694]),\n",
       " tensor([605, 606, 615, 614, 686, 687, 696, 695]),\n",
       " tensor([606, 607, 616, 615, 687, 688, 697, 696]),\n",
       " tensor([607, 608, 617, 616, 688, 689, 698, 697]),\n",
       " tensor([608, 609, 618, 617, 689, 690, 699, 698]),\n",
       " tensor([609, 610, 619, 618, 690, 691, 700, 699]),\n",
       " tensor([610, 611, 620, 619, 691, 692, 701, 700]),\n",
       " tensor([611, 198, 199, 620, 692, 207, 208, 701]),\n",
       " tensor([367, 612, 621, 366, 376, 693, 702, 375]),\n",
       " tensor([612, 613, 622, 621, 693, 694, 703, 702]),\n",
       " tensor([613, 614, 623, 622, 694, 695, 704, 703]),\n",
       " tensor([614, 615, 624, 623, 695, 696, 705, 704]),\n",
       " tensor([615, 616, 625, 624, 696, 697, 706, 705]),\n",
       " tensor([616, 617, 626, 625, 697, 698, 707, 706]),\n",
       " tensor([617, 618, 627, 626, 698, 699, 708, 707]),\n",
       " tensor([618, 619, 628, 627, 699, 700, 709, 708]),\n",
       " tensor([619, 620, 629, 628, 700, 701, 710, 709]),\n",
       " tensor([620, 199, 200, 629, 701, 208, 209, 710]),\n",
       " tensor([366, 621, 630, 365, 375, 702, 711, 374]),\n",
       " tensor([621, 622, 631, 630, 702, 703, 712, 711]),\n",
       " tensor([622, 623, 632, 631, 703, 704, 713, 712]),\n",
       " tensor([623, 624, 633, 632, 704, 705, 714, 713]),\n",
       " tensor([624, 625, 634, 633, 705, 706, 715, 714]),\n",
       " tensor([625, 626, 635, 634, 706, 707, 716, 715]),\n",
       " tensor([626, 627, 636, 635, 707, 708, 717, 716]),\n",
       " tensor([627, 628, 637, 636, 708, 709, 718, 717]),\n",
       " tensor([628, 629, 638, 637, 709, 710, 719, 718]),\n",
       " tensor([629, 200, 201, 638, 710, 209, 210, 719]),\n",
       " tensor([365, 630, 639, 364, 374, 711, 720, 373]),\n",
       " tensor([630, 631, 640, 639, 711, 712, 721, 720]),\n",
       " tensor([631, 632, 641, 640, 712, 713, 722, 721]),\n",
       " tensor([632, 633, 642, 641, 713, 714, 723, 722]),\n",
       " tensor([633, 634, 643, 642, 714, 715, 724, 723]),\n",
       " tensor([634, 635, 644, 643, 715, 716, 725, 724]),\n",
       " tensor([635, 636, 645, 644, 716, 717, 726, 725]),\n",
       " tensor([636, 637, 646, 645, 717, 718, 727, 726]),\n",
       " tensor([637, 638, 647, 646, 718, 719, 728, 727]),\n",
       " tensor([638, 201, 202, 647, 719, 210, 211, 728]),\n",
       " tensor([364, 639, 648, 363, 373, 720, 729, 372]),\n",
       " tensor([639, 640, 649, 648, 720, 721, 730, 729]),\n",
       " tensor([640, 641, 650, 649, 721, 722, 731, 730]),\n",
       " tensor([641, 642, 651, 650, 722, 723, 732, 731]),\n",
       " tensor([642, 643, 652, 651, 723, 724, 733, 732]),\n",
       " tensor([643, 644, 653, 652, 724, 725, 734, 733]),\n",
       " tensor([644, 645, 654, 653, 725, 726, 735, 734]),\n",
       " tensor([645, 646, 655, 654, 726, 727, 736, 735]),\n",
       " tensor([646, 647, 656, 655, 727, 728, 737, 736]),\n",
       " tensor([647, 202, 203, 656, 728, 211, 212, 737]),\n",
       " tensor([363, 648, 657, 362, 372, 729, 738, 371]),\n",
       " tensor([648, 649, 658, 657, 729, 730, 739, 738]),\n",
       " tensor([649, 650, 659, 658, 730, 731, 740, 739]),\n",
       " tensor([650, 651, 660, 659, 731, 732, 741, 740]),\n",
       " tensor([651, 652, 661, 660, 732, 733, 742, 741]),\n",
       " tensor([652, 653, 662, 661, 733, 734, 743, 742]),\n",
       " tensor([653, 654, 663, 662, 734, 735, 744, 743]),\n",
       " tensor([654, 655, 664, 663, 735, 736, 745, 744]),\n",
       " tensor([655, 656, 665, 664, 736, 737, 746, 745]),\n",
       " tensor([656, 203, 204, 665, 737, 212, 213, 746]),\n",
       " tensor([362, 657, 666, 361, 371, 738, 747, 370]),\n",
       " tensor([657, 658, 667, 666, 738, 739, 748, 747]),\n",
       " tensor([658, 659, 668, 667, 739, 740, 749, 748]),\n",
       " tensor([659, 660, 669, 668, 740, 741, 750, 749]),\n",
       " tensor([660, 661, 670, 669, 741, 742, 751, 750]),\n",
       " tensor([661, 662, 671, 670, 742, 743, 752, 751]),\n",
       " tensor([662, 663, 672, 671, 743, 744, 753, 752]),\n",
       " tensor([663, 664, 673, 672, 744, 745, 754, 753]),\n",
       " tensor([664, 665, 674, 673, 745, 746, 755, 754]),\n",
       " tensor([665, 204, 205, 674, 746, 213, 214, 755]),\n",
       " tensor([361, 666, 675, 360, 370, 747, 756, 369]),\n",
       " tensor([666, 667, 676, 675, 747, 748, 757, 756]),\n",
       " tensor([667, 668, 677, 676, 748, 749, 758, 757]),\n",
       " tensor([668, 669, 678, 677, 749, 750, 759, 758]),\n",
       " tensor([669, 670, 679, 678, 750, 751, 760, 759]),\n",
       " tensor([670, 671, 680, 679, 751, 752, 761, 760]),\n",
       " tensor([671, 672, 681, 680, 752, 753, 762, 761]),\n",
       " tensor([672, 673, 682, 681, 753, 754, 763, 762]),\n",
       " tensor([673, 674, 683, 682, 754, 755, 764, 763]),\n",
       " tensor([674, 205, 206, 683, 755, 214, 215, 764]),\n",
       " tensor([360, 675, 287,  81, 369, 756, 296,  82]),\n",
       " tensor([675, 676, 286, 287, 756, 757, 295, 296]),\n",
       " tensor([676, 677, 285, 286, 757, 758, 294, 295]),\n",
       " tensor([677, 678, 284, 285, 758, 759, 293, 294]),\n",
       " tensor([678, 679, 283, 284, 759, 760, 292, 293]),\n",
       " tensor([679, 680, 282, 283, 760, 761, 291, 292]),\n",
       " tensor([680, 681, 281, 282, 761, 762, 290, 291]),\n",
       " tensor([681, 682, 280, 281, 762, 763, 289, 290]),\n",
       " tensor([682, 683, 279, 280, 763, 764, 288, 289]),\n",
       " tensor([683, 206,  54, 279, 764, 215,  55, 288]),\n",
       " tensor([ 43, 126, 684, 377,  42, 135, 765, 386]),\n",
       " tensor([126, 127, 685, 684, 135, 136, 766, 765]),\n",
       " tensor([127, 128, 686, 685, 136, 137, 767, 766]),\n",
       " tensor([128, 129, 687, 686, 137, 138, 768, 767]),\n",
       " tensor([129, 130, 688, 687, 138, 139, 769, 768]),\n",
       " tensor([130, 131, 689, 688, 139, 140, 770, 769]),\n",
       " tensor([131, 132, 690, 689, 140, 141, 771, 770]),\n",
       " tensor([132, 133, 691, 690, 141, 142, 772, 771]),\n",
       " tensor([133, 134, 692, 691, 142, 143, 773, 772]),\n",
       " tensor([134,  19, 207, 692, 143,  20, 216, 773]),\n",
       " tensor([377, 684, 693, 376, 386, 765, 774, 385]),\n",
       " tensor([684, 685, 694, 693, 765, 766, 775, 774]),\n",
       " tensor([685, 686, 695, 694, 766, 767, 776, 775]),\n",
       " tensor([686, 687, 696, 695, 767, 768, 777, 776]),\n",
       " tensor([687, 688, 697, 696, 768, 769, 778, 777]),\n",
       " tensor([688, 689, 698, 697, 769, 770, 779, 778]),\n",
       " tensor([689, 690, 699, 698, 770, 771, 780, 779]),\n",
       " tensor([690, 691, 700, 699, 771, 772, 781, 780]),\n",
       " tensor([691, 692, 701, 700, 772, 773, 782, 781]),\n",
       " tensor([692, 207, 208, 701, 773, 216, 217, 782]),\n",
       " tensor([376, 693, 702, 375, 385, 774, 783, 384]),\n",
       " tensor([693, 694, 703, 702, 774, 775, 784, 783]),\n",
       " tensor([694, 695, 704, 703, 775, 776, 785, 784]),\n",
       " tensor([695, 696, 705, 704, 776, 777, 786, 785]),\n",
       " tensor([696, 697, 706, 705, 777, 778, 787, 786]),\n",
       " tensor([697, 698, 707, 706, 778, 779, 788, 787]),\n",
       " tensor([698, 699, 708, 707, 779, 780, 789, 788]),\n",
       " tensor([699, 700, 709, 708, 780, 781, 790, 789]),\n",
       " tensor([700, 701, 710, 709, 781, 782, 791, 790]),\n",
       " tensor([701, 208, 209, 710, 782, 217, 218, 791]),\n",
       " tensor([375, 702, 711, 374, 384, 783, 792, 383]),\n",
       " tensor([702, 703, 712, 711, 783, 784, 793, 792]),\n",
       " tensor([703, 704, 713, 712, 784, 785, 794, 793]),\n",
       " tensor([704, 705, 714, 713, 785, 786, 795, 794]),\n",
       " tensor([705, 706, 715, 714, 786, 787, 796, 795]),\n",
       " tensor([706, 707, 716, 715, 787, 788, 797, 796]),\n",
       " tensor([707, 708, 717, 716, 788, 789, 798, 797]),\n",
       " tensor([708, 709, 718, 717, 789, 790, 799, 798]),\n",
       " tensor([709, 710, 719, 718, 790, 791, 800, 799]),\n",
       " tensor([710, 209, 210, 719, 791, 218, 219, 800]),\n",
       " tensor([374, 711, 720, 373, 383, 792, 801, 382]),\n",
       " tensor([711, 712, 721, 720, 792, 793, 802, 801]),\n",
       " tensor([712, 713, 722, 721, 793, 794, 803, 802]),\n",
       " tensor([713, 714, 723, 722, 794, 795, 804, 803]),\n",
       " tensor([714, 715, 724, 723, 795, 796, 805, 804]),\n",
       " tensor([715, 716, 725, 724, 796, 797, 806, 805]),\n",
       " tensor([716, 717, 726, 725, 797, 798, 807, 806]),\n",
       " tensor([717, 718, 727, 726, 798, 799, 808, 807]),\n",
       " tensor([718, 719, 728, 727, 799, 800, 809, 808]),\n",
       " tensor([719, 210, 211, 728, 800, 219, 220, 809]),\n",
       " tensor([373, 720, 729, 372, 382, 801, 810, 381]),\n",
       " tensor([720, 721, 730, 729, 801, 802, 811, 810]),\n",
       " tensor([721, 722, 731, 730, 802, 803, 812, 811]),\n",
       " tensor([722, 723, 732, 731, 803, 804, 813, 812]),\n",
       " tensor([723, 724, 733, 732, 804, 805, 814, 813]),\n",
       " tensor([724, 725, 734, 733, 805, 806, 815, 814]),\n",
       " tensor([725, 726, 735, 734, 806, 807, 816, 815]),\n",
       " tensor([726, 727, 736, 735, 807, 808, 817, 816]),\n",
       " tensor([727, 728, 737, 736, 808, 809, 818, 817]),\n",
       " tensor([728, 211, 212, 737, 809, 220, 221, 818]),\n",
       " tensor([372, 729, 738, 371, 381, 810, 819, 380]),\n",
       " tensor([729, 730, 739, 738, 810, 811, 820, 819]),\n",
       " tensor([730, 731, 740, 739, 811, 812, 821, 820]),\n",
       " tensor([731, 732, 741, 740, 812, 813, 822, 821]),\n",
       " tensor([732, 733, 742, 741, 813, 814, 823, 822]),\n",
       " tensor([733, 734, 743, 742, 814, 815, 824, 823]),\n",
       " tensor([734, 735, 744, 743, 815, 816, 825, 824]),\n",
       " tensor([735, 736, 745, 744, 816, 817, 826, 825]),\n",
       " tensor([736, 737, 746, 745, 817, 818, 827, 826]),\n",
       " tensor([737, 212, 213, 746, 818, 221, 222, 827]),\n",
       " tensor([371, 738, 747, 370, 380, 819, 828, 379]),\n",
       " tensor([738, 739, 748, 747, 819, 820, 829, 828]),\n",
       " tensor([739, 740, 749, 748, 820, 821, 830, 829]),\n",
       " tensor([740, 741, 750, 749, 821, 822, 831, 830]),\n",
       " tensor([741, 742, 751, 750, 822, 823, 832, 831]),\n",
       " tensor([742, 743, 752, 751, 823, 824, 833, 832]),\n",
       " tensor([743, 744, 753, 752, 824, 825, 834, 833]),\n",
       " tensor([744, 745, 754, 753, 825, 826, 835, 834]),\n",
       " tensor([745, 746, 755, 754, 826, 827, 836, 835]),\n",
       " tensor([746, 213, 214, 755, 827, 222, 223, 836]),\n",
       " tensor([370, 747, 756, 369, 379, 828, 837, 378]),\n",
       " tensor([747, 748, 757, 756, 828, 829, 838, 837]),\n",
       " tensor([748, 749, 758, 757, 829, 830, 839, 838]),\n",
       " tensor([749, 750, 759, 758, 830, 831, 840, 839]),\n",
       " tensor([750, 751, 760, 759, 831, 832, 841, 840]),\n",
       " tensor([751, 752, 761, 760, 832, 833, 842, 841]),\n",
       " tensor([752, 753, 762, 761, 833, 834, 843, 842]),\n",
       " tensor([753, 754, 763, 762, 834, 835, 844, 843]),\n",
       " tensor([754, 755, 764, 763, 835, 836, 845, 844]),\n",
       " tensor([755, 214, 215, 764, 836, 223, 224, 845]),\n",
       " tensor([369, 756, 296,  82, 378, 837, 305,  83]),\n",
       " tensor([756, 757, 295, 296, 837, 838, 304, 305]),\n",
       " tensor([757, 758, 294, 295, 838, 839, 303, 304]),\n",
       " tensor([758, 759, 293, 294, 839, 840, 302, 303]),\n",
       " tensor([759, 760, 292, 293, 840, 841, 301, 302]),\n",
       " tensor([760, 761, 291, 292, 841, 842, 300, 301]),\n",
       " tensor([761, 762, 290, 291, 842, 843, 299, 300]),\n",
       " tensor([762, 763, 289, 290, 843, 844, 298, 299]),\n",
       " tensor([763, 764, 288, 289, 844, 845, 297, 298]),\n",
       " tensor([764, 215,  55, 288, 845, 224,  56, 297]),\n",
       " tensor([ 42, 135, 765, 386,  41, 144, 846, 395]),\n",
       " tensor([135, 136, 766, 765, 144, 145, 847, 846]),\n",
       " tensor([136, 137, 767, 766, 145, 146, 848, 847]),\n",
       " tensor([137, 138, 768, 767, 146, 147, 849, 848]),\n",
       " tensor([138, 139, 769, 768, 147, 148, 850, 849]),\n",
       " tensor([139, 140, 770, 769, 148, 149, 851, 850]),\n",
       " tensor([140, 141, 771, 770, 149, 150, 852, 851]),\n",
       " tensor([141, 142, 772, 771, 150, 151, 853, 852]),\n",
       " tensor([142, 143, 773, 772, 151, 152, 854, 853]),\n",
       " tensor([143,  20, 216, 773, 152,  21, 225, 854]),\n",
       " tensor([386, 765, 774, 385, 395, 846, 855, 394]),\n",
       " tensor([765, 766, 775, 774, 846, 847, 856, 855]),\n",
       " tensor([766, 767, 776, 775, 847, 848, 857, 856]),\n",
       " tensor([767, 768, 777, 776, 848, 849, 858, 857]),\n",
       " tensor([768, 769, 778, 777, 849, 850, 859, 858]),\n",
       " tensor([769, 770, 779, 778, 850, 851, 860, 859]),\n",
       " tensor([770, 771, 780, 779, 851, 852, 861, 860]),\n",
       " tensor([771, 772, 781, 780, 852, 853, 862, 861]),\n",
       " tensor([772, 773, 782, 781, 853, 854, 863, 862]),\n",
       " tensor([773, 216, 217, 782, 854, 225, 226, 863]),\n",
       " tensor([385, 774, 783, 384, 394, 855, 864, 393]),\n",
       " tensor([774, 775, 784, 783, 855, 856, 865, 864]),\n",
       " tensor([775, 776, 785, 784, 856, 857, 866, 865]),\n",
       " tensor([776, 777, 786, 785, 857, 858, 867, 866]),\n",
       " tensor([777, 778, 787, 786, 858, 859, 868, 867]),\n",
       " tensor([778, 779, 788, 787, 859, 860, 869, 868]),\n",
       " tensor([779, 780, 789, 788, 860, 861, 870, 869]),\n",
       " tensor([780, 781, 790, 789, 861, 862, 871, 870]),\n",
       " tensor([781, 782, 791, 790, 862, 863, 872, 871]),\n",
       " tensor([782, 217, 218, 791, 863, 226, 227, 872]),\n",
       " tensor([384, 783, 792, 383, 393, 864, 873, 392]),\n",
       " tensor([783, 784, 793, 792, 864, 865, 874, 873]),\n",
       " tensor([784, 785, 794, 793, 865, 866, 875, 874]),\n",
       " tensor([785, 786, 795, 794, 866, 867, 876, 875]),\n",
       " tensor([786, 787, 796, 795, 867, 868, 877, 876]),\n",
       " tensor([787, 788, 797, 796, 868, 869, 878, 877]),\n",
       " tensor([788, 789, 798, 797, 869, 870, 879, 878]),\n",
       " tensor([789, 790, 799, 798, 870, 871, 880, 879]),\n",
       " tensor([790, 791, 800, 799, 871, 872, 881, 880]),\n",
       " tensor([791, 218, 219, 800, 872, 227, 228, 881]),\n",
       " tensor([383, 792, 801, 382, 392, 873, 882, 391]),\n",
       " tensor([792, 793, 802, 801, 873, 874, 883, 882]),\n",
       " tensor([793, 794, 803, 802, 874, 875, 884, 883]),\n",
       " tensor([794, 795, 804, 803, 875, 876, 885, 884]),\n",
       " tensor([795, 796, 805, 804, 876, 877, 886, 885]),\n",
       " tensor([796, 797, 806, 805, 877, 878, 887, 886]),\n",
       " tensor([797, 798, 807, 806, 878, 879, 888, 887]),\n",
       " tensor([798, 799, 808, 807, 879, 880, 889, 888]),\n",
       " tensor([799, 800, 809, 808, 880, 881, 890, 889]),\n",
       " tensor([800, 219, 220, 809, 881, 228, 229, 890]),\n",
       " tensor([382, 801, 810, 381, 391, 882, 891, 390]),\n",
       " tensor([801, 802, 811, 810, 882, 883, 892, 891]),\n",
       " tensor([802, 803, 812, 811, 883, 884, 893, 892]),\n",
       " tensor([803, 804, 813, 812, 884, 885, 894, 893]),\n",
       " tensor([804, 805, 814, 813, 885, 886, 895, 894]),\n",
       " tensor([805, 806, 815, 814, 886, 887, 896, 895]),\n",
       " tensor([806, 807, 816, 815, 887, 888, 897, 896]),\n",
       " tensor([807, 808, 817, 816, 888, 889, 898, 897]),\n",
       " tensor([808, 809, 818, 817, 889, 890, 899, 898]),\n",
       " tensor([809, 220, 221, 818, 890, 229, 230, 899]),\n",
       " tensor([381, 810, 819, 380, 390, 891, 900, 389]),\n",
       " tensor([810, 811, 820, 819, 891, 892, 901, 900]),\n",
       " tensor([811, 812, 821, 820, 892, 893, 902, 901]),\n",
       " tensor([812, 813, 822, 821, 893, 894, 903, 902]),\n",
       " tensor([813, 814, 823, 822, 894, 895, 904, 903]),\n",
       " tensor([814, 815, 824, 823, 895, 896, 905, 904]),\n",
       " tensor([815, 816, 825, 824, 896, 897, 906, 905]),\n",
       " tensor([816, 817, 826, 825, 897, 898, 907, 906]),\n",
       " tensor([817, 818, 827, 826, 898, 899, 908, 907]),\n",
       " tensor([818, 221, 222, 827, 899, 230, 231, 908]),\n",
       " tensor([380, 819, 828, 379, 389, 900, 909, 388]),\n",
       " tensor([819, 820, 829, 828, 900, 901, 910, 909]),\n",
       " tensor([820, 821, 830, 829, 901, 902, 911, 910]),\n",
       " tensor([821, 822, 831, 830, 902, 903, 912, 911]),\n",
       " tensor([822, 823, 832, 831, 903, 904, 913, 912]),\n",
       " tensor([823, 824, 833, 832, 904, 905, 914, 913]),\n",
       " tensor([824, 825, 834, 833, 905, 906, 915, 914]),\n",
       " tensor([825, 826, 835, 834, 906, 907, 916, 915]),\n",
       " tensor([826, 827, 836, 835, 907, 908, 917, 916]),\n",
       " tensor([827, 222, 223, 836, 908, 231, 232, 917]),\n",
       " tensor([379, 828, 837, 378, 388, 909, 918, 387]),\n",
       " tensor([828, 829, 838, 837, 909, 910, 919, 918]),\n",
       " tensor([829, 830, 839, 838, 910, 911, 920, 919]),\n",
       " tensor([830, 831, 840, 839, 911, 912, 921, 920]),\n",
       " tensor([831, 832, 841, 840, 912, 913, 922, 921]),\n",
       " tensor([832, 833, 842, 841, 913, 914, 923, 922]),\n",
       " tensor([833, 834, 843, 842, 914, 915, 924, 923]),\n",
       " tensor([834, 835, 844, 843, 915, 916, 925, 924]),\n",
       " tensor([835, 836, 845, 844, 916, 917, 926, 925]),\n",
       " tensor([836, 223, 224, 845, 917, 232, 233, 926]),\n",
       " tensor([378, 837, 305,  83, 387, 918, 314,  84]),\n",
       " tensor([837, 838, 304, 305, 918, 919, 313, 314]),\n",
       " tensor([838, 839, 303, 304, 919, 920, 312, 313]),\n",
       " tensor([839, 840, 302, 303, 920, 921, 311, 312]),\n",
       " tensor([840, 841, 301, 302, 921, 922, 310, 311]),\n",
       " tensor([841, 842, 300, 301, 922, 923, 309, 310]),\n",
       " tensor([842, 843, 299, 300, 923, 924, 308, 309]),\n",
       " tensor([843, 844, 298, 299, 924, 925, 307, 308]),\n",
       " tensor([844, 845, 297, 298, 925, 926, 306, 307]),\n",
       " tensor([845, 224,  56, 297, 926, 233,  57, 306]),\n",
       " tensor([ 41, 144, 846, 395,  40, 153, 927, 404]),\n",
       " tensor([144, 145, 847, 846, 153, 154, 928, 927]),\n",
       " tensor([145, 146, 848, 847, 154, 155, 929, 928]),\n",
       " tensor([146, 147, 849, 848, 155, 156, 930, 929]),\n",
       " tensor([147, 148, 850, 849, 156, 157, 931, 930]),\n",
       " tensor([148, 149, 851, 850, 157, 158, 932, 931]),\n",
       " tensor([149, 150, 852, 851, 158, 159, 933, 932]),\n",
       " tensor([150, 151, 853, 852, 159, 160, 934, 933]),\n",
       " tensor([151, 152, 854, 853, 160, 161, 935, 934]),\n",
       " tensor([152,  21, 225, 854, 161,  22, 234, 935]),\n",
       " tensor([395, 846, 855, 394, 404, 927, 936, 403]),\n",
       " tensor([846, 847, 856, 855, 927, 928, 937, 936]),\n",
       " tensor([847, 848, 857, 856, 928, 929, 938, 937]),\n",
       " tensor([848, 849, 858, 857, 929, 930, 939, 938]),\n",
       " tensor([849, 850, 859, 858, 930, 931, 940, 939]),\n",
       " tensor([850, 851, 860, 859, 931, 932, 941, 940]),\n",
       " tensor([851, 852, 861, 860, 932, 933, 942, 941]),\n",
       " tensor([852, 853, 862, 861, 933, 934, 943, 942]),\n",
       " tensor([853, 854, 863, 862, 934, 935, 944, 943]),\n",
       " tensor([854, 225, 226, 863, 935, 234, 235, 944]),\n",
       " tensor([394, 855, 864, 393, 403, 936, 945, 402]),\n",
       " tensor([855, 856, 865, 864, 936, 937, 946, 945]),\n",
       " tensor([856, 857, 866, 865, 937, 938, 947, 946]),\n",
       " tensor([857, 858, 867, 866, 938, 939, 948, 947]),\n",
       " tensor([858, 859, 868, 867, 939, 940, 949, 948]),\n",
       " tensor([859, 860, 869, 868, 940, 941, 950, 949]),\n",
       " tensor([860, 861, 870, 869, 941, 942, 951, 950]),\n",
       " tensor([861, 862, 871, 870, 942, 943, 952, 951]),\n",
       " tensor([862, 863, 872, 871, 943, 944, 953, 952]),\n",
       " tensor([863, 226, 227, 872, 944, 235, 236, 953]),\n",
       " tensor([393, 864, 873, 392, 402, 945, 954, 401]),\n",
       " tensor([864, 865, 874, 873, 945, 946, 955, 954]),\n",
       " tensor([865, 866, 875, 874, 946, 947, 956, 955]),\n",
       " tensor([866, 867, 876, 875, 947, 948, 957, 956]),\n",
       " tensor([867, 868, 877, 876, 948, 949, 958, 957]),\n",
       " tensor([868, 869, 878, 877, 949, 950, 959, 958]),\n",
       " tensor([869, 870, 879, 878, 950, 951, 960, 959]),\n",
       " tensor([870, 871, 880, 879, 951, 952, 961, 960]),\n",
       " tensor([871, 872, 881, 880, 952, 953, 962, 961]),\n",
       " tensor([872, 227, 228, 881, 953, 236, 237, 962]),\n",
       " tensor([392, 873, 882, 391, 401, 954, 963, 400]),\n",
       " tensor([873, 874, 883, 882, 954, 955, 964, 963]),\n",
       " tensor([874, 875, 884, 883, 955, 956, 965, 964]),\n",
       " tensor([875, 876, 885, 884, 956, 957, 966, 965]),\n",
       " tensor([876, 877, 886, 885, 957, 958, 967, 966]),\n",
       " tensor([877, 878, 887, 886, 958, 959, 968, 967]),\n",
       " tensor([878, 879, 888, 887, 959, 960, 969, 968]),\n",
       " tensor([879, 880, 889, 888, 960, 961, 970, 969]),\n",
       " tensor([880, 881, 890, 889, 961, 962, 971, 970]),\n",
       " tensor([881, 228, 229, 890, 962, 237, 238, 971]),\n",
       " tensor([391, 882, 891, 390, 400, 963, 972, 399]),\n",
       " tensor([882, 883, 892, 891, 963, 964, 973, 972]),\n",
       " tensor([883, 884, 893, 892, 964, 965, 974, 973]),\n",
       " tensor([884, 885, 894, 893, 965, 966, 975, 974]),\n",
       " tensor([885, 886, 895, 894, 966, 967, 976, 975]),\n",
       " tensor([886, 887, 896, 895, 967, 968, 977, 976]),\n",
       " tensor([887, 888, 897, 896, 968, 969, 978, 977]),\n",
       " tensor([888, 889, 898, 897, 969, 970, 979, 978]),\n",
       " tensor([889, 890, 899, 898, 970, 971, 980, 979]),\n",
       " tensor([890, 229, 230, 899, 971, 238, 239, 980]),\n",
       " tensor([390, 891, 900, 389, 399, 972, 981, 398]),\n",
       " tensor([891, 892, 901, 900, 972, 973, 982, 981]),\n",
       " tensor([892, 893, 902, 901, 973, 974, 983, 982]),\n",
       " tensor([893, 894, 903, 902, 974, 975, 984, 983]),\n",
       " tensor([894, 895, 904, 903, 975, 976, 985, 984]),\n",
       " tensor([895, 896, 905, 904, 976, 977, 986, 985]),\n",
       " tensor([896, 897, 906, 905, 977, 978, 987, 986]),\n",
       " tensor([897, 898, 907, 906, 978, 979, 988, 987]),\n",
       " tensor([898, 899, 908, 907, 979, 980, 989, 988]),\n",
       " tensor([899, 230, 231, 908, 980, 239, 240, 989]),\n",
       " tensor([389, 900, 909, 388, 398, 981, 990, 397]),\n",
       " tensor([900, 901, 910, 909, 981, 982, 991, 990]),\n",
       " tensor([901, 902, 911, 910, 982, 983, 992, 991]),\n",
       " tensor([902, 903, 912, 911, 983, 984, 993, 992]),\n",
       " tensor([903, 904, 913, 912, 984, 985, 994, 993]),\n",
       " tensor([904, 905, 914, 913, 985, 986, 995, 994]),\n",
       " tensor([905, 906, 915, 914, 986, 987, 996, 995]),\n",
       " tensor([906, 907, 916, 915, 987, 988, 997, 996]),\n",
       " tensor([907, 908, 917, 916, 988, 989, 998, 997]),\n",
       " tensor([908, 231, 232, 917, 989, 240, 241, 998]),\n",
       " tensor([388, 909, 918, 387, 397, 990, 999, 396]),\n",
       " tensor([ 909,  910,  919,  918,  990,  991, 1000,  999]),\n",
       " tensor([ 910,  911,  920,  919,  991,  992, 1001, 1000]),\n",
       " tensor([ 911,  912,  921,  920,  992,  993, 1002, 1001]),\n",
       " tensor([ 912,  913,  922,  921,  993,  994, 1003, 1002]),\n",
       " tensor([ 913,  914,  923,  922,  994,  995, 1004, 1003]),\n",
       " tensor([ 914,  915,  924,  923,  995,  996, 1005, 1004]),\n",
       " tensor([ 915,  916,  925,  924,  996,  997, 1006, 1005]),\n",
       " tensor([ 916,  917,  926,  925,  997,  998, 1007, 1006]),\n",
       " tensor([ 917,  232,  233,  926,  998,  241,  242, 1007]),\n",
       " tensor([387, 918, 314,  84, 396, 999, 323,  85]),\n",
       " tensor([ 918,  919,  313,  314,  999, 1000,  322,  323]),\n",
       " tensor([ 919,  920,  312,  313, 1000, 1001,  321,  322]),\n",
       " tensor([ 920,  921,  311,  312, 1001, 1002,  320,  321]),\n",
       " tensor([ 921,  922,  310,  311, 1002, 1003,  319,  320]),\n",
       " tensor([ 922,  923,  309,  310, 1003, 1004,  318,  319]),\n",
       " tensor([ 923,  924,  308,  309, 1004, 1005,  317,  318]),\n",
       " tensor([ 924,  925,  307,  308, 1005, 1006,  316,  317]),\n",
       " tensor([ 925,  926,  306,  307, 1006, 1007,  315,  316]),\n",
       " tensor([ 926,  233,   57,  306, 1007,  242,   58,  315]),\n",
       " tensor([  40,  153,  927,  404,   39,  162, 1008,  413]),\n",
       " tensor([ 153,  154,  928,  927,  162,  163, 1009, 1008]),\n",
       " tensor([ 154,  155,  929,  928,  163,  164, 1010, 1009]),\n",
       " tensor([ 155,  156,  930,  929,  164,  165, 1011, 1010]),\n",
       " tensor([ 156,  157,  931,  930,  165,  166, 1012, 1011]),\n",
       " tensor([ 157,  158,  932,  931,  166,  167, 1013, 1012]),\n",
       " tensor([ 158,  159,  933,  932,  167,  168, 1014, 1013]),\n",
       " tensor([ 159,  160,  934,  933,  168,  169, 1015, 1014]),\n",
       " tensor([ 160,  161,  935,  934,  169,  170, 1016, 1015]),\n",
       " tensor([ 161,   22,  234,  935,  170,   23,  243, 1016]),\n",
       " tensor([ 404,  927,  936,  403,  413, 1008, 1017,  412]),\n",
       " tensor([ 927,  928,  937,  936, 1008, 1009, 1018, 1017]),\n",
       " tensor([ 928,  929,  938,  937, 1009, 1010, 1019, 1018]),\n",
       " tensor([ 929,  930,  939,  938, 1010, 1011, 1020, 1019]),\n",
       " tensor([ 930,  931,  940,  939, 1011, 1012, 1021, 1020]),\n",
       " tensor([ 931,  932,  941,  940, 1012, 1013, 1022, 1021]),\n",
       " tensor([ 932,  933,  942,  941, 1013, 1014, 1023, 1022]),\n",
       " tensor([ 933,  934,  943,  942, 1014, 1015, 1024, 1023]),\n",
       " tensor([ 934,  935,  944,  943, 1015, 1016, 1025, 1024]),\n",
       " tensor([ 935,  234,  235,  944, 1016,  243,  244, 1025]),\n",
       " tensor([ 403,  936,  945,  402,  412, 1017, 1026,  411]),\n",
       " tensor([ 936,  937,  946,  945, 1017, 1018, 1027, 1026]),\n",
       " tensor([ 937,  938,  947,  946, 1018, 1019, 1028, 1027]),\n",
       " tensor([ 938,  939,  948,  947, 1019, 1020, 1029, 1028]),\n",
       " tensor([ 939,  940,  949,  948, 1020, 1021, 1030, 1029]),\n",
       " tensor([ 940,  941,  950,  949, 1021, 1022, 1031, 1030]),\n",
       " tensor([ 941,  942,  951,  950, 1022, 1023, 1032, 1031]),\n",
       " tensor([ 942,  943,  952,  951, 1023, 1024, 1033, 1032]),\n",
       " tensor([ 943,  944,  953,  952, 1024, 1025, 1034, 1033]),\n",
       " tensor([ 944,  235,  236,  953, 1025,  244,  245, 1034]),\n",
       " tensor([ 402,  945,  954,  401,  411, 1026, 1035,  410]),\n",
       " tensor([ 945,  946,  955,  954, 1026, 1027, 1036, 1035]),\n",
       " tensor([ 946,  947,  956,  955, 1027, 1028, 1037, 1036]),\n",
       " tensor([ 947,  948,  957,  956, 1028, 1029, 1038, 1037]),\n",
       " tensor([ 948,  949,  958,  957, 1029, 1030, 1039, 1038]),\n",
       " tensor([ 949,  950,  959,  958, 1030, 1031, 1040, 1039]),\n",
       " tensor([ 950,  951,  960,  959, 1031, 1032, 1041, 1040]),\n",
       " tensor([ 951,  952,  961,  960, 1032, 1033, 1042, 1041]),\n",
       " tensor([ 952,  953,  962,  961, 1033, 1034, 1043, 1042]),\n",
       " tensor([ 953,  236,  237,  962, 1034,  245,  246, 1043]),\n",
       " tensor([ 401,  954,  963,  400,  410, 1035, 1044,  409]),\n",
       " tensor([ 954,  955,  964,  963, 1035, 1036, 1045, 1044]),\n",
       " tensor([ 955,  956,  965,  964, 1036, 1037, 1046, 1045]),\n",
       " tensor([ 956,  957,  966,  965, 1037, 1038, 1047, 1046]),\n",
       " tensor([ 957,  958,  967,  966, 1038, 1039, 1048, 1047]),\n",
       " tensor([ 958,  959,  968,  967, 1039, 1040, 1049, 1048]),\n",
       " tensor([ 959,  960,  969,  968, 1040, 1041, 1050, 1049]),\n",
       " tensor([ 960,  961,  970,  969, 1041, 1042, 1051, 1050]),\n",
       " tensor([ 961,  962,  971,  970, 1042, 1043, 1052, 1051]),\n",
       " tensor([ 962,  237,  238,  971, 1043,  246,  247, 1052]),\n",
       " tensor([ 400,  963,  972,  399,  409, 1044, 1053,  408]),\n",
       " tensor([ 963,  964,  973,  972, 1044, 1045, 1054, 1053]),\n",
       " tensor([ 964,  965,  974,  973, 1045, 1046, 1055, 1054]),\n",
       " tensor([ 965,  966,  975,  974, 1046, 1047, 1056, 1055]),\n",
       " tensor([ 966,  967,  976,  975, 1047, 1048, 1057, 1056]),\n",
       " tensor([ 967,  968,  977,  976, 1048, 1049, 1058, 1057]),\n",
       " tensor([ 968,  969,  978,  977, 1049, 1050, 1059, 1058]),\n",
       " tensor([ 969,  970,  979,  978, 1050, 1051, 1060, 1059]),\n",
       " tensor([ 970,  971,  980,  979, 1051, 1052, 1061, 1060]),\n",
       " tensor([ 971,  238,  239,  980, 1052,  247,  248, 1061]),\n",
       " tensor([ 399,  972,  981,  398,  408, 1053, 1062,  407]),\n",
       " tensor([ 972,  973,  982,  981, 1053, 1054, 1063, 1062]),\n",
       " tensor([ 973,  974,  983,  982, 1054, 1055, 1064, 1063]),\n",
       " tensor([ 974,  975,  984,  983, 1055, 1056, 1065, 1064]),\n",
       " tensor([ 975,  976,  985,  984, 1056, 1057, 1066, 1065]),\n",
       " tensor([ 976,  977,  986,  985, 1057, 1058, 1067, 1066]),\n",
       " tensor([ 977,  978,  987,  986, 1058, 1059, 1068, 1067]),\n",
       " tensor([ 978,  979,  988,  987, 1059, 1060, 1069, 1068]),\n",
       " tensor([ 979,  980,  989,  988, 1060, 1061, 1070, 1069]),\n",
       " tensor([ 980,  239,  240,  989, 1061,  248,  249, 1070]),\n",
       " tensor([ 398,  981,  990,  397,  407, 1062, 1071,  406]),\n",
       " tensor([ 981,  982,  991,  990, 1062, 1063, 1072, 1071]),\n",
       " tensor([ 982,  983,  992,  991, 1063, 1064, 1073, 1072]),\n",
       " tensor([ 983,  984,  993,  992, 1064, 1065, 1074, 1073]),\n",
       " tensor([ 984,  985,  994,  993, 1065, 1066, 1075, 1074]),\n",
       " tensor([ 985,  986,  995,  994, 1066, 1067, 1076, 1075]),\n",
       " tensor([ 986,  987,  996,  995, 1067, 1068, 1077, 1076]),\n",
       " tensor([ 987,  988,  997,  996, 1068, 1069, 1078, 1077]),\n",
       " tensor([ 988,  989,  998,  997, 1069, 1070, 1079, 1078]),\n",
       " tensor([ 989,  240,  241,  998, 1070,  249,  250, 1079]),\n",
       " tensor([ 397,  990,  999,  396,  406, 1071, 1080,  405]),\n",
       " tensor([ 990,  991, 1000,  999, 1071, 1072, 1081, 1080]),\n",
       " tensor([ 991,  992, 1001, 1000, 1072, 1073, 1082, 1081]),\n",
       " tensor([ 992,  993, 1002, 1001, 1073, 1074, 1083, 1082]),\n",
       " tensor([ 993,  994, 1003, 1002, 1074, 1075, 1084, 1083]),\n",
       " tensor([ 994,  995, 1004, 1003, 1075, 1076, 1085, 1084]),\n",
       " tensor([ 995,  996, 1005, 1004, 1076, 1077, 1086, 1085]),\n",
       " tensor([ 996,  997, 1006, 1005, 1077, 1078, 1087, 1086]),\n",
       " tensor([ 997,  998, 1007, 1006, 1078, 1079, 1088, 1087]),\n",
       " tensor([ 998,  241,  242, 1007, 1079,  250,  251, 1088]),\n",
       " tensor([ 396,  999,  323,   85,  405, 1080,  332,   86]),\n",
       " tensor([ 999, 1000,  322,  323, 1080, 1081,  331,  332]),\n",
       " tensor([1000, 1001,  321,  322, 1081, 1082,  330,  331]),\n",
       " tensor([1001, 1002,  320,  321, 1082, 1083,  329,  330]),\n",
       " tensor([1002, 1003,  319,  320, 1083, 1084,  328,  329]),\n",
       " tensor([1003, 1004,  318,  319, 1084, 1085,  327,  328]),\n",
       " tensor([1004, 1005,  317,  318, 1085, 1086,  326,  327]),\n",
       " tensor([1005, 1006,  316,  317, 1086, 1087,  325,  326]),\n",
       " tensor([1006, 1007,  315,  316, 1087, 1088,  324,  325]),\n",
       " tensor([1007,  242,   58,  315, 1088,  251,   59,  324]),\n",
       " tensor([  39,  162, 1008,  413,   38,  171, 1089,  422]),\n",
       " tensor([ 162,  163, 1009, 1008,  171,  172, 1090, 1089]),\n",
       " tensor([ 163,  164, 1010, 1009,  172,  173, 1091, 1090]),\n",
       " tensor([ 164,  165, 1011, 1010,  173,  174, 1092, 1091]),\n",
       " tensor([ 165,  166, 1012, 1011,  174,  175, 1093, 1092]),\n",
       " tensor([ 166,  167, 1013, 1012,  175,  176, 1094, 1093]),\n",
       " tensor([ 167,  168, 1014, 1013,  176,  177, 1095, 1094]),\n",
       " tensor([ 168,  169, 1015, 1014,  177,  178, 1096, 1095]),\n",
       " tensor([ 169,  170, 1016, 1015,  178,  179, 1097, 1096]),\n",
       " tensor([ 170,   23,  243, 1016,  179,   24,  252, 1097]),\n",
       " tensor([ 413, 1008, 1017,  412,  422, 1089, 1098,  421]),\n",
       " tensor([1008, 1009, 1018, 1017, 1089, 1090, 1099, 1098]),\n",
       " tensor([1009, 1010, 1019, 1018, 1090, 1091, 1100, 1099]),\n",
       " tensor([1010, 1011, 1020, 1019, 1091, 1092, 1101, 1100]),\n",
       " tensor([1011, 1012, 1021, 1020, 1092, 1093, 1102, 1101]),\n",
       " tensor([1012, 1013, 1022, 1021, 1093, 1094, 1103, 1102]),\n",
       " tensor([1013, 1014, 1023, 1022, 1094, 1095, 1104, 1103]),\n",
       " tensor([1014, 1015, 1024, 1023, 1095, 1096, 1105, 1104]),\n",
       " tensor([1015, 1016, 1025, 1024, 1096, 1097, 1106, 1105]),\n",
       " tensor([1016,  243,  244, 1025, 1097,  252,  253, 1106]),\n",
       " tensor([ 412, 1017, 1026,  411,  421, 1098, 1107,  420]),\n",
       " tensor([1017, 1018, 1027, 1026, 1098, 1099, 1108, 1107]),\n",
       " tensor([1018, 1019, 1028, 1027, 1099, 1100, 1109, 1108]),\n",
       " tensor([1019, 1020, 1029, 1028, 1100, 1101, 1110, 1109]),\n",
       " tensor([1020, 1021, 1030, 1029, 1101, 1102, 1111, 1110]),\n",
       " tensor([1021, 1022, 1031, 1030, 1102, 1103, 1112, 1111]),\n",
       " tensor([1022, 1023, 1032, 1031, 1103, 1104, 1113, 1112]),\n",
       " tensor([1023, 1024, 1033, 1032, 1104, 1105, 1114, 1113]),\n",
       " tensor([1024, 1025, 1034, 1033, 1105, 1106, 1115, 1114]),\n",
       " tensor([1025,  244,  245, 1034, 1106,  253,  254, 1115]),\n",
       " tensor([ 411, 1026, 1035,  410,  420, 1107, 1116,  419]),\n",
       " tensor([1026, 1027, 1036, 1035, 1107, 1108, 1117, 1116]),\n",
       " tensor([1027, 1028, 1037, 1036, 1108, 1109, 1118, 1117]),\n",
       " tensor([1028, 1029, 1038, 1037, 1109, 1110, 1119, 1118]),\n",
       " tensor([1029, 1030, 1039, 1038, 1110, 1111, 1120, 1119]),\n",
       " tensor([1030, 1031, 1040, 1039, 1111, 1112, 1121, 1120]),\n",
       " tensor([1031, 1032, 1041, 1040, 1112, 1113, 1122, 1121]),\n",
       " tensor([1032, 1033, 1042, 1041, 1113, 1114, 1123, 1122]),\n",
       " tensor([1033, 1034, 1043, 1042, 1114, 1115, 1124, 1123]),\n",
       " tensor([1034,  245,  246, 1043, 1115,  254,  255, 1124]),\n",
       " tensor([ 410, 1035, 1044,  409,  419, 1116, 1125,  418]),\n",
       " tensor([1035, 1036, 1045, 1044, 1116, 1117, 1126, 1125]),\n",
       " tensor([1036, 1037, 1046, 1045, 1117, 1118, 1127, 1126]),\n",
       " tensor([1037, 1038, 1047, 1046, 1118, 1119, 1128, 1127]),\n",
       " tensor([1038, 1039, 1048, 1047, 1119, 1120, 1129, 1128]),\n",
       " tensor([1039, 1040, 1049, 1048, 1120, 1121, 1130, 1129]),\n",
       " tensor([1040, 1041, 1050, 1049, 1121, 1122, 1131, 1130]),\n",
       " tensor([1041, 1042, 1051, 1050, 1122, 1123, 1132, 1131]),\n",
       " tensor([1042, 1043, 1052, 1051, 1123, 1124, 1133, 1132]),\n",
       " tensor([1043,  246,  247, 1052, 1124,  255,  256, 1133]),\n",
       " tensor([ 409, 1044, 1053,  408,  418, 1125, 1134,  417]),\n",
       " tensor([1044, 1045, 1054, 1053, 1125, 1126, 1135, 1134]),\n",
       " tensor([1045, 1046, 1055, 1054, 1126, 1127, 1136, 1135]),\n",
       " tensor([1046, 1047, 1056, 1055, 1127, 1128, 1137, 1136]),\n",
       " tensor([1047, 1048, 1057, 1056, 1128, 1129, 1138, 1137]),\n",
       " tensor([1048, 1049, 1058, 1057, 1129, 1130, 1139, 1138]),\n",
       " tensor([1049, 1050, 1059, 1058, 1130, 1131, 1140, 1139]),\n",
       " tensor([1050, 1051, 1060, 1059, 1131, 1132, 1141, 1140]),\n",
       " tensor([1051, 1052, 1061, 1060, 1132, 1133, 1142, 1141]),\n",
       " tensor([1052,  247,  248, 1061, 1133,  256,  257, 1142]),\n",
       " tensor([ 408, 1053, 1062,  407,  417, 1134, 1143,  416]),\n",
       " tensor([1053, 1054, 1063, 1062, 1134, 1135, 1144, 1143]),\n",
       " tensor([1054, 1055, 1064, 1063, 1135, 1136, 1145, 1144]),\n",
       " tensor([1055, 1056, 1065, 1064, 1136, 1137, 1146, 1145]),\n",
       " tensor([1056, 1057, 1066, 1065, 1137, 1138, 1147, 1146]),\n",
       " tensor([1057, 1058, 1067, 1066, 1138, 1139, 1148, 1147]),\n",
       " tensor([1058, 1059, 1068, 1067, 1139, 1140, 1149, 1148]),\n",
       " tensor([1059, 1060, 1069, 1068, 1140, 1141, 1150, 1149]),\n",
       " tensor([1060, 1061, 1070, 1069, 1141, 1142, 1151, 1150]),\n",
       " tensor([1061,  248,  249, 1070, 1142,  257,  258, 1151]),\n",
       " tensor([ 407, 1062, 1071,  406,  416, 1143, 1152,  415]),\n",
       " tensor([1062, 1063, 1072, 1071, 1143, 1144, 1153, 1152]),\n",
       " tensor([1063, 1064, 1073, 1072, 1144, 1145, 1154, 1153]),\n",
       " tensor([1064, 1065, 1074, 1073, 1145, 1146, 1155, 1154]),\n",
       " tensor([1065, 1066, 1075, 1074, 1146, 1147, 1156, 1155]),\n",
       " tensor([1066, 1067, 1076, 1075, 1147, 1148, 1157, 1156]),\n",
       " tensor([1067, 1068, 1077, 1076, 1148, 1149, 1158, 1157]),\n",
       " tensor([1068, 1069, 1078, 1077, 1149, 1150, 1159, 1158]),\n",
       " tensor([1069, 1070, 1079, 1078, 1150, 1151, 1160, 1159]),\n",
       " tensor([1070,  249,  250, 1079, 1151,  258,  259, 1160]),\n",
       " tensor([ 406, 1071, 1080,  405,  415, 1152, 1161,  414]),\n",
       " tensor([1071, 1072, 1081, 1080, 1152, 1153, 1162, 1161]),\n",
       " tensor([1072, 1073, 1082, 1081, 1153, 1154, 1163, 1162]),\n",
       " tensor([1073, 1074, 1083, 1082, 1154, 1155, 1164, 1163]),\n",
       " tensor([1074, 1075, 1084, 1083, 1155, 1156, 1165, 1164]),\n",
       " tensor([1075, 1076, 1085, 1084, 1156, 1157, 1166, 1165]),\n",
       " tensor([1076, 1077, 1086, 1085, 1157, 1158, 1167, 1166]),\n",
       " tensor([1077, 1078, 1087, 1086, 1158, 1159, 1168, 1167]),\n",
       " tensor([1078, 1079, 1088, 1087, 1159, 1160, 1169, 1168]),\n",
       " tensor([1079,  250,  251, 1088, 1160,  259,  260, 1169]),\n",
       " tensor([ 405, 1080,  332,   86,  414, 1161,  341,   87]),\n",
       " tensor([1080, 1081,  331,  332, 1161, 1162,  340,  341]),\n",
       " tensor([1081, 1082,  330,  331, 1162, 1163,  339,  340]),\n",
       " tensor([1082, 1083,  329,  330, 1163, 1164,  338,  339]),\n",
       " tensor([1083, 1084,  328,  329, 1164, 1165,  337,  338]),\n",
       " tensor([1084, 1085,  327,  328, 1165, 1166,  336,  337]),\n",
       " tensor([1085, 1086,  326,  327, 1166, 1167,  335,  336]),\n",
       " tensor([1086, 1087,  325,  326, 1167, 1168,  334,  335]),\n",
       " tensor([1087, 1088,  324,  325, 1168, 1169,  333,  334]),\n",
       " tensor([1088,  251,   59,  324, 1169,  260,   60,  333]),\n",
       " tensor([  38,  171, 1089,  422,   37,  180, 1170,  431]),\n",
       " tensor([ 171,  172, 1090, 1089,  180,  181, 1171, 1170]),\n",
       " tensor([ 172,  173, 1091, 1090,  181,  182, 1172, 1171]),\n",
       " tensor([ 173,  174, 1092, 1091,  182,  183, 1173, 1172]),\n",
       " tensor([ 174,  175, 1093, 1092,  183,  184, 1174, 1173]),\n",
       " tensor([ 175,  176, 1094, 1093,  184,  185, 1175, 1174]),\n",
       " tensor([ 176,  177, 1095, 1094,  185,  186, 1176, 1175]),\n",
       " tensor([ 177,  178, 1096, 1095,  186,  187, 1177, 1176]),\n",
       " tensor([ 178,  179, 1097, 1096,  187,  188, 1178, 1177]),\n",
       " tensor([ 179,   24,  252, 1097,  188,   25,  261, 1178]),\n",
       " tensor([ 422, 1089, 1098,  421,  431, 1170, 1179,  430]),\n",
       " tensor([1089, 1090, 1099, 1098, 1170, 1171, 1180, 1179]),\n",
       " tensor([1090, 1091, 1100, 1099, 1171, 1172, 1181, 1180]),\n",
       " tensor([1091, 1092, 1101, 1100, 1172, 1173, 1182, 1181]),\n",
       " tensor([1092, 1093, 1102, 1101, 1173, 1174, 1183, 1182]),\n",
       " tensor([1093, 1094, 1103, 1102, 1174, 1175, 1184, 1183]),\n",
       " tensor([1094, 1095, 1104, 1103, 1175, 1176, 1185, 1184]),\n",
       " tensor([1095, 1096, 1105, 1104, 1176, 1177, 1186, 1185]),\n",
       " tensor([1096, 1097, 1106, 1105, 1177, 1178, 1187, 1186]),\n",
       " tensor([1097,  252,  253, 1106, 1178,  261,  262, 1187]),\n",
       " tensor([ 421, 1098, 1107,  420,  430, 1179, 1188,  429]),\n",
       " tensor([1098, 1099, 1108, 1107, 1179, 1180, 1189, 1188]),\n",
       " tensor([1099, 1100, 1109, 1108, 1180, 1181, 1190, 1189]),\n",
       " tensor([1100, 1101, 1110, 1109, 1181, 1182, 1191, 1190]),\n",
       " tensor([1101, 1102, 1111, 1110, 1182, 1183, 1192, 1191]),\n",
       " tensor([1102, 1103, 1112, 1111, 1183, 1184, 1193, 1192]),\n",
       " tensor([1103, 1104, 1113, 1112, 1184, 1185, 1194, 1193]),\n",
       " tensor([1104, 1105, 1114, 1113, 1185, 1186, 1195, 1194]),\n",
       " tensor([1105, 1106, 1115, 1114, 1186, 1187, 1196, 1195]),\n",
       " tensor([1106,  253,  254, 1115, 1187,  262,  263, 1196]),\n",
       " tensor([ 420, 1107, 1116,  419,  429, 1188, 1197,  428]),\n",
       " tensor([1107, 1108, 1117, 1116, 1188, 1189, 1198, 1197]),\n",
       " tensor([1108, 1109, 1118, 1117, 1189, 1190, 1199, 1198]),\n",
       " tensor([1109, 1110, 1119, 1118, 1190, 1191, 1200, 1199]),\n",
       " tensor([1110, 1111, 1120, 1119, 1191, 1192, 1201, 1200]),\n",
       " tensor([1111, 1112, 1121, 1120, 1192, 1193, 1202, 1201]),\n",
       " tensor([1112, 1113, 1122, 1121, 1193, 1194, 1203, 1202]),\n",
       " tensor([1113, 1114, 1123, 1122, 1194, 1195, 1204, 1203]),\n",
       " tensor([1114, 1115, 1124, 1123, 1195, 1196, 1205, 1204]),\n",
       " tensor([1115,  254,  255, 1124, 1196,  263,  264, 1205]),\n",
       " tensor([ 419, 1116, 1125,  418,  428, 1197, 1206,  427]),\n",
       " tensor([1116, 1117, 1126, 1125, 1197, 1198, 1207, 1206]),\n",
       " tensor([1117, 1118, 1127, 1126, 1198, 1199, 1208, 1207]),\n",
       " tensor([1118, 1119, 1128, 1127, 1199, 1200, 1209, 1208]),\n",
       " tensor([1119, 1120, 1129, 1128, 1200, 1201, 1210, 1209]),\n",
       " tensor([1120, 1121, 1130, 1129, 1201, 1202, 1211, 1210]),\n",
       " tensor([1121, 1122, 1131, 1130, 1202, 1203, 1212, 1211]),\n",
       " tensor([1122, 1123, 1132, 1131, 1203, 1204, 1213, 1212]),\n",
       " tensor([1123, 1124, 1133, 1132, 1204, 1205, 1214, 1213]),\n",
       " tensor([1124,  255,  256, 1133, 1205,  264,  265, 1214]),\n",
       " tensor([ 418, 1125, 1134,  417,  427, 1206, 1215,  426]),\n",
       " tensor([1125, 1126, 1135, 1134, 1206, 1207, 1216, 1215]),\n",
       " tensor([1126, 1127, 1136, 1135, 1207, 1208, 1217, 1216]),\n",
       " tensor([1127, 1128, 1137, 1136, 1208, 1209, 1218, 1217]),\n",
       " tensor([1128, 1129, 1138, 1137, 1209, 1210, 1219, 1218]),\n",
       " tensor([1129, 1130, 1139, 1138, 1210, 1211, 1220, 1219]),\n",
       " tensor([1130, 1131, 1140, 1139, 1211, 1212, 1221, 1220]),\n",
       " tensor([1131, 1132, 1141, 1140, 1212, 1213, 1222, 1221]),\n",
       " tensor([1132, 1133, 1142, 1141, 1213, 1214, 1223, 1222]),\n",
       " tensor([1133,  256,  257, 1142, 1214,  265,  266, 1223]),\n",
       " tensor([ 417, 1134, 1143,  416,  426, 1215, 1224,  425]),\n",
       " tensor([1134, 1135, 1144, 1143, 1215, 1216, 1225, 1224]),\n",
       " tensor([1135, 1136, 1145, 1144, 1216, 1217, 1226, 1225]),\n",
       " tensor([1136, 1137, 1146, 1145, 1217, 1218, 1227, 1226]),\n",
       " tensor([1137, 1138, 1147, 1146, 1218, 1219, 1228, 1227]),\n",
       " tensor([1138, 1139, 1148, 1147, 1219, 1220, 1229, 1228]),\n",
       " tensor([1139, 1140, 1149, 1148, 1220, 1221, 1230, 1229]),\n",
       " tensor([1140, 1141, 1150, 1149, 1221, 1222, 1231, 1230]),\n",
       " tensor([1141, 1142, 1151, 1150, 1222, 1223, 1232, 1231]),\n",
       " tensor([1142,  257,  258, 1151, 1223,  266,  267, 1232]),\n",
       " tensor([ 416, 1143, 1152,  415,  425, 1224, 1233,  424]),\n",
       " tensor([1143, 1144, 1153, 1152, 1224, 1225, 1234, 1233]),\n",
       " tensor([1144, 1145, 1154, 1153, 1225, 1226, 1235, 1234]),\n",
       " tensor([1145, 1146, 1155, 1154, 1226, 1227, 1236, 1235]),\n",
       " tensor([1146, 1147, 1156, 1155, 1227, 1228, 1237, 1236]),\n",
       " tensor([1147, 1148, 1157, 1156, 1228, 1229, 1238, 1237]),\n",
       " tensor([1148, 1149, 1158, 1157, 1229, 1230, 1239, 1238]),\n",
       " tensor([1149, 1150, 1159, 1158, 1230, 1231, 1240, 1239]),\n",
       " tensor([1150, 1151, 1160, 1159, 1231, 1232, 1241, 1240]),\n",
       " tensor([1151,  258,  259, 1160, 1232,  267,  268, 1241]),\n",
       " tensor([ 415, 1152, 1161,  414,  424, 1233, 1242,  423]),\n",
       " tensor([1152, 1153, 1162, 1161, 1233, 1234, 1243, 1242]),\n",
       " tensor([1153, 1154, 1163, 1162, 1234, 1235, 1244, 1243]),\n",
       " tensor([1154, 1155, 1164, 1163, 1235, 1236, 1245, 1244]),\n",
       " tensor([1155, 1156, 1165, 1164, 1236, 1237, 1246, 1245]),\n",
       " tensor([1156, 1157, 1166, 1165, 1237, 1238, 1247, 1246]),\n",
       " tensor([1157, 1158, 1167, 1166, 1238, 1239, 1248, 1247]),\n",
       " tensor([1158, 1159, 1168, 1167, 1239, 1240, 1249, 1248]),\n",
       " tensor([1159, 1160, 1169, 1168, 1240, 1241, 1250, 1249]),\n",
       " tensor([1160,  259,  260, 1169, 1241,  268,  269, 1250]),\n",
       " tensor([ 414, 1161,  341,   87,  423, 1242,  350,   88]),\n",
       " tensor([1161, 1162,  340,  341, 1242, 1243,  349,  350]),\n",
       " tensor([1162, 1163,  339,  340, 1243, 1244,  348,  349]),\n",
       " tensor([1163, 1164,  338,  339, 1244, 1245,  347,  348]),\n",
       " tensor([1164, 1165,  337,  338, 1245, 1246,  346,  347]),\n",
       " tensor([1165, 1166,  336,  337, 1246, 1247,  345,  346]),\n",
       " tensor([1166, 1167,  335,  336, 1247, 1248,  344,  345]),\n",
       " tensor([1167, 1168,  334,  335, 1248, 1249,  343,  344]),\n",
       " tensor([1168, 1169,  333,  334, 1249, 1250,  342,  343]),\n",
       " tensor([1169,  260,   60,  333, 1250,  269,   61,  342]),\n",
       " tensor([  37,  180, 1170,  431,   36,  189, 1251,  440]),\n",
       " tensor([ 180,  181, 1171, 1170,  189,  190, 1252, 1251]),\n",
       " tensor([ 181,  182, 1172, 1171,  190,  191, 1253, 1252]),\n",
       " tensor([ 182,  183, 1173, 1172,  191,  192, 1254, 1253]),\n",
       " tensor([ 183,  184, 1174, 1173,  192,  193, 1255, 1254]),\n",
       " tensor([ 184,  185, 1175, 1174,  193,  194, 1256, 1255]),\n",
       " tensor([ 185,  186, 1176, 1175,  194,  195, 1257, 1256]),\n",
       " tensor([ 186,  187, 1177, 1176,  195,  196, 1258, 1257]),\n",
       " tensor([ 187,  188, 1178, 1177,  196,  197, 1259, 1258]),\n",
       " tensor([ 188,   25,  261, 1178,  197,   26,  270, 1259]),\n",
       " tensor([ 431, 1170, 1179,  430,  440, 1251, 1260,  439]),\n",
       " tensor([1170, 1171, 1180, 1179, 1251, 1252, 1261, 1260]),\n",
       " tensor([1171, 1172, 1181, 1180, 1252, 1253, 1262, 1261]),\n",
       " tensor([1172, 1173, 1182, 1181, 1253, 1254, 1263, 1262]),\n",
       " tensor([1173, 1174, 1183, 1182, 1254, 1255, 1264, 1263]),\n",
       " tensor([1174, 1175, 1184, 1183, 1255, 1256, 1265, 1264]),\n",
       " tensor([1175, 1176, 1185, 1184, 1256, 1257, 1266, 1265]),\n",
       " tensor([1176, 1177, 1186, 1185, 1257, 1258, 1267, 1266]),\n",
       " tensor([1177, 1178, 1187, 1186, 1258, 1259, 1268, 1267]),\n",
       " tensor([1178,  261,  262, 1187, 1259,  270,  271, 1268]),\n",
       " tensor([ 430, 1179, 1188,  429,  439, 1260, 1269,  438]),\n",
       " tensor([1179, 1180, 1189, 1188, 1260, 1261, 1270, 1269]),\n",
       " tensor([1180, 1181, 1190, 1189, 1261, 1262, 1271, 1270]),\n",
       " tensor([1181, 1182, 1191, 1190, 1262, 1263, 1272, 1271]),\n",
       " tensor([1182, 1183, 1192, 1191, 1263, 1264, 1273, 1272]),\n",
       " tensor([1183, 1184, 1193, 1192, 1264, 1265, 1274, 1273]),\n",
       " tensor([1184, 1185, 1194, 1193, 1265, 1266, 1275, 1274]),\n",
       " tensor([1185, 1186, 1195, 1194, 1266, 1267, 1276, 1275]),\n",
       " tensor([1186, 1187, 1196, 1195, 1267, 1268, 1277, 1276]),\n",
       " tensor([1187,  262,  263, 1196, 1268,  271,  272, 1277]),\n",
       " tensor([ 429, 1188, 1197,  428,  438, 1269, 1278,  437]),\n",
       " tensor([1188, 1189, 1198, 1197, 1269, 1270, 1279, 1278]),\n",
       " tensor([1189, 1190, 1199, 1198, 1270, 1271, 1280, 1279]),\n",
       " tensor([1190, 1191, 1200, 1199, 1271, 1272, 1281, 1280]),\n",
       " tensor([1191, 1192, 1201, 1200, 1272, 1273, 1282, 1281]),\n",
       " tensor([1192, 1193, 1202, 1201, 1273, 1274, 1283, 1282]),\n",
       " tensor([1193, 1194, 1203, 1202, 1274, 1275, 1284, 1283]),\n",
       " tensor([1194, 1195, 1204, 1203, 1275, 1276, 1285, 1284]),\n",
       " tensor([1195, 1196, 1205, 1204, 1276, 1277, 1286, 1285]),\n",
       " tensor([1196,  263,  264, 1205, 1277,  272,  273, 1286]),\n",
       " tensor([ 428, 1197, 1206,  427,  437, 1278, 1287,  436]),\n",
       " tensor([1197, 1198, 1207, 1206, 1278, 1279, 1288, 1287]),\n",
       " tensor([1198, 1199, 1208, 1207, 1279, 1280, 1289, 1288]),\n",
       " tensor([1199, 1200, 1209, 1208, 1280, 1281, 1290, 1289]),\n",
       " tensor([1200, 1201, 1210, 1209, 1281, 1282, 1291, 1290]),\n",
       " tensor([1201, 1202, 1211, 1210, 1282, 1283, 1292, 1291]),\n",
       " tensor([1202, 1203, 1212, 1211, 1283, 1284, 1293, 1292]),\n",
       " tensor([1203, 1204, 1213, 1212, 1284, 1285, 1294, 1293]),\n",
       " tensor([1204, 1205, 1214, 1213, 1285, 1286, 1295, 1294]),\n",
       " tensor([1205,  264,  265, 1214, 1286,  273,  274, 1295]),\n",
       " tensor([ 427, 1206, 1215,  426,  436, 1287, 1296,  435]),\n",
       " tensor([1206, 1207, 1216, 1215, 1287, 1288, 1297, 1296]),\n",
       " tensor([1207, 1208, 1217, 1216, 1288, 1289, 1298, 1297]),\n",
       " tensor([1208, 1209, 1218, 1217, 1289, 1290, 1299, 1298]),\n",
       " tensor([1209, 1210, 1219, 1218, 1290, 1291, 1300, 1299]),\n",
       " tensor([1210, 1211, 1220, 1219, 1291, 1292, 1301, 1300]),\n",
       " tensor([1211, 1212, 1221, 1220, 1292, 1293, 1302, 1301]),\n",
       " tensor([1212, 1213, 1222, 1221, 1293, 1294, 1303, 1302]),\n",
       " tensor([1213, 1214, 1223, 1222, 1294, 1295, 1304, 1303]),\n",
       " tensor([1214,  265,  266, 1223, 1295,  274,  275, 1304]),\n",
       " tensor([ 426, 1215, 1224,  425,  435, 1296, 1305,  434]),\n",
       " tensor([1215, 1216, 1225, 1224, 1296, 1297, 1306, 1305]),\n",
       " tensor([1216, 1217, 1226, 1225, 1297, 1298, 1307, 1306]),\n",
       " tensor([1217, 1218, 1227, 1226, 1298, 1299, 1308, 1307]),\n",
       " tensor([1218, 1219, 1228, 1227, 1299, 1300, 1309, 1308]),\n",
       " tensor([1219, 1220, 1229, 1228, 1300, 1301, 1310, 1309]),\n",
       " tensor([1220, 1221, 1230, 1229, 1301, 1302, 1311, 1310]),\n",
       " tensor([1221, 1222, 1231, 1230, 1302, 1303, 1312, 1311]),\n",
       " tensor([1222, 1223, 1232, 1231, 1303, 1304, 1313, 1312]),\n",
       " tensor([1223,  266,  267, 1232, 1304,  275,  276, 1313]),\n",
       " tensor([ 425, 1224, 1233,  424,  434, 1305, 1314,  433]),\n",
       " tensor([1224, 1225, 1234, 1233, 1305, 1306, 1315, 1314]),\n",
       " tensor([1225, 1226, 1235, 1234, 1306, 1307, 1316, 1315]),\n",
       " tensor([1226, 1227, 1236, 1235, 1307, 1308, 1317, 1316]),\n",
       " tensor([1227, 1228, 1237, 1236, 1308, 1309, 1318, 1317]),\n",
       " tensor([1228, 1229, 1238, 1237, 1309, 1310, 1319, 1318]),\n",
       " tensor([1229, 1230, 1239, 1238, 1310, 1311, 1320, 1319]),\n",
       " tensor([1230, 1231, 1240, 1239, 1311, 1312, 1321, 1320]),\n",
       " tensor([1231, 1232, 1241, 1240, 1312, 1313, 1322, 1321]),\n",
       " tensor([1232,  267,  268, 1241, 1313,  276,  277, 1322]),\n",
       " tensor([ 424, 1233, 1242,  423,  433, 1314, 1323,  432]),\n",
       " tensor([1233, 1234, 1243, 1242, 1314, 1315, 1324, 1323]),\n",
       " tensor([1234, 1235, 1244, 1243, 1315, 1316, 1325, 1324]),\n",
       " tensor([1235, 1236, 1245, 1244, 1316, 1317, 1326, 1325]),\n",
       " tensor([1236, 1237, 1246, 1245, 1317, 1318, 1327, 1326]),\n",
       " tensor([1237, 1238, 1247, 1246, 1318, 1319, 1328, 1327]),\n",
       " tensor([1238, 1239, 1248, 1247, 1319, 1320, 1329, 1328]),\n",
       " tensor([1239, 1240, 1249, 1248, 1320, 1321, 1330, 1329]),\n",
       " tensor([1240, 1241, 1250, 1249, 1321, 1322, 1331, 1330]),\n",
       " tensor([1241,  268,  269, 1250, 1322,  277,  278, 1331]),\n",
       " tensor([ 423, 1242,  350,   88,  432, 1323,  359,   89]),\n",
       " tensor([1242, 1243,  349,  350, 1323, 1324,  358,  359]),\n",
       " tensor([1243, 1244,  348,  349, 1324, 1325,  357,  358]),\n",
       " tensor([1244, 1245,  347,  348, 1325, 1326,  356,  357]),\n",
       " tensor([1245, 1246,  346,  347, 1326, 1327,  355,  356]),\n",
       " tensor([1246, 1247,  345,  346, 1327, 1328,  354,  355]),\n",
       " tensor([1247, 1248,  344,  345, 1328, 1329,  353,  354]),\n",
       " tensor([1248, 1249,  343,  344, 1329, 1330,  352,  353]),\n",
       " tensor([1249, 1250,  342,  343, 1330, 1331,  351,  352]),\n",
       " tensor([1250,  269,   61,  342, 1331,  278,   62,  351]),\n",
       " tensor([  36,  189, 1251,  440,    5,   35,  522,  108]),\n",
       " tensor([ 189,  190, 1252, 1251,   35,   34,  523,  522]),\n",
       " tensor([ 190,  191, 1253, 1252,   34,   33,  524,  523]),\n",
       " tensor([ 191,  192, 1254, 1253,   33,   32,  525,  524]),\n",
       " tensor([ 192,  193, 1255, 1254,   32,   31,  526,  525]),\n",
       " tensor([ 193,  194, 1256, 1255,   31,   30,  527,  526]),\n",
       " tensor([ 194,  195, 1257, 1256,   30,   29,  528,  527]),\n",
       " tensor([ 195,  196, 1258, 1257,   29,   28,  529,  528]),\n",
       " tensor([ 196,  197, 1259, 1258,   28,   27,  530,  529]),\n",
       " tensor([ 197,   26,  270, 1259,   27,    6,   71,  530]),\n",
       " tensor([ 440, 1251, 1260,  439,  108,  522,  531,  109]),\n",
       " tensor([1251, 1252, 1261, 1260,  522,  523,  532,  531]),\n",
       " tensor([1252, 1253, 1262, 1261,  523,  524,  533,  532]),\n",
       " tensor([1253, 1254, 1263, 1262,  524,  525,  534,  533]),\n",
       " tensor([1254, 1255, 1264, 1263,  525,  526,  535,  534]),\n",
       " tensor([1255, 1256, 1265, 1264,  526,  527,  536,  535]),\n",
       " tensor([1256, 1257, 1266, 1265,  527,  528,  537,  536]),\n",
       " tensor([1257, 1258, 1267, 1266,  528,  529,  538,  537]),\n",
       " tensor([1258, 1259, 1268, 1267,  529,  530,  539,  538]),\n",
       " tensor([1259,  270,  271, 1268,  530,   71,   70,  539]),\n",
       " tensor([ 439, 1260, 1269,  438,  109,  531,  540,  110]),\n",
       " tensor([1260, 1261, 1270, 1269,  531,  532,  541,  540]),\n",
       " tensor([1261, 1262, 1271, 1270,  532,  533,  542,  541]),\n",
       " tensor([1262, 1263, 1272, 1271,  533,  534,  543,  542]),\n",
       " tensor([1263, 1264, 1273, 1272,  534,  535,  544,  543]),\n",
       " tensor([1264, 1265, 1274, 1273,  535,  536,  545,  544]),\n",
       " tensor([1265, 1266, 1275, 1274,  536,  537,  546,  545]),\n",
       " tensor([1266, 1267, 1276, 1275,  537,  538,  547,  546]),\n",
       " tensor([1267, 1268, 1277, 1276,  538,  539,  548,  547]),\n",
       " tensor([1268,  271,  272, 1277,  539,   70,   69,  548]),\n",
       " tensor([ 438, 1269, 1278,  437,  110,  540,  549,  111]),\n",
       " tensor([1269, 1270, 1279, 1278,  540,  541,  550,  549]),\n",
       " tensor([1270, 1271, 1280, 1279,  541,  542,  551,  550]),\n",
       " tensor([1271, 1272, 1281, 1280,  542,  543,  552,  551]),\n",
       " tensor([1272, 1273, 1282, 1281,  543,  544,  553,  552]),\n",
       " tensor([1273, 1274, 1283, 1282,  544,  545,  554,  553]),\n",
       " tensor([1274, 1275, 1284, 1283,  545,  546,  555,  554]),\n",
       " tensor([1275, 1276, 1285, 1284,  546,  547,  556,  555]),\n",
       " tensor([1276, 1277, 1286, 1285,  547,  548,  557,  556]),\n",
       " tensor([1277,  272,  273, 1286,  548,   69,   68,  557]),\n",
       " tensor([ 437, 1278, 1287,  436,  111,  549,  558,  112]),\n",
       " tensor([1278, 1279, 1288, 1287,  549,  550,  559,  558]),\n",
       " tensor([1279, 1280, 1289, 1288,  550,  551,  560,  559]),\n",
       " tensor([1280, 1281, 1290, 1289,  551,  552,  561,  560]),\n",
       " tensor([1281, 1282, 1291, 1290,  552,  553,  562,  561]),\n",
       " tensor([1282, 1283, 1292, 1291,  553,  554,  563,  562]),\n",
       " tensor([1283, 1284, 1293, 1292,  554,  555,  564,  563]),\n",
       " tensor([1284, 1285, 1294, 1293,  555,  556,  565,  564]),\n",
       " tensor([1285, 1286, 1295, 1294,  556,  557,  566,  565]),\n",
       " tensor([1286,  273,  274, 1295,  557,   68,   67,  566]),\n",
       " tensor([ 436, 1287, 1296,  435,  112,  558,  567,  113]),\n",
       " tensor([1287, 1288, 1297, 1296,  558,  559,  568,  567]),\n",
       " tensor([1288, 1289, 1298, 1297,  559,  560,  569,  568]),\n",
       " tensor([1289, 1290, 1299, 1298,  560,  561,  570,  569]),\n",
       " tensor([1290, 1291, 1300, 1299,  561,  562,  571,  570]),\n",
       " tensor([1291, 1292, 1301, 1300,  562,  563,  572,  571]),\n",
       " tensor([1292, 1293, 1302, 1301,  563,  564,  573,  572]),\n",
       " tensor([1293, 1294, 1303, 1302,  564,  565,  574,  573]),\n",
       " tensor([1294, 1295, 1304, 1303,  565,  566,  575,  574]),\n",
       " tensor([1295,  274,  275, 1304,  566,   67,   66,  575]),\n",
       " tensor([ 435, 1296, 1305,  434,  113,  567,  576,  114]),\n",
       " tensor([1296, 1297, 1306, 1305,  567,  568,  577,  576]),\n",
       " tensor([1297, 1298, 1307, 1306,  568,  569,  578,  577]),\n",
       " tensor([1298, 1299, 1308, 1307,  569,  570,  579,  578]),\n",
       " tensor([1299, 1300, 1309, 1308,  570,  571,  580,  579]),\n",
       " tensor([1300, 1301, 1310, 1309,  571,  572,  581,  580]),\n",
       " tensor([1301, 1302, 1311, 1310,  572,  573,  582,  581]),\n",
       " tensor([1302, 1303, 1312, 1311,  573,  574,  583,  582]),\n",
       " tensor([1303, 1304, 1313, 1312,  574,  575,  584,  583]),\n",
       " tensor([1304,  275,  276, 1313,  575,   66,   65,  584]),\n",
       " tensor([ 434, 1305, 1314,  433,  114,  576,  585,  115]),\n",
       " tensor([1305, 1306, 1315, 1314,  576,  577,  586,  585]),\n",
       " tensor([1306, 1307, 1316, 1315,  577,  578,  587,  586]),\n",
       " tensor([1307, 1308, 1317, 1316,  578,  579,  588,  587]),\n",
       " tensor([1308, 1309, 1318, 1317,  579,  580,  589,  588]),\n",
       " tensor([1309, 1310, 1319, 1318,  580,  581,  590,  589]),\n",
       " tensor([1310, 1311, 1320, 1319,  581,  582,  591,  590]),\n",
       " tensor([1311, 1312, 1321, 1320,  582,  583,  592,  591]),\n",
       " tensor([1312, 1313, 1322, 1321,  583,  584,  593,  592]),\n",
       " tensor([1313,  276,  277, 1322,  584,   65,   64,  593]),\n",
       " tensor([ 433, 1314, 1323,  432,  115,  585,  594,  116]),\n",
       " tensor([1314, 1315, 1324, 1323,  585,  586,  595,  594]),\n",
       " tensor([1315, 1316, 1325, 1324,  586,  587,  596,  595]),\n",
       " tensor([1316, 1317, 1326, 1325,  587,  588,  597,  596]),\n",
       " tensor([1317, 1318, 1327, 1326,  588,  589,  598,  597]),\n",
       " tensor([1318, 1319, 1328, 1327,  589,  590,  599,  598]),\n",
       " tensor([1319, 1320, 1329, 1328,  590,  591,  600,  599]),\n",
       " tensor([1320, 1321, 1330, 1329,  591,  592,  601,  600]),\n",
       " tensor([1321, 1322, 1331, 1330,  592,  593,  602,  601]),\n",
       " tensor([1322,  277,  278, 1331,  593,   64,   63,  602]),\n",
       " tensor([ 432, 1323,  359,   89,  116,  594,   90,    8]),\n",
       " tensor([1323, 1324,  358,  359,  594,  595,   91,   90]),\n",
       " tensor([1324, 1325,  357,  358,  595,  596,   92,   91]),\n",
       " tensor([1325, 1326,  356,  357,  596,  597,   93,   92]),\n",
       " tensor([1326, 1327,  355,  356,  597,  598,   94,   93]),\n",
       " tensor([1327, 1328,  354,  355,  598,  599,   95,   94]),\n",
       " tensor([1328, 1329,  353,  354,  599,  600,   96,   95]),\n",
       " tensor([1329, 1330,  352,  353,  600,  601,   97,   96]),\n",
       " tensor([1330, 1331,  351,  352,  601,  602,   98,   97]),\n",
       " tensor([1331,  278,   62,  351,  602,   63,    7,   98])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connectivity = [torch.tensor(row.tolist(), dtype=torch.long) for _, row in connectivity.iterrows()]\n",
    "connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([999, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read volume\n",
    "vol = pd.read_csv(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube/jobs/outputs/vol_last\")\n",
    "\n",
    "# Drop the first column, then convert to an (N×9) Python list:\n",
    "vol = torch.tensor(vol.iloc[:, 1:].to_numpy())   # shape = (N, 9))\n",
    "\n",
    "vol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1330, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read volume\n",
    "position_last = pd.read_csv(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube/jobs/outputs/position_last\")\n",
    "\n",
    "# Drop the first column, then convert to an (N×9) Python list:\n",
    "position_last = torch.tensor(position_last.iloc[:, 1:].to_numpy())   # shape = (N, 9))\n",
    "\n",
    "position_last.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([999, 6])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read volume\n",
    "stress_last = pd.read_csv(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube/jobs/outputs/stress_last\")\n",
    "\n",
    "# Drop the first column, then convert to an (N×9) Python list:\n",
    "stress_last = torch.tensor(stress_last.iloc[:, 1:].to_numpy())   # shape = (N, 9))\n",
    "\n",
    "stress_last.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Suppose `stress_last` has shape [Ne, 6], with columns:\n",
    "#   [sigma_xx, sigma_yy, sigma_zz, sigma_xy, sigma_yz, sigma_xz]\n",
    "stress_last = torch.randn(stress_last.shape[0], 6)  # replace with your actual [Ne,6] tensor\n",
    "\n",
    "# 1) Unpack each Voigt component:\n",
    "sigma_xx = stress_last[:, 0]    # shape [Ne]\n",
    "sigma_yy = stress_last[:, 1]    # shape [Ne]\n",
    "sigma_zz = stress_last[:, 2]    # shape [Ne]\n",
    "sigma_xy = stress_last[:, 3]    # shape [Ne]\n",
    "sigma_yz = stress_last[:, 4]    # shape [Ne]\n",
    "sigma_xz = stress_last[:, 5]    # shape [Ne]\n",
    "\n",
    "# 2) Create a [Ne,3,3] tensor and fill in symmetric entries:\n",
    "Ne = stress_last.shape[0]\n",
    "device = stress_last.device\n",
    "\n",
    "sigma_full = torch.zeros((Ne, 3, 3), device=device, dtype=stress_last.dtype)\n",
    "\n",
    "sigma_full[:, 0, 0] = sigma_xx\n",
    "sigma_full[:, 1, 1] = sigma_yy\n",
    "sigma_full[:, 2, 2] = sigma_zz\n",
    "\n",
    "sigma_full[:, 0, 1] = sigma_xy\n",
    "sigma_full[:, 1, 0] = sigma_xy\n",
    "\n",
    "sigma_full[:, 1, 2] = sigma_yz\n",
    "sigma_full[:, 2, 1] = sigma_yz\n",
    "\n",
    "sigma_full[:, 0, 2] = sigma_xz\n",
    "sigma_full[:, 2, 0] = sigma_xz\n",
    "\n",
    "# 3) Finally reshape to [Ne, 9] if you really need a flat 9‐component vector per element:\n",
    "sigma_flat9 = sigma_full.view(Ne, 9)\n",
    "\n",
    "# Now sigma_flat9[i] = [sigma_xx, sigma_xy, sigma_xz, sigma_xy, sigma_yy, sigma_yz, sigma_xz, sigma_yz, sigma_zz]\n",
    "# (i.e. row‐major flatten of the 3×3 tensor).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1330, 999)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numNodes=displacement.shape[0]\n",
    "numElements=F_last.shape[0]\n",
    "num_nodes_per_element=8\n",
    "numNodes, numElements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log file outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67848/1839226347.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  cx = pd.read_csv(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube/jobs/outputs/centroid_x\", delim_whitespace=True, header=None, usecols=[1]).squeeze(\"columns\").to_numpy()\n",
      "/tmp/ipykernel_67848/1839226347.py:3: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  cy = pd.read_csv(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube/jobs/outputs/centroid_y\", delim_whitespace=True, header=None, usecols=[1]).squeeze(\"columns\").to_numpy()\n",
      "/tmp/ipykernel_67848/1839226347.py:4: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  cz=pd.read_csv(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube/jobs/outputs/centroid_z\", delim_whitespace=True, header=None, usecols=[1]).squeeze(\"columns\").to_numpy()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([999, 3]),\n",
       " tensor([[-0.4505, -0.4505,  0.0497],\n",
       "         [-0.3503, -0.4505,  0.0498],\n",
       "         [-0.2502, -0.4505,  0.0498],\n",
       "         ...,\n",
       "         [ 0.1508,  0.4522,  0.9417],\n",
       "         [ 0.2513,  0.4522,  0.9417],\n",
       "         [ 0.3517,  0.4522,  0.9416]], dtype=torch.float32))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read volume\n",
    "cx = pd.read_csv(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube/jobs/outputs/centroid_x\", delim_whitespace=True, header=None, usecols=[1]).squeeze(\"columns\").to_numpy()\n",
    "cy = pd.read_csv(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube/jobs/outputs/centroid_y\", delim_whitespace=True, header=None, usecols=[1]).squeeze(\"columns\").to_numpy()\n",
    "cz=pd.read_csv(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube/jobs/outputs/centroid_z\", delim_whitespace=True, header=None, usecols=[1]).squeeze(\"columns\").to_numpy()\n",
    "\n",
    "\n",
    "# Drop the first column, then convert to an (N×9) Python list:\n",
    "centroids = torch.tensor(np.stack([cx, cy, cz], axis=1), dtype=torch.float32)[:999]\n",
    "centroids.requires_grad_(True) \n",
    "\n",
    "\n",
    "\n",
    "centroids.shape, centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67848/3584441370.py:3: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  cx = pd.read_csv(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube/jobs/outputs/centroid_x\", delim_whitespace=True, header=None, usecols=[1]).squeeze(\"columns\").to_numpy()\n",
      "/tmp/ipykernel_67848/3584441370.py:4: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  cy = pd.read_csv(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube/jobs/outputs/centroid_y\", delim_whitespace=True, header=None, usecols=[1]).squeeze(\"columns\").to_numpy()\n",
      "/tmp/ipykernel_67848/3584441370.py:5: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  cz=pd.read_csv(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube/jobs/outputs/centroid_z\", delim_whitespace=True, header=None, usecols=[1]).squeeze(\"columns\").to_numpy()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([999, 3]),\n",
       " tensor([[-0.4505, -0.4505,  0.0497],\n",
       "         [-0.3503, -0.4505,  0.0498],\n",
       "         [-0.2502, -0.4505,  0.0498],\n",
       "         ...,\n",
       "         [ 0.1508,  0.4522,  0.9417],\n",
       "         [ 0.2513,  0.4522,  0.9417],\n",
       "         [ 0.3517,  0.4522,  0.9416]], dtype=torch.float32, requires_grad=True))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This should be for initial tensor of centroids vs last \n",
    "#Read volume\n",
    "cx = pd.read_csv(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube/jobs/outputs/centroid_x\", delim_whitespace=True, header=None, usecols=[1]).squeeze(\"columns\").to_numpy()\n",
    "cy = pd.read_csv(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube/jobs/outputs/centroid_y\", delim_whitespace=True, header=None, usecols=[1]).squeeze(\"columns\").to_numpy()\n",
    "cz=pd.read_csv(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube/jobs/outputs/centroid_z\", delim_whitespace=True, header=None, usecols=[1]).squeeze(\"columns\").to_numpy()\n",
    "\n",
    "\n",
    "# Drop the first column, then convert to an (N×9) Python list:\n",
    "centroids_init = torch.tensor(np.stack([cx, cy, cz], axis=1), dtype=torch.float32)[:999]\n",
    "centroids_init.requires_grad_(True) \n",
    "\n",
    "\n",
    "\n",
    "centroids_init.shape, centroids_init\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up architecture of network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "\n",
    "model = ICNN3D_position(n_input=6,\n",
    "                n_hidden=[64,64,64],\n",
    "                n_output=3,\n",
    "                use_dropout=True,\n",
    "                dropout_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ICNN3D_position                          --\n",
       "├─ModuleDict: 1-1                        --\n",
       "│    └─Linear: 2-1                       448\n",
       "│    └─convexLinear: 2-2                 4,096\n",
       "│    └─convexLinear: 2-3                 4,096\n",
       "│    └─convexLinear: 2-4                 192\n",
       "├─ModuleDict: 1-2                        --\n",
       "│    └─Linear: 2-5                       448\n",
       "│    └─Linear: 2-6                       448\n",
       "│    └─convexLinear: 2-7                 18\n",
       "=================================================================\n",
       "Total params: 9,746\n",
       "Trainable params: 9,746\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "model = model.to(device)\n",
    "summary(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Function prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\int_{\\Omega} \\boldsymbol{\\sigma} : \\nabla \\mathbf{v} \\; d x\n",
    "\\;=\\;\n",
    "\\int_{\\Omega} \\mathbf{f} \\cdot \\mathbf{v} \\; d x\n",
    "\\;+\\;\n",
    "\\int_{\\partial \\Omega} \\mathbf{T} \\cdot \\mathbf{v} \\; d s\\,.\n",
    "$$\n",
    "\n",
    "But if there are no body forces:\n",
    "\n",
    "$$\n",
    "a(u,v) \\;=\\; \\int_{\\Omega} \\sigma(u) : \\nabla v \\,\\mathrm{d}x\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "L(v) \\;=\\;  \\int_{\\partial\\Omega} T \\cdot v \\,\\mathrm{d}s\n",
    "$$\n",
    "\n",
    "We can then do a minimization of L and a. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([999, 6]),\n",
       " torch.Size([999, 1]),\n",
       " torch.Size([999, 4]),\n",
       " torch.Size([999, 9]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stress_last.shape, stress_last[:,0:1].shape, stress_last[:,0:4].shape, F_last.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class VirtualFieldNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # A few hidden layers; output dimension = 3 (virtual displacement components)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 3)\n",
    "        )\n",
    "    def forward(self, xyz):\n",
    "        # xyz: [nPoints, 3]\n",
    "        return self.net(xyz)  # returns [nPoints, 3]\n",
    "    \n",
    "v_model = VirtualFieldNet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centroids.dtype = torch.float32\n",
      "net.0.weight.dtype = torch.float64\n"
     ]
    }
   ],
   "source": [
    "print(\"centroids.dtype =\", centroids.dtype)\n",
    "for name, param in v_model.named_parameters():\n",
    "    print(f\"{name}.dtype =\", param.dtype)\n",
    "    break   # just need one parameter to check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([999, 3]), torch.Size([999, 9]), torch.Size([999, 12]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids.shape, F_last.shape, torch.cat((centroids, F_last), dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids.requires_grad_(True) \n",
    "x_input= torch.cat((centroids.to(device), F_last.to(device)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([999, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_NN=model(x_input)\n",
    "V_NN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_outputs = torch.ones_like(V_NN[:, 1])  # shape = [N]\n",
    "\n",
    "dVx_dcentroids = torch.autograd.grad(\n",
    "    outputs=V_NN[:, 0],    # shape [N]\n",
    "    inputs=centroids,      # shape [N,3]\n",
    "    grad_outputs=grad_outputs,\n",
    "    create_graph=True\n",
    ")[0]  # → shape [N,3]\n",
    "\n",
    "dVy_dcentroids = torch.autograd.grad(\n",
    "    outputs=V_NN[:, 1],    # shape [N]\n",
    "    inputs=centroids,      # shape [N,3]\n",
    "    grad_outputs=grad_outputs,\n",
    "    create_graph=True\n",
    ")[0]  # → shape [N,3]\n",
    "\n",
    "dVz_dcentroids = torch.autograd.grad(\n",
    "    outputs=V_NN[:, 2],    # shape [N]\n",
    "    inputs=centroids,      # shape [N,3]\n",
    "    grad_outputs=grad_outputs,\n",
    "    create_graph=True\n",
    ")[0]  # → shape [N,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack them into grad_v[e, i, j] = ∂v_i/∂x_j:\n",
    "grad_v = torch.stack(\n",
    "    [dVx_dcentroids,    # [N,3] → (i=0)\n",
    "     dVy_dcentroids,    # [N,3] → (i=1)\n",
    "     dVz_dcentroids],   # [N,3] → (i=2)\n",
    "    dim=1               # new dim = “i”\n",
    ")                      # → grad_v.shape = [N, 3, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "a(u,v) \\;=\\; \\int_{\\Omega} \\sigma(u) : \\nabla v \\,\\mathrm{d}x\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element‐wise inner product σ^e : ∇v^e\n",
    "integrand = torch.sum(sigma_full * grad_v, dim=(1, 2))  # → shape [N]\n",
    "\n",
    "a_uv = torch.sum(integrand * vol)  # scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "L(v) \\;=\\;  \\int_{\\partial\\Omega} T \\cdot v \\,\\mathrm{d}s\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Build the traction vector T_surf = [0, 0, -1000] for each boundary element:\n",
    "T_surf = torch.tensor([0.0, 0.0, -1000.0], device=centroids.device)  # [3]\n",
    "T_surf = T_surf.view(1,3).expand(numElements, 3)  # → [nB, 3]\n",
    "\n",
    "L_uv=torch.sum(T_surf*V_NN*0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4892884.4903, grad_fn=<SumBackward0>),\n",
       " tensor(-19804954.0409, grad_fn=<SumBackward0>),\n",
       " torch.Size([999, 3]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_uv, L_uv, (T_surf*V_NN).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 62781.804830020774\n",
      "Epoch 10 loss: 61572.57047346433\n",
      "Epoch 20 loss: 60065.0341208992\n",
      "Epoch 30 loss: 59397.67381849515\n",
      "Epoch 40 loss: 58536.34007410749\n",
      "Epoch 50 loss: 57927.439788430784\n",
      "Epoch 60 loss: 57301.63448869555\n",
      "Epoch 70 loss: 56693.291529924056\n",
      "Epoch 80 loss: 56088.877988833694\n",
      "Epoch 90 loss: 55518.76007202036\n",
      "Epoch 100 loss: 54929.48588471265\n",
      "Epoch 110 loss: 54375.94205487245\n",
      "Epoch 120 loss: 53817.846766437695\n",
      "Epoch 130 loss: 53261.29409532341\n",
      "Epoch 140 loss: 52737.198514484626\n",
      "Epoch 150 loss: 52203.43886304635\n",
      "Epoch 160 loss: 51677.57725026529\n",
      "Epoch 170 loss: 51158.47647103532\n",
      "Epoch 180 loss: 50644.37489158097\n",
      "Epoch 190 loss: 50134.29068573398\n",
      "Epoch 200 loss: 49629.10054354105\n",
      "Epoch 210 loss: 49135.40051075414\n",
      "Epoch 220 loss: 48642.80322594891\n",
      "Epoch 230 loss: 48165.191242840716\n",
      "Epoch 240 loss: 47680.98168491004\n"
     ]
    }
   ],
   "source": [
    "epoch=250\n",
    "# Adam with a learning rate:\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for i in range(epoch):\n",
    "    optimizer.zero_grad()              # ← reset gradients\n",
    "\n",
    "    #Estimate\n",
    "    V_NN=model(x_input)\n",
    "    \n",
    "    #Gradients\n",
    "    grad_outputs = torch.ones_like(V_NN[:, 1])  # shape = [N]\n",
    "\n",
    "    dVx_dcentroids = torch.autograd.grad(\n",
    "        outputs=V_NN[:, 0],    # shape [N]\n",
    "        inputs=centroids,      # shape [N,3]\n",
    "        grad_outputs=grad_outputs,\n",
    "        create_graph=True\n",
    "    )[0]  # → shape [N,3]\n",
    "\n",
    "    dVy_dcentroids = torch.autograd.grad(\n",
    "        outputs=V_NN[:, 1],    # shape [N]\n",
    "        inputs=centroids,      # shape [N,3]\n",
    "        grad_outputs=grad_outputs,\n",
    "        create_graph=True\n",
    "    )[0]  # → shape [N,3]\n",
    "\n",
    "    dVz_dcentroids = torch.autograd.grad(\n",
    "        outputs=V_NN[:, 2],    # shape [N]\n",
    "        inputs=centroids,      # shape [N,3]\n",
    "        grad_outputs=grad_outputs,\n",
    "        create_graph=True\n",
    "    )[0]  # → shape [N,3]\n",
    "\n",
    "    # Stack them into grad_v[e, i, j] = ∂v_i/∂x_j:\n",
    "    grad_v = torch.stack(\n",
    "        [dVx_dcentroids,    # [N,3] → (i=0)\n",
    "        dVy_dcentroids,    # [N,3] → (i=1)\n",
    "        dVz_dcentroids],   # [N,3] → (i=2)\n",
    "        dim=1               # new dim = “i”\n",
    "    )                      # → grad_v.shape = [N, 3, 3]\n",
    "\n",
    "    #Strain\n",
    "\n",
    "    virtual_strain=0.5*(grad_v+grad_v.transpose(1,2))\n",
    "\n",
    "    #Volume integral:\n",
    "    # element‐wise inner product σ^e : ∇v^e\n",
    "    integrand = torch.sum(sigma_full * virtual_strain, dim=(1, 2))  # → shape [N]\n",
    "\n",
    "    a_uv = torch.sum(integrand * vol)  # scalar\n",
    "\n",
    "    #Surface integral:\n",
    "\n",
    "    # 3) Build the traction vector T_surf = [0, 0, -1000] for each boundary element:\n",
    "    T_surf = torch.tensor([0.0, 0.0, -1000.0], device=centroids.device)  # [3]\n",
    "    T_surf = T_surf.view(1,3).expand(numElements, 3)  # → [nB, 3]\n",
    "\n",
    "    L_uv=torch.sum(T_surf*V_NN*0.01)\n",
    "\n",
    "    #Loss:\n",
    "    loss=a_uv-L_uv\n",
    "\n",
    "    if i%10==0:\n",
    "        print(f'Epoch {i} loss: {loss.item()}')\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([999, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_NN.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporate Taylor Expansions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "\n",
    "model = ICNN3D_position(n_input=6,\n",
    "                n_hidden=[64,64,64],\n",
    "                n_output=9,\n",
    "                use_dropout=True,\n",
    "                dropout_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ICNN3D_position                          --\n",
       "├─ModuleDict: 1-1                        --\n",
       "│    └─Linear: 2-1                       448\n",
       "│    └─convexLinear: 2-2                 4,096\n",
       "│    └─convexLinear: 2-3                 4,096\n",
       "│    └─convexLinear: 2-4                 576\n",
       "├─ModuleDict: 1-2                        --\n",
       "│    └─Linear: 2-5                       448\n",
       "│    └─Linear: 2-6                       448\n",
       "│    └─convexLinear: 2-7                 54\n",
       "=================================================================\n",
       "Total params: 10,166\n",
       "Trainable params: 10,166\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "model = model.to(device)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input= torch.cat((centroids.to(device), F_last.to(device)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 701300.5999156203\n",
      "Epoch 10 loss: 660172.2553948627\n",
      "Epoch 20 loss: 521437.9593230293\n",
      "Epoch 30 loss: 441887.0765655747\n",
      "Epoch 40 loss: 363808.93722922023\n",
      "Epoch 50 loss: 431991.5129347159\n",
      "Epoch 60 loss: 397078.6121137984\n",
      "Epoch 70 loss: 367744.7389653851\n",
      "Epoch 80 loss: 315745.1910212556\n",
      "Epoch 90 loss: 290113.72272858076\n",
      "Epoch 100 loss: 297140.5713646321\n",
      "Epoch 110 loss: 295796.96391673246\n",
      "Epoch 120 loss: 240036.34625141116\n",
      "Epoch 130 loss: 243894.05698468458\n",
      "Epoch 140 loss: 189534.30293784826\n",
      "Epoch 150 loss: 209108.86083031638\n",
      "Epoch 160 loss: 182342.4601990158\n",
      "Epoch 170 loss: 176658.07820793212\n",
      "Epoch 180 loss: 168332.50445081602\n",
      "Epoch 190 loss: 149631.16014772968\n",
      "Epoch 200 loss: 161905.55282641083\n",
      "Epoch 210 loss: 148909.95746859745\n",
      "Epoch 220 loss: 143917.47918613622\n",
      "Epoch 230 loss: 125097.2814831423\n",
      "Epoch 240 loss: 124312.20348404215\n"
     ]
    }
   ],
   "source": [
    "epoch=250\n",
    "# Adam with a learning rate:\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for i in range(epoch):\n",
    "    optimizer.zero_grad()              # ← reset gradients\n",
    "\n",
    "    #Estimate\n",
    "    V_NN=model(x_input) #This is N elements x9 \n",
    "    \n",
    "    #Construct VF \n",
    "    Vx=V_NN[:,0]+V_NN[:,1]*(centroids_init[:,0]-centroids[:,0])+V_NN[:,2]*(centroids_init[:,0]-centroids[:,0])**2\n",
    "    Vy=V_NN[:,3]+V_NN[:,4]*(centroids_init[:,0]-centroids[:,0])+V_NN[:,5]*(centroids_init[:,0]-centroids[:,0])**2\n",
    "    Vz=V_NN[:,6]+V_NN[:,7]*(centroids_init[:,0]-centroids[:,0])+V_NN[:,8]*(centroids_init[:,0]-centroids[:,0])**2\n",
    "\n",
    "    VF=torch.cat((Vx.unsqueeze(1),Vy.unsqueeze(1),Vz.unsqueeze(1)), dim=1)\n",
    "\n",
    "    #Gradients\n",
    "    grad_outputs = torch.ones_like(V_NN[:, 1])  # shape = [N]\n",
    "\n",
    "    dVx_dcentroids = torch.autograd.grad(\n",
    "        outputs=Vx,    # shape [N]\n",
    "        inputs=centroids,      # shape [N,3]\n",
    "        grad_outputs=grad_outputs,\n",
    "        create_graph=True\n",
    "    )[0]  # → shape [N,3]\n",
    "\n",
    "    dVy_dcentroids = torch.autograd.grad(\n",
    "        outputs=Vy,    # shape [N]\n",
    "        inputs=centroids,      # shape [N,3]\n",
    "        grad_outputs=grad_outputs,\n",
    "        create_graph=True\n",
    "    )[0]  # → shape [N,3]\n",
    "\n",
    "    dVz_dcentroids = torch.autograd.grad(\n",
    "        outputs=Vz,    # shape [N]\n",
    "        inputs=centroids,      # shape [N,3]\n",
    "        grad_outputs=grad_outputs,\n",
    "        create_graph=True\n",
    "    )[0]  # → shape [N,3]\n",
    "\n",
    "    # Stack them into grad_v[e, i, j] = ∂v_i/∂x_j:\n",
    "    grad_v = torch.stack(\n",
    "        [dVx_dcentroids,    # [N,3] → (i=0)\n",
    "        dVy_dcentroids,    # [N,3] → (i=1)\n",
    "        dVz_dcentroids],   # [N,3] → (i=2)\n",
    "        dim=1               # new dim = “i”\n",
    "    )                      # → grad_v.shape = [N, 3, 3]\n",
    "\n",
    "    #Strain\n",
    "\n",
    "    virtual_strain=0.5*(grad_v+grad_v.transpose(1,2))\n",
    "\n",
    "    #Volume integral:\n",
    "    # element‐wise inner product σ^e : ∇v^e\n",
    "    integrand = torch.sum(sigma_full * virtual_strain, dim=(1, 2))  # → shape [N]\n",
    "\n",
    "    a_uv = torch.sum(integrand * vol)  # scalar\n",
    "\n",
    "    #Surface integral:\n",
    "\n",
    "    # 3) Build the traction vector T_surf = [0, 0, -1000] for each boundary element:\n",
    "    T_surf = torch.tensor([0.0, 0.0, -1000.0], device=centroids.device)  # [3]\n",
    "    T_surf = T_surf.view(1,3).expand(numElements, 3)  # → [nB, 3]\n",
    "\n",
    "    L_uv=torch.sum(T_surf*VF*0.01)\n",
    "\n",
    "    #Loss:\n",
    "    loss=a_uv-L_uv\n",
    "\n",
    "    if i%10==0:\n",
    "        print(f'Epoch {i} loss: {loss.item()}')\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virtual Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to revise the 1000 vs 99\n",
    "v_x_star1 = torch.zeros_like(centroids[:-1,0]) \n",
    "v_y_star1 = torch.zeros_like(centroids[:-1,0]) \n",
    "v_z_star1 = -centroids[:-1,2]\n",
    "\n",
    "\n",
    "virtual_displacement1 = torch.stack([v_x_star1, v_y_star1, v_z_star1], dim=1)  #torch.Size([Nodes, 2])\n",
    "\n",
    "zeros = torch.zeros_like(v_z_star1)\n",
    "minus_ones = -torch.ones_like(v_z_star1)\n",
    "\n",
    "gradient_virtual_displacement = torch.stack([\n",
    "    zeros, zeros, zeros,  # ∂v_x/∂x, ∂v_x/∂y, ∂v_x/∂z\n",
    "    zeros, zeros, zeros,  # ∂v_y/∂x, ∂v_y/∂y, ∂v_y/∂z\n",
    "    zeros, zeros, minus_ones  # ∂v_z/∂x, ∂v_z/∂y, ∂v_z/∂z\n",
    "], dim=1)  #shape: [Nodes, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([999, 9])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_virtual_displacement.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal Virtual Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{IVW}_k(\\mathcal{Q}, \\mathbf{v}^*) \n",
    "= V_k \\, \\xi^{*k}_{ij} \\, \\sigma^k_{ij}(\\mathcal{Q}) \n",
    "= V_k \\, \\xi^{*k}_{ij} \\left( \\frac{1}{J_k} P^k_{im} F^k_{jm} \\right)\n",
    "$$\n",
    "Where:\n",
    "* k is each element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([999, 3, 3])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_mat = torch.stack([\n",
    "    torch.stack([F_last[:,0:1], F_last[:,1:2],F_last[:,2:3]], dim=-1),\n",
    "    torch.stack([F_last[:,3:4], F_last[:,4:5],F_last[:,5:6]], dim=-1),\n",
    "    torch.stack([F_last[:,6:7], F_last[:,7:8],F_last[:,8:9]], dim=-1)\n",
    "], dim=-2).squeeze() #torch.Size([2752, 2, 2]) after squeeze \n",
    "P_mat=torch.zeros_like(F_mat)\n",
    "J = torch.det(F_mat)         # [nElem]\n",
    "F_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = (P_mat @ F_mat.transpose(-2,-1)) / J.view(-1,1,1) # [nElem,2,2]\n",
    "\n",
    "\n",
    "# --- flatten σᵢⱼ in the standard row‐major order [11,12,21,22] ---\n",
    "sigma_flat = sigma.view(-1,9)   # [nElem,9]\t\n",
    "F_mat_flat = F_mat.view(-1,9)   # [nElem,9]\t\n",
    "P_mat_flat = P_mat.view(-1,9)   # [nElem,9]\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([999])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate element IVF\n",
    "\n",
    "element_internal_IVF=vol.squeeze()*torch.sum(gradient_virtual_displacement*sigma_flat,dim=1)\n",
    "\n",
    "element_internal_IVF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_IVF=torch.sum(element_internal_IVF)\n",
    "total_IVF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External Virtual Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathrm{EVW}_k\\bigl(\\mathbf{v}^*\\bigr) \\;=\\; S^k \\, v^{*k}_{i} \\, \\tau_i^k\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate element EVF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #connectivity is a list of 3 1D-matrix. Each matrix contains integers.\n",
    "#Length of each matrix is equal to numElements. \n",
    "#For 2D-triangular elements with a={0,1,2}:\n",
    "#connectivity[a][e]: is the index of the 'a'-th node of the 'e'-th element.\n",
    "#Note that node indices range from 0 to (numNodes-1).\n",
    "# # Mapping from **elements to nodes**\n",
    "#f_int_nodes[:,i].index_add_(0,data.connectivity[a],force)\n",
    "#ewk[:,i].index_add_(0,data.connectivity[a],external_virtual_work)\n",
    "\n",
    "#From elements to nodes\n",
    "#force = P[:,voigt_map[i][j]] * data.gradNa[a][:,j] * data.qpWeights\n",
    "#f_int_nodes[:,i].index_add_(0,data.connectivity[a],force)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NNEUCLID",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
