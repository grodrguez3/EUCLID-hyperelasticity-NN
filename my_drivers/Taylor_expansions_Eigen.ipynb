{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo Virtual Fields: Neural Networks act as Taylor expansions to find optimal virtual fields via weak equilibrium minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_FEBIO import *\n",
    "from VF_helper import *\n",
    "from model import *\n",
    "from plot_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------\n",
      "Setting device to:  0\n",
      "Test:  cuda:0\n",
      "-----------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/feolalab/anaconda3/envs/NNEUCLID/lib/python3.9/site-packages/torch/__init__.py:747: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1712608883701/work/torch/csrc/tensor/python_tensor.cpp:431.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from core import *\n",
    "#config\n",
    "from config import *\n",
    "#CUDA\n",
    "cuda=0\n",
    "device=initCUDA(cuda)\n",
    "#supporting files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read FEBIO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>9</th>\n",
       "      <th>133</th>\n",
       "      <th>52</th>\n",
       "      <th>24</th>\n",
       "      <th>57</th>\n",
       "      <th>153</th>\n",
       "      <th>108</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>134</td>\n",
       "      <td>133</td>\n",
       "      <td>57</td>\n",
       "      <td>58</td>\n",
       "      <td>154</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>135</td>\n",
       "      <td>134</td>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "      <td>155</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>136</td>\n",
       "      <td>135</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>156</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>136</td>\n",
       "      <td>60</td>\n",
       "      <td>13</td>\n",
       "      <td>73</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>133</td>\n",
       "      <td>129</td>\n",
       "      <td>51</td>\n",
       "      <td>108</td>\n",
       "      <td>153</td>\n",
       "      <td>157</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>121</td>\n",
       "      <td>117</td>\n",
       "      <td>213</td>\n",
       "      <td>104</td>\n",
       "      <td>44</td>\n",
       "      <td>56</td>\n",
       "      <td>149</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>122</td>\n",
       "      <td>213</td>\n",
       "      <td>214</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>149</td>\n",
       "      <td>150</td>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>123</td>\n",
       "      <td>214</td>\n",
       "      <td>215</td>\n",
       "      <td>102</td>\n",
       "      <td>103</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>47</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>124</td>\n",
       "      <td>215</td>\n",
       "      <td>216</td>\n",
       "      <td>101</td>\n",
       "      <td>102</td>\n",
       "      <td>151</td>\n",
       "      <td>152</td>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>125</td>\n",
       "      <td>216</td>\n",
       "      <td>88</td>\n",
       "      <td>32</td>\n",
       "      <td>101</td>\n",
       "      <td>152</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1    1    9   133   52   24   57   153   108\n",
       "0      2    9   10   134  133   57   58   154   153\n",
       "1      3   10   11   135  134   58   59   155   154\n",
       "2      4   11   12   136  135   59   60   156   155\n",
       "3      5   12    2    25  136   60   13    73   156\n",
       "4      6   52  133   129   51  108  153   157   107\n",
       "..   ...  ...  ...   ...  ...  ...  ...   ...   ...\n",
       "119  121  117  213   104   44   56  149    45     8\n",
       "120  122  213  214   103  104  149  150    46    45\n",
       "121  123  214  215   102  103  150  151    47    46\n",
       "122  124  215  216   101  102  151  152    48    47\n",
       "123  125  216   88    32  101  152   33     7    48\n",
       "\n",
       "[124 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read connectivity\n",
    "connectivity = pd.read_csv(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube_Studio3/output_files/connectivity\")\n",
    "connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>9</th>\n",
       "      <th>57</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>133</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>58</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>133</td>\n",
       "      <td>134</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>59</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>146</td>\n",
       "      <td>101</td>\n",
       "      <td>102</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>147</td>\n",
       "      <td>151</td>\n",
       "      <td>152</td>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>148</td>\n",
       "      <td>88</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>149</td>\n",
       "      <td>32</td>\n",
       "      <td>101</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>150</td>\n",
       "      <td>152</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1    1    9   57   24\n",
       "0      2   52    1   24  108\n",
       "1      3   52  133    9    1\n",
       "2      4    9   10   58   57\n",
       "3      5  133  134   10    9\n",
       "4      6   10   11   59   58\n",
       "..   ...  ...  ...  ...  ...\n",
       "144  146  101  102   47   48\n",
       "145  147  151  152   48   47\n",
       "146  148   88   32    7   33\n",
       "147  149   32  101   48    7\n",
       "148  150  152   33    7   48\n",
       "\n",
       "[149 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read connectivity\n",
    "facet_connectivity = pd.read_csv(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube_Studio3/output_files/facet_connectivity\")\n",
    "facet_connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to read multiple states from FEBIO file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 1-field blocks → ['element']\n",
      "Number of states: 11\n",
      " State 1: element=125\n",
      " State 2: element=125\n",
      " State 3: element=125\n",
      " State 4: element=125\n",
      " State 5: element=125\n",
      " State 6: element=125\n",
      " State 7: element=125\n",
      " State 8: element=125\n",
      " State 9: element=125\n",
      " State 10: element=125\n",
      " State 11: element=125\n"
     ]
    }
   ],
   "source": [
    "volume_file=\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube_Studio3/output_files/volume\"\n",
    "volume=read_multi_ste_output2(volume_file,p=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 1-field blocks → ['element']\n",
      "Number of states: 11\n",
      " State 1: element=150\n",
      " State 2: element=150\n",
      " State 3: element=150\n",
      " State 4: element=150\n",
      " State 5: element=150\n",
      " State 6: element=150\n",
      " State 7: element=150\n",
      " State 8: element=150\n",
      " State 9: element=150\n",
      " State 10: element=150\n",
      " State 11: element=150\n"
     ]
    }
   ],
   "source": [
    "area_file=\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube_Studio3/output_files/facet_area\"\n",
    "area=read_multi_ste_output2(area_file,p=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 6-field blocks → ['xx', 'yy', 'zz', 'xy', 'yz', 'xz']\n",
      "Number of states: 11\n",
      " State 1: xx=125, yy=125, zz=125, xy=125, yz=125, xz=125\n",
      " State 2: xx=125, yy=125, zz=125, xy=125, yz=125, xz=125\n",
      " State 3: xx=125, yy=125, zz=125, xy=125, yz=125, xz=125\n",
      " State 4: xx=125, yy=125, zz=125, xy=125, yz=125, xz=125\n",
      " State 5: xx=125, yy=125, zz=125, xy=125, yz=125, xz=125\n",
      " State 6: xx=125, yy=125, zz=125, xy=125, yz=125, xz=125\n",
      " State 7: xx=125, yy=125, zz=125, xy=125, yz=125, xz=125\n",
      " State 8: xx=125, yy=125, zz=125, xy=125, yz=125, xz=125\n",
      " State 9: xx=125, yy=125, zz=125, xy=125, yz=125, xz=125\n",
      " State 10: xx=125, yy=125, zz=125, xy=125, yz=125, xz=125\n",
      " State 11: xx=125, yy=125, zz=125, xy=125, yz=125, xz=125\n"
     ]
    }
   ],
   "source": [
    "stress_file=\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube_Studio3/output_files/stress\"\n",
    "stress=read_multi_ste_output_VOIGT(stress_file,p=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Fxx=125, Fxy=125, Fxz=125, Fyx=125, Fyy=125, Fyz=125, Fzx=125, Fzy=125, Fzz=125\n",
      "Step 1: Fxx=125, Fxy=125, Fxz=125, Fyx=125, Fyy=125, Fyz=125, Fzx=125, Fzy=125, Fzz=125\n",
      "Step 2: Fxx=125, Fxy=125, Fxz=125, Fyx=125, Fyy=125, Fyz=125, Fzx=125, Fzy=125, Fzz=125\n",
      "Step 3: Fxx=125, Fxy=125, Fxz=125, Fyx=125, Fyy=125, Fyz=125, Fzx=125, Fzy=125, Fzz=125\n",
      "Step 4: Fxx=125, Fxy=125, Fxz=125, Fyx=125, Fyy=125, Fyz=125, Fzx=125, Fzy=125, Fzz=125\n",
      "Step 5: Fxx=125, Fxy=125, Fxz=125, Fyx=125, Fyy=125, Fyz=125, Fzx=125, Fzy=125, Fzz=125\n",
      "Step 6: Fxx=125, Fxy=125, Fxz=125, Fyx=125, Fyy=125, Fyz=125, Fzx=125, Fzy=125, Fzz=125\n",
      "Step 7: Fxx=125, Fxy=125, Fxz=125, Fyx=125, Fyy=125, Fyz=125, Fzx=125, Fzy=125, Fzz=125\n",
      "Step 8: Fxx=125, Fxy=125, Fxz=125, Fyx=125, Fyy=125, Fyz=125, Fzx=125, Fzy=125, Fzz=125\n",
      "Step 9: Fxx=125, Fxy=125, Fxz=125, Fyx=125, Fyy=125, Fyz=125, Fzx=125, Fzy=125, Fzz=125\n",
      "Step 10: Fxx=125, Fxy=125, Fxz=125, Fyx=125, Fyy=125, Fyz=125, Fzx=125, Fzy=125, Fzz=125\n"
     ]
    }
   ],
   "source": [
    "F_file=\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube_Studio3/jobs/deformation_tensor.txt\"\n",
    "F=read_multi_stepped_output_txt(F_file,p=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 3-field blocks → ['x', 'y', 'z']\n",
      "Number of states: 11\n",
      " State 1: x=150, y=150, z=150\n",
      " State 2: x=150, y=150, z=150\n",
      " State 3: x=150, y=150, z=150\n",
      " State 4: x=150, y=150, z=150\n",
      " State 5: x=150, y=150, z=150\n",
      " State 6: x=150, y=150, z=150\n",
      " State 7: x=150, y=150, z=150\n",
      " State 8: x=150, y=150, z=150\n",
      " State 9: x=150, y=150, z=150\n",
      " State 10: x=150, y=150, z=150\n",
      " State 11: x=150, y=150, z=150\n"
     ]
    }
   ],
   "source": [
    "surface_normal_file=\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube_Studio3/output_files/surface_normal\"\n",
    "surface_normal=read_multi_ste_output_VOIGT(surface_normal_file,p=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 3-field blocks → ['x', 'y', 'z']\n",
      "Number of states: 11\n",
      " State 1: x=216, y=216, z=216\n",
      " State 2: x=216, y=216, z=216\n",
      " State 3: x=216, y=216, z=216\n",
      " State 4: x=216, y=216, z=216\n",
      " State 5: x=216, y=216, z=216\n",
      " State 6: x=216, y=216, z=216\n",
      " State 7: x=216, y=216, z=216\n",
      " State 8: x=216, y=216, z=216\n",
      " State 9: x=216, y=216, z=216\n",
      " State 10: x=216, y=216, z=216\n",
      " State 11: x=216, y=216, z=216\n"
     ]
    }
   ],
   "source": [
    "position_file=\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube_Studio3/output_files/position\"\n",
    "position=read_multi_ste_output_VOIGT(position_file,p=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 6-field blocks → ['xx', 'yy', 'zz', 'xy', 'yz', 'xz']\n",
      "Number of states: 11\n",
      " State 1: xx=125, yy=125, zz=125, xy=125, yz=125, xz=125\n",
      " State 2: xx=125, yy=125, zz=125, xy=125, yz=125, xz=125\n",
      " State 3: xx=125, yy=125, zz=125, xy=125, yz=125, xz=125\n",
      " State 4: xx=125, yy=125, zz=125, xy=125, yz=125, xz=125\n",
      " State 5: xx=125, yy=125, zz=125, xy=125, yz=125, xz=125\n",
      " State 6: xx=125, yy=125, zz=125, xy=125, yz=125, xz=125\n",
      " State 7: xx=125, yy=125, zz=125, xy=125, yz=125, xz=125\n",
      " State 8: xx=125, yy=125, zz=125, xy=125, yz=125, xz=125\n",
      " State 9: xx=125, yy=125, zz=125, xy=125, yz=125, xz=125\n",
      " State 10: xx=125, yy=125, zz=125, xy=125, yz=125, xz=125\n",
      " State 11: xx=125, yy=125, zz=125, xy=125, yz=125, xz=125\n"
     ]
    }
   ],
   "source": [
    "strain_file=\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube_Studio3/output_files/lagrange_strain\"\n",
    "strain=read_multi_ste_output_VOIGT(strain_file,p=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log file data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: x=125, y=125, z=125\n",
      "Step 1: x=125, y=125, z=125\n",
      "Step 2: x=125, y=125, z=125\n",
      "Step 3: x=125, y=125, z=125\n",
      "Step 4: x=125, y=125, z=125\n",
      "Step 5: x=125, y=125, z=125\n",
      "Step 6: x=125, y=125, z=125\n",
      "Step 7: x=125, y=125, z=125\n",
      "Step 8: x=125, y=125, z=125\n",
      "Step 9: x=125, y=125, z=125\n",
      "Step 10: x=125, y=125, z=125\n"
     ]
    }
   ],
   "source": [
    "centroids_file=\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube_Studio3/jobs/centroids.txt\"\n",
    "centroids_dict=read_multi_stepped_output_txt(centroids_file,p=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Centroids from log file\n",
    "#centroids_file='/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube_Studio3/jobs/Model1.log'\n",
    "#centroids_dict  = parse_states(centroids_file)\n",
    "\n",
    "#Should get 11 states, each with exactly 1000 x/y/z values:\n",
    "#print(\"states found:\", sorted(centroids_dict.keys()))\n",
    "#for step, d in centroids_dict.items():\n",
    "    #print(f\" step {step:2d}: x={len(d['x'])} pts, y={len(d['y'])}, z={len(d['z'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State dict to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centroids_tensor.shape: torch.Size([125, 3, 11])\n",
      "stress_tensor.shape: torch.Size([125, 6, 11])\n",
      "volume_tensor.shape: torch.Size([125, 1, 11])\n",
      "F_tensor.shape: torch.Size([125, 9, 11])\n",
      "surface_normal_tensor.shape: torch.Size([150, 3, 11])\n",
      "area_tensor.shape: torch.Size([150, 1, 11])\n",
      "strain_tensor.shape: torch.Size([125, 6, 11])\n",
      "strain_tensor.shape: torch.Size([216, 3, 11])\n"
     ]
    }
   ],
   "source": [
    "# 1) Build a (Nelements,3,nstates) tensor for centroids:\n",
    "centroids_tensor = states_to_tensor(centroids_dict, ['x','y','z'])\n",
    "print(\"centroids_tensor.shape:\", centroids_tensor.shape)\n",
    "# → (Nelements, 3, nstates)\n",
    "\n",
    "# 2) Build a (Nelements,6,nstates) tensor for volume‐stress:\n",
    "stress_tensor = states_to_tensor(stress,\n",
    "                                ['xx','yy','zz','xy','xz','yz'])\n",
    "print(\"stress_tensor.shape:\", stress_tensor.shape)\n",
    "# → (Nelements, 6, nstates)\n",
    "\n",
    "# 3) If you just want the x‐only channel across states:\n",
    "#x_only = states_to_tensor(centroids_dict, ['x'])\n",
    "#print(\"x_only.shape:\", x_only.shape)\n",
    "# → (Nelements, 1, nstates)\n",
    "\n",
    "# 3) Volume:\n",
    "volume_tensor = states_to_tensor(volume, ['element'])\n",
    "print(\"volume_tensor.shape:\", volume_tensor.shape)\n",
    "# → (Nelements, 1, nstates)\n",
    "\n",
    "# 4) Deformation tensor:\n",
    "F_tensor = states_to_tensor(F, ['Fxx','Fxy','Fxz','Fyx','Fyy','Fyz','Fzx','Fzy','Fzz'])\n",
    "print(\"F_tensor.shape:\", F_tensor.shape)\n",
    "\n",
    "# 4) Surface Normal:\n",
    "surface_normal_tensor = states_to_tensor(surface_normal, ['x','y','z'])\n",
    "print(\"surface_normal_tensor.shape:\", surface_normal_tensor.shape)\n",
    "\n",
    "\n",
    "# 5) Area:\n",
    "area_tensor = states_to_tensor(area, ['element'])\n",
    "print(\"area_tensor.shape:\", area_tensor.shape)\n",
    "\n",
    "\n",
    "# 6) Strain:\n",
    "#del strain[1]\n",
    "strain_tensor = states_to_tensor(strain, ['xx','yy','zz','xy','xz','yz'])\n",
    "print(\"strain_tensor.shape:\", strain_tensor.shape)\n",
    "\n",
    "position_tensor = states_to_tensor(position, ['x','y','z'])\n",
    "print(\"strain_tensor.shape:\", position_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000, -1.0000, -0.0076], dtype=torch.float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surface_normal_tensor[0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strain_tensor.shape: torch.Size([216, 3, 11])\n"
     ]
    }
   ],
   "source": [
    "position_tensor = states_to_tensor(position, ['x','y','z'])\n",
    "print(\"strain_tensor.shape:\", position_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(87.5000, dtype=torch.float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(centroids_tensor[:,:,0], dim=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nelements=F_tensor.shape[0]\n",
    "Nelements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triple Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class convexLinear(torch.nn.Module):\n",
    "\t\"\"\"\n",
    "\n",
    "\tCustom linear layer with positive weights and no bias\n",
    "\n",
    "\tInit:\tsize_in, size_out\n",
    "\tInputs: input data\n",
    "\tOutput: input data times softplus(trainable weight)\n",
    "\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, size_in, size_out, ):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.size_in, self.size_out = size_in, size_out\n",
    "\t\tweights = torch.Tensor(size_out, size_in)\n",
    "\t\tself.weights = torch.nn.Parameter(weights)\n",
    "\n",
    "\t\t# initialize weights\n",
    "\t\ttorch.nn.init.kaiming_uniform_(self.weights, a=np.math.sqrt(5))\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tw_times_x= torch.mm(x, torch.nn.functional.softplus(self.weights.t()))\n",
    "\t\treturn w_times_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBranch(nn.Module):\n",
    "    \"\"\"\n",
    "    A single branch with per‐layer skip connections:\n",
    "      x_input --[Linear or convexLinear]--> z\n",
    "       for each layer i:\n",
    "          z = softplus(  branch_i(z) + skip_i(x_input)  )\n",
    "    \"\"\"\n",
    "    def __init__(self, n_input, n_hidden, use_dropout=False, p_dropout=0.1):\n",
    "        super().__init__()\n",
    "        depth = len(n_hidden)\n",
    "        self.layers      = nn.ModuleDict()\n",
    "        self.skip_layers = nn.ModuleDict()\n",
    "        self.depth       = depth\n",
    "        self.use_dp      = use_dropout\n",
    "        self.dp_rate     = p_dropout\n",
    "\n",
    "        # layer 0: full input → first hidden\n",
    "        self.layers[\"0\"]      = nn.Linear(n_input, n_hidden[0])\n",
    "        #self.skip_layers[\"0\"] = nn.Identity()\n",
    "\n",
    "        # hidden → hidden with convexLinear + softplus + skip\n",
    "        for i in range(1, depth):\n",
    "            self.layers[str(i)]      = convexLinear(n_hidden[i-1], n_hidden[i])\n",
    "            self.skip_layers[str(i)] = nn.Linear(n_input, n_hidden[i])\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x0 = x                   # keep the original input for all skips\n",
    "        z  = self.layers[\"0\"](x0)\n",
    "        z  = F.softplus(z)\n",
    "        if self.use_dp and self.training:\n",
    "            z = F.dropout(z, p=self.dp_rate)\n",
    "\n",
    "        for i in range(1, self.depth):\n",
    "            skip = self.skip_layers[str(i)](x0)\n",
    "            h    = self.layers[str(i)](z)\n",
    "            z    = F.softplus(h + skip)\n",
    "            if self.use_dp and self.training:\n",
    "                z = F.dropout(z, p=self.dp_rate)\n",
    "        #y = self.layers[str(self.depth)](z) + self.skip_layers[str(self.depth)](x0)\n",
    "\n",
    "        return z  # shape [batch, n_hidden[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICNN3D_WithResidualBranches(nn.Module):\n",
    "    def __init__(self,\n",
    "                 branch_input_dim: int = 3,\n",
    "                 branch_hidden:    list[int] = [64,64],\n",
    "                 n_coeffs:         int = 30,\n",
    "                 n_fields:         int = 2,\n",
    "                 use_dropout:      bool = False,\n",
    "                 p_dropout:        float = 0.1):\n",
    "        super().__init__()\n",
    "        B0, B1 = branch_hidden\n",
    "        B_last = branch_hidden[-1]\n",
    "        K      = n_fields\n",
    "        C      = n_coeffs\n",
    "\n",
    "        # two residual‐skip branches\n",
    "        self.branch1 = ResidualBranch(branch_input_dim, branch_hidden,\n",
    "                                      use_dropout, p_dropout)\n",
    "        \n",
    "        self.branch2 = ResidualBranch(branch_input_dim, branch_hidden,\n",
    "                                      use_dropout, p_dropout)\n",
    "\n",
    "        # trunk: fuse 2×B_last → K·C\n",
    "        fuse_dim =  B1\n",
    "        self.trunk = nn.Sequential(\n",
    "            convexLinear(fuse_dim, fuse_dim),\n",
    "            nn.Softplus(),\n",
    "            convexLinear(fuse_dim, K*C)\n",
    "        )\n",
    "\n",
    "        # K independent heads (simple linear → allow neg/pos coeffs)\n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Linear(C, C, bias=True)\n",
    "            for _ in range(K)\n",
    "        ])\n",
    "\n",
    "        self.K = K\n",
    "        self.C = C\n",
    "\n",
    "    def forward(self, inv, cent):\n",
    "        \"\"\"\n",
    "        inv : [Ne, 3]   → branch1\n",
    "        cent: [Ne, 3]   → branch2\n",
    "        returns: [Ne, K, C]\n",
    "        \"\"\"\n",
    "        b1 = self.branch1(inv)               # [Ne, B_last]\n",
    "        b2 = self.branch2(cent)              # [Ne, B_last]\n",
    "        \n",
    "        fuse = b1*b2 #torch.cat([b1, b2], dim=1)    # [Ne, B_last]\n",
    "        flat = self.trunk(fuse)              # [Ne, K·C]\n",
    "\n",
    "        # reshape to [Ne, K, C]\n",
    "        flatK = flat.view(-1, self.K, self.C)\n",
    "        outs  = []\n",
    "        for k, head in enumerate(self.heads):\n",
    "            vk = flatK[:, k, :]              # [Ne, C]\n",
    "            outs.append(head(vk))            # [Ne, C]\n",
    "\n",
    "        return torch.stack(outs, dim=1)      # [Ne, K, C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([125, 2])\n"
     ]
    }
   ],
   "source": [
    "Ne = 125\n",
    "model = ICNN3D_WithResidualBranches(\n",
    "    branch_input_dim=3,\n",
    "    branch_hidden=[32,32],\n",
    "    n_coeffs=30,\n",
    "    n_fields=2,\n",
    "    use_dropout=True,\n",
    "    p_dropout=0.1\n",
    ").float().to(device)\n",
    "\n",
    "\n",
    "invariants1 = torch.randn(Ne, 3).float().to(device)\n",
    "centroids1  = torch.randn(Ne, 3).float().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer                          | Input Shape     → Output Shape\n",
      "------------------------------------------------------------\n",
      "Linear                         | torch.Size([125, 3]) → torch.Size([125, 32])\n",
      "Linear                         | torch.Size([125, 3]) → torch.Size([125, 32])\n",
      "convexLinear                   | torch.Size([125, 32]) → torch.Size([125, 32])\n",
      "Linear                         | torch.Size([125, 3]) → torch.Size([125, 32])\n",
      "Linear                         | torch.Size([125, 3]) → torch.Size([125, 32])\n",
      "convexLinear                   | torch.Size([125, 32]) → torch.Size([125, 32])\n",
      "convexLinear                   | torch.Size([125, 32]) → torch.Size([125, 32])\n",
      "Softplus                       | torch.Size([125, 32]) → torch.Size([125, 32])\n",
      "convexLinear                   | torch.Size([125, 32]) → torch.Size([125, 60])\n",
      "Linear                         | torch.Size([125, 30]) → torch.Size([125, 30])\n",
      "Linear                         | torch.Size([125, 30]) → torch.Size([125, 30])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ── 2) Create dummy inputs matching your real shapes ──────────────────\n",
    "Ne = 125\n",
    "dummy_inv  = torch.zeros(Ne, 3).float().to(device)  # invariants\n",
    "dummy_cent = torch.zeros(Ne, 3).float().to(device)    # centroids\n",
    "\n",
    "# ── 3) Install hooks to record shapes ─────────────────────────────────\n",
    "shapes = {}\n",
    "hooks = []\n",
    "def hook_fn(module, inp, out):\n",
    "    # record only leaf modules (no children)\n",
    "    if not list(module.children()):\n",
    "        shapes[module] = (inp[0].shape, out.shape)\n",
    "\n",
    "for m in model.modules():\n",
    "    hooks.append(m.register_forward_hook(hook_fn))\n",
    "\n",
    "# ── 4) Run a single forward pass ──────────────────────────────────────\n",
    "_ = model(dummy_inv, dummy_cent)\n",
    "\n",
    "# ── 5) Remove hooks and print ─────────────────────────────────────────\n",
    "for h in hooks:\n",
    "    h.remove()\n",
    "\n",
    "print(f\"{'Layer':30s} | {'Input Shape':15s} → {'Output Shape'}\")\n",
    "print(\"-\"* 60)\n",
    "for module, (in_sh, out_sh) in shapes.items():\n",
    "    print(f\"{module.__class__.__name__:30s} | {str(in_sh):15s} → {out_sh}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([125, 3, 11]), torch.Size([125, 3, 11]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invariants=transform_to_invariants(F_tensor)\n",
    "invariants.shape, centroids_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ICNN3D_MultiHead(branch_hidden=[32,32], n_coeffs=30, n_fields=2).float().to(device)\n",
    "#out   = model(invariants[:,:,0], centroids_tensor[:,:,0])     # → [125, 2, 30]\n",
    "#print(out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where pressure is applied and Zero Displacement Boundary Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure_nodes = parse_quad4_from_feb(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube_Studio3/jobs/Model1.feb\", surface_name=\"Pressure1\")\n",
    "pressure_node_ids = list(pressure_nodes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5, 20, 137, 53], dict)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pressure_nodes[1], type(pressure_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ZD_nodes = parse_quad4_from_feb(\"/home/feolalab/Desktop/EUCLID-hyperelasticity-NN/my_data/Cube_Studio3/jobs/Model1.feb\", surface_name=\"ZeroDisplacement1\")\n",
    "ZD_node_ids = list(ZD_nodes.keys())\n",
    "ZD_idx = torch.tensor([nid - 1 for nid in ZD_node_ids], dtype=torch.long)\n",
    "ZD_idx[:10], ZD_node_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4, 40, 121, 49], 25)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ZD_nodes[1], len(ZD_node_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "connectivity_list = [\n",
    "    tuple(map(int, row))           # ensure ints\n",
    "    for row in connectivity.values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element 101:\n",
      "  all_nodes:      [21, 69, 201, 120, 5, 20, 137, 53]\n",
      "  pressure_nodes: [5, 20, 137, 53]\n",
      "Element 102:\n",
      "  all_nodes:      [69, 70, 202, 201, 20, 19, 138, 137]\n",
      "  pressure_nodes: [20, 19, 138, 137]\n",
      "Element 103:\n",
      "  all_nodes:      [70, 71, 203, 202, 19, 18, 139, 138]\n",
      "  pressure_nodes: [19, 18, 139, 138]\n",
      "Element 104:\n",
      "  all_nodes:      [71, 72, 204, 203, 18, 17, 140, 139]\n",
      "  pressure_nodes: [18, 17, 140, 139]\n",
      "Element 105:\n",
      "  all_nodes:      [72, 16, 85, 204, 17, 6, 36, 140]\n",
      "  pressure_nodes: [17, 6, 36, 140]\n",
      "Element 106:\n",
      "  all_nodes:      [120, 201, 205, 119, 53, 137, 141, 54]\n",
      "  pressure_nodes: [53, 137, 141, 54]\n",
      "Element 107:\n",
      "  all_nodes:      [201, 202, 206, 205, 137, 138, 142, 141]\n",
      "  pressure_nodes: [137, 138, 142, 141]\n",
      "Element 108:\n",
      "  all_nodes:      [202, 203, 207, 206, 138, 139, 143, 142]\n",
      "  pressure_nodes: [138, 139, 143, 142]\n",
      "Element 109:\n",
      "  all_nodes:      [203, 204, 208, 207, 139, 140, 144, 143]\n",
      "  pressure_nodes: [139, 140, 144, 143]\n",
      "Element 110:\n",
      "  all_nodes:      [204, 85, 86, 208, 140, 36, 35, 144]\n",
      "  pressure_nodes: [140, 36, 35, 144]\n",
      "Element 111:\n",
      "  all_nodes:      [119, 205, 209, 118, 54, 141, 145, 55]\n",
      "  pressure_nodes: [54, 141, 145, 55]\n",
      "Element 112:\n",
      "  all_nodes:      [205, 206, 210, 209, 141, 142, 146, 145]\n",
      "  pressure_nodes: [141, 142, 146, 145]\n",
      "Element 113:\n",
      "  all_nodes:      [206, 207, 211, 210, 142, 143, 147, 146]\n",
      "  pressure_nodes: [142, 143, 147, 146]\n",
      "Element 114:\n",
      "  all_nodes:      [207, 208, 212, 211, 143, 144, 148, 147]\n",
      "  pressure_nodes: [143, 144, 148, 147]\n",
      "Element 115:\n",
      "  all_nodes:      [208, 86, 87, 212, 144, 35, 34, 148]\n",
      "  pressure_nodes: [144, 35, 34, 148]\n",
      "Element 116:\n",
      "  all_nodes:      [118, 209, 213, 117, 55, 145, 149, 56]\n",
      "  pressure_nodes: [55, 145, 149, 56]\n",
      "Element 117:\n",
      "  all_nodes:      [209, 210, 214, 213, 145, 146, 150, 149]\n",
      "  pressure_nodes: [145, 146, 150, 149]\n",
      "Element 118:\n",
      "  all_nodes:      [210, 211, 215, 214, 146, 147, 151, 150]\n",
      "  pressure_nodes: [146, 147, 151, 150]\n",
      "Element 119:\n",
      "  all_nodes:      [211, 212, 216, 215, 147, 148, 152, 151]\n",
      "  pressure_nodes: [147, 148, 152, 151]\n",
      "Element 120:\n",
      "  all_nodes:      [212, 87, 88, 216, 148, 34, 33, 152]\n",
      "  pressure_nodes: [148, 34, 33, 152]\n",
      "Element 121:\n",
      "  all_nodes:      [117, 213, 104, 44, 56, 149, 45, 8]\n",
      "  pressure_nodes: [56, 149, 45, 8]\n",
      "Element 122:\n",
      "  all_nodes:      [213, 214, 103, 104, 149, 150, 46, 45]\n",
      "  pressure_nodes: [149, 150, 46, 45]\n",
      "Element 123:\n",
      "  all_nodes:      [214, 215, 102, 103, 150, 151, 47, 46]\n",
      "  pressure_nodes: [150, 151, 47, 46]\n",
      "Element 124:\n",
      "  all_nodes:      [215, 216, 101, 102, 151, 152, 48, 47]\n",
      "  pressure_nodes: [151, 152, 48, 47]\n",
      "Element 125:\n",
      "  all_nodes:      [216, 88, 32, 101, 152, 33, 7, 48]\n",
      "  pressure_nodes: [152, 33, 7, 48]\n"
     ]
    }
   ],
   "source": [
    "# 2) Flatten pressure-node dict into a set of node IDs\n",
    "pressure_nodes_set = {\n",
    "    n\n",
    "    for nodes in pressure_nodes.values()\n",
    "    for n in nodes\n",
    "}\n",
    "\n",
    "mapping_element_pressure = map_pressure_to_elements(connectivity_list, pressure_nodes_set)\n",
    "#print(mapping.keys())\n",
    "# (3) inspect\n",
    "for eid, info in mapping_element_pressure.items():\n",
    "    print(f\"Element {eid}:\")\n",
    "    print(\"  all_nodes:     \", info['all_nodes'])\n",
    "    print(\"  pressure_nodes:\", info['pressure_nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element 2:\n",
      "  all_nodes:      [9, 10, 134, 133, 57, 58, 154, 153]\n",
      "  pressure_nodes: [9, 10, 134, 133]\n",
      "Element 3:\n",
      "  all_nodes:      [10, 11, 135, 134, 58, 59, 155, 154]\n",
      "  pressure_nodes: [10, 11, 135, 134]\n",
      "Element 4:\n",
      "  all_nodes:      [11, 12, 136, 135, 59, 60, 156, 155]\n",
      "  pressure_nodes: [11, 12, 136, 135]\n",
      "Element 5:\n",
      "  all_nodes:      [12, 2, 25, 136, 60, 13, 73, 156]\n",
      "  pressure_nodes: [12, 2, 25, 136]\n",
      "Element 6:\n",
      "  all_nodes:      [52, 133, 129, 51, 108, 153, 157, 107]\n",
      "  pressure_nodes: [52, 133, 129, 51]\n",
      "Element 7:\n",
      "  all_nodes:      [133, 134, 130, 129, 153, 154, 158, 157]\n",
      "  pressure_nodes: [133, 134, 130, 129]\n",
      "Element 8:\n",
      "  all_nodes:      [134, 135, 131, 130, 154, 155, 159, 158]\n",
      "  pressure_nodes: [134, 135, 131, 130]\n",
      "Element 9:\n",
      "  all_nodes:      [135, 136, 132, 131, 155, 156, 160, 159]\n",
      "  pressure_nodes: [135, 136, 132, 131]\n",
      "Element 10:\n",
      "  all_nodes:      [136, 25, 26, 132, 156, 73, 74, 160]\n",
      "  pressure_nodes: [136, 25, 26, 132]\n",
      "Element 11:\n",
      "  all_nodes:      [51, 129, 125, 50, 107, 157, 161, 106]\n",
      "  pressure_nodes: [51, 129, 125, 50]\n",
      "Element 12:\n",
      "  all_nodes:      [129, 130, 126, 125, 157, 158, 162, 161]\n",
      "  pressure_nodes: [129, 130, 126, 125]\n",
      "Element 13:\n",
      "  all_nodes:      [130, 131, 127, 126, 158, 159, 163, 162]\n",
      "  pressure_nodes: [130, 131, 127, 126]\n",
      "Element 14:\n",
      "  all_nodes:      [131, 132, 128, 127, 159, 160, 164, 163]\n",
      "  pressure_nodes: [131, 132, 128, 127]\n",
      "Element 15:\n",
      "  all_nodes:      [132, 26, 27, 128, 160, 74, 75, 164]\n",
      "  pressure_nodes: [132, 26, 27, 128]\n",
      "Element 16:\n",
      "  all_nodes:      [50, 125, 121, 49, 106, 161, 165, 105]\n",
      "  pressure_nodes: [50, 125, 121, 49]\n",
      "Element 17:\n",
      "  all_nodes:      [125, 126, 122, 121, 161, 162, 166, 165]\n",
      "  pressure_nodes: [125, 126, 122, 121]\n",
      "Element 18:\n",
      "  all_nodes:      [126, 127, 123, 122, 162, 163, 167, 166]\n",
      "  pressure_nodes: [126, 127, 123, 122]\n",
      "Element 19:\n",
      "  all_nodes:      [127, 128, 124, 123, 163, 164, 168, 167]\n",
      "  pressure_nodes: [127, 128, 124, 123]\n",
      "Element 20:\n",
      "  all_nodes:      [128, 27, 28, 124, 164, 75, 76, 168]\n",
      "  pressure_nodes: [128, 27, 28, 124]\n",
      "Element 21:\n",
      "  all_nodes:      [49, 121, 40, 4, 105, 165, 92, 41]\n",
      "  pressure_nodes: [49, 121, 40, 4]\n",
      "Element 22:\n",
      "  all_nodes:      [121, 122, 39, 40, 165, 166, 91, 92]\n",
      "  pressure_nodes: [121, 122, 39, 40]\n",
      "Element 23:\n",
      "  all_nodes:      [122, 123, 38, 39, 166, 167, 90, 91]\n",
      "  pressure_nodes: [122, 123, 38, 39]\n",
      "Element 24:\n",
      "  all_nodes:      [123, 124, 37, 38, 167, 168, 89, 90]\n",
      "  pressure_nodes: [123, 124, 37, 38]\n",
      "Element 25:\n",
      "  all_nodes:      [124, 28, 3, 37, 168, 76, 29, 89]\n",
      "  pressure_nodes: [124, 28, 3, 37]\n"
     ]
    }
   ],
   "source": [
    "# 2) Flatten pressure-node dict into a set of node IDs\n",
    "ZD_nodes_set = {\n",
    "    n\n",
    "    for nodes in ZD_nodes.values()\n",
    "    for n in nodes\n",
    "}\n",
    "\n",
    "mapping_element_ZD = map_pressure_to_elements(connectivity_list, ZD_nodes_set)\n",
    "#print(mapping.keys())\n",
    "# (3) inspect\n",
    "for eid, info in mapping_element_ZD.items():\n",
    "    print(f\"Element {eid}:\")\n",
    "    print(\"  all_nodes:     \", info['all_nodes'])\n",
    "    print(\"  pressure_nodes:\", info['pressure_nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure_element_IDs=list(mapping_element_pressure.keys())\n",
    "\n",
    "pressure_element_IDs_final = torch.tensor([nid - 1 for nid in pressure_element_IDs], dtype=torch.long)\n",
    "\n",
    "#len(pressure_element_IDs_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZD_element_IDs=list(mapping_element_ZD.keys())\n",
    "\n",
    "ZD_element_IDs_final = torch.tensor([nid - 1 for nid in ZD_element_IDs], dtype=torch.long)\n",
    "\n",
    "#len(pressure_element_IDs_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "        19, 20, 21, 22, 23, 24])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ZD_element_IDs_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 3, 11])\n",
      "torch.Size([25, 3, 11])\n"
     ]
    }
   ],
   "source": [
    "#Get normals of surfaces where pressure is applied\n",
    "# 1) zero‐based indices for those nodes:\n",
    "idx = torch.tensor([nid - 1 for nid in pressure_node_ids], dtype=torch.long)\n",
    "idx_ZD = torch.tensor([nid - 1 for nid in ZD_node_ids], dtype=torch.long)\n",
    "\n",
    "# 2) index into the first dimension:\n",
    "#    result has shape (100, 3, 11)\n",
    "pressure_normals = surface_normal_tensor[idx, :, :]\n",
    "area_normals = area_tensor[idx, :, :]\n",
    "\n",
    "#ZD:\n",
    "ZD_normals = surface_normal_tensor[idx_ZD, :, :]\n",
    "ZD_areas = area_tensor[idx_ZD, :, :]\n",
    "\n",
    "\n",
    "print(pressure_normals.shape)  # → torch.Size([100, 3, 11])\n",
    "print(ZD_normals.shape)  # → torch.Size([100, 3, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max idx = 124\n",
      "min idx = 100\n"
     ]
    }
   ],
   "source": [
    "#print(\"VF.shape =\", VF.shape)\n",
    "print(\"max idx =\", max(pressure_element_IDs_final).item())\n",
    "print(\"min idx =\", min(pressure_element_IDs_final).item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surface Normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([150, 3, 11])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surface_normal_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet_connectivity_list = [\n",
    "    tuple(map(int, row))           # ensure ints\n",
    "    for row in facet_connectivity.values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 52, 1, 24, 108),\n",
       " (3, 52, 133, 9, 1),\n",
       " (4, 9, 10, 58, 57),\n",
       " (5, 133, 134, 10, 9),\n",
       " (6, 10, 11, 59, 58),\n",
       " (7, 134, 135, 11, 10),\n",
       " (8, 11, 12, 60, 59),\n",
       " (9, 135, 136, 12, 11),\n",
       " (10, 12, 2, 13, 60),\n",
       " (11, 2, 25, 73, 13),\n",
       " (12, 136, 25, 2, 12),\n",
       " (13, 51, 52, 108, 107),\n",
       " (14, 51, 129, 133, 52),\n",
       " (15, 129, 130, 134, 133),\n",
       " (16, 130, 131, 135, 134),\n",
       " (17, 131, 132, 136, 135),\n",
       " (18, 25, 26, 74, 73),\n",
       " (19, 132, 26, 25, 136),\n",
       " (20, 50, 51, 107, 106),\n",
       " (21, 50, 125, 129, 51),\n",
       " (22, 125, 126, 130, 129),\n",
       " (23, 126, 127, 131, 130),\n",
       " (24, 127, 128, 132, 131),\n",
       " (25, 26, 27, 75, 74),\n",
       " (26, 128, 27, 26, 132),\n",
       " (27, 49, 50, 106, 105),\n",
       " (28, 49, 121, 125, 50),\n",
       " (29, 121, 122, 126, 125),\n",
       " (30, 122, 123, 127, 126),\n",
       " (31, 123, 124, 128, 127),\n",
       " (32, 27, 28, 76, 75),\n",
       " (33, 124, 28, 27, 128),\n",
       " (34, 40, 4, 41, 92),\n",
       " (35, 4, 49, 105, 41),\n",
       " (36, 4, 40, 121, 49),\n",
       " (37, 39, 40, 92, 91),\n",
       " (38, 40, 39, 122, 121),\n",
       " (39, 38, 39, 91, 90),\n",
       " (40, 39, 38, 123, 122),\n",
       " (41, 37, 38, 90, 89),\n",
       " (42, 38, 37, 124, 123),\n",
       " (43, 28, 3, 29, 76),\n",
       " (44, 3, 37, 89, 29),\n",
       " (45, 37, 3, 28, 124),\n",
       " (46, 24, 57, 61, 23),\n",
       " (47, 108, 24, 23, 112),\n",
       " (48, 57, 58, 62, 61),\n",
       " (49, 58, 59, 63, 62),\n",
       " (50, 59, 60, 64, 63),\n",
       " (51, 60, 13, 14, 64),\n",
       " (52, 13, 73, 77, 14),\n",
       " (53, 107, 108, 112, 111),\n",
       " (54, 73, 74, 78, 77),\n",
       " (55, 106, 107, 111, 110),\n",
       " (56, 74, 75, 79, 78),\n",
       " (57, 105, 106, 110, 109),\n",
       " (58, 75, 76, 80, 79),\n",
       " (59, 92, 41, 42, 96),\n",
       " (60, 41, 105, 109, 42),\n",
       " (61, 91, 92, 96, 95),\n",
       " (62, 90, 91, 95, 94),\n",
       " (63, 89, 90, 94, 93),\n",
       " (64, 76, 29, 30, 80),\n",
       " (65, 29, 89, 93, 30),\n",
       " (66, 23, 61, 65, 22),\n",
       " (67, 112, 23, 22, 116),\n",
       " (68, 61, 62, 66, 65),\n",
       " (69, 62, 63, 67, 66),\n",
       " (70, 63, 64, 68, 67),\n",
       " (71, 64, 14, 15, 68),\n",
       " (72, 14, 77, 81, 15),\n",
       " (73, 111, 112, 116, 115),\n",
       " (74, 77, 78, 82, 81),\n",
       " (75, 110, 111, 115, 114),\n",
       " (76, 78, 79, 83, 82),\n",
       " (77, 109, 110, 114, 113),\n",
       " (78, 79, 80, 84, 83),\n",
       " (79, 96, 42, 43, 100),\n",
       " (80, 42, 109, 113, 43),\n",
       " (81, 95, 96, 100, 99),\n",
       " (82, 94, 95, 99, 98),\n",
       " (83, 93, 94, 98, 97),\n",
       " (84, 80, 30, 31, 84),\n",
       " (85, 30, 93, 97, 31),\n",
       " (86, 22, 65, 69, 21),\n",
       " (87, 116, 22, 21, 120),\n",
       " (88, 65, 66, 70, 69),\n",
       " (89, 66, 67, 71, 70),\n",
       " (90, 67, 68, 72, 71),\n",
       " (91, 68, 15, 16, 72),\n",
       " (92, 15, 81, 85, 16),\n",
       " (93, 115, 116, 120, 119),\n",
       " (94, 81, 82, 86, 85),\n",
       " (95, 114, 115, 119, 118),\n",
       " (96, 82, 83, 87, 86),\n",
       " (97, 113, 114, 118, 117),\n",
       " (98, 83, 84, 88, 87),\n",
       " (99, 100, 43, 44, 104),\n",
       " (100, 43, 113, 117, 44),\n",
       " (101, 99, 100, 104, 103),\n",
       " (102, 98, 99, 103, 102),\n",
       " (103, 97, 98, 102, 101),\n",
       " (104, 84, 31, 32, 88),\n",
       " (105, 31, 97, 101, 32),\n",
       " (106, 21, 69, 20, 5),\n",
       " (107, 120, 21, 5, 53),\n",
       " (108, 5, 20, 137, 53),\n",
       " (109, 69, 70, 19, 20),\n",
       " (110, 20, 19, 138, 137),\n",
       " (111, 70, 71, 18, 19),\n",
       " (112, 19, 18, 139, 138),\n",
       " (113, 71, 72, 17, 18),\n",
       " (114, 18, 17, 140, 139),\n",
       " (115, 72, 16, 6, 17),\n",
       " (116, 16, 85, 36, 6),\n",
       " (117, 17, 6, 36, 140),\n",
       " (118, 119, 120, 53, 54),\n",
       " (119, 53, 137, 141, 54),\n",
       " (120, 137, 138, 142, 141),\n",
       " (121, 138, 139, 143, 142),\n",
       " (122, 139, 140, 144, 143),\n",
       " (123, 85, 86, 35, 36),\n",
       " (124, 140, 36, 35, 144),\n",
       " (125, 118, 119, 54, 55),\n",
       " (126, 54, 141, 145, 55),\n",
       " (127, 141, 142, 146, 145),\n",
       " (128, 142, 143, 147, 146),\n",
       " (129, 143, 144, 148, 147),\n",
       " (130, 86, 87, 34, 35),\n",
       " (131, 144, 35, 34, 148),\n",
       " (132, 117, 118, 55, 56),\n",
       " (133, 55, 145, 149, 56),\n",
       " (134, 145, 146, 150, 149),\n",
       " (135, 146, 147, 151, 150),\n",
       " (136, 147, 148, 152, 151),\n",
       " (137, 87, 88, 33, 34),\n",
       " (138, 148, 34, 33, 152),\n",
       " (139, 104, 44, 8, 45),\n",
       " (140, 44, 117, 56, 8),\n",
       " (141, 56, 149, 45, 8),\n",
       " (142, 103, 104, 45, 46),\n",
       " (143, 149, 150, 46, 45),\n",
       " (144, 102, 103, 46, 47),\n",
       " (145, 150, 151, 47, 46),\n",
       " (146, 101, 102, 47, 48),\n",
       " (147, 151, 152, 48, 47),\n",
       " (148, 88, 32, 7, 33),\n",
       " (149, 32, 101, 48, 7),\n",
       " (150, 152, 33, 7, 48)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facet_connectivity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facet 4 with nodes [9, 10, 58, 57] → elements [2]\n",
      "Facet 5 with nodes [133, 134, 10, 9] → elements [2]\n",
      "Facet 6 with nodes [10, 11, 59, 58] → elements [3]\n",
      "Facet 7 with nodes [134, 135, 11, 10] → elements [3]\n",
      "Facet 8 with nodes [11, 12, 60, 59] → elements [4]\n",
      "Facet 9 with nodes [135, 136, 12, 11] → elements [4]\n",
      "Facet 10 with nodes [12, 2, 13, 60] → elements [5]\n",
      "Facet 11 with nodes [2, 25, 73, 13] → elements [5]\n",
      "Facet 12 with nodes [136, 25, 2, 12] → elements [5]\n",
      "Facet 13 with nodes [51, 52, 108, 107] → elements [6]\n",
      "Facet 14 with nodes [51, 129, 133, 52] → elements [6]\n",
      "Facet 15 with nodes [129, 130, 134, 133] → elements [7]\n",
      "Facet 16 with nodes [130, 131, 135, 134] → elements [8]\n",
      "Facet 17 with nodes [131, 132, 136, 135] → elements [9]\n",
      "Facet 18 with nodes [25, 26, 74, 73] → elements [10]\n",
      "Facet 19 with nodes [132, 26, 25, 136] → elements [10]\n",
      "Facet 20 with nodes [50, 51, 107, 106] → elements [11]\n",
      "Facet 21 with nodes [50, 125, 129, 51] → elements [11]\n",
      "Facet 22 with nodes [125, 126, 130, 129] → elements [12]\n",
      "Facet 23 with nodes [126, 127, 131, 130] → elements [13]\n",
      "Facet 24 with nodes [127, 128, 132, 131] → elements [14]\n",
      "Facet 25 with nodes [26, 27, 75, 74] → elements [15]\n",
      "Facet 26 with nodes [128, 27, 26, 132] → elements [15]\n",
      "Facet 27 with nodes [49, 50, 106, 105] → elements [16]\n",
      "Facet 28 with nodes [49, 121, 125, 50] → elements [16]\n",
      "Facet 29 with nodes [121, 122, 126, 125] → elements [17]\n",
      "Facet 30 with nodes [122, 123, 127, 126] → elements [18]\n",
      "Facet 31 with nodes [123, 124, 128, 127] → elements [19]\n",
      "Facet 32 with nodes [27, 28, 76, 75] → elements [20]\n",
      "Facet 33 with nodes [124, 28, 27, 128] → elements [20]\n",
      "Facet 34 with nodes [40, 4, 41, 92] → elements [21]\n",
      "Facet 35 with nodes [4, 49, 105, 41] → elements [21]\n",
      "Facet 36 with nodes [4, 40, 121, 49] → elements [21]\n",
      "Facet 37 with nodes [39, 40, 92, 91] → elements [22]\n",
      "Facet 38 with nodes [40, 39, 122, 121] → elements [22]\n",
      "Facet 39 with nodes [38, 39, 91, 90] → elements [23]\n",
      "Facet 40 with nodes [39, 38, 123, 122] → elements [23]\n",
      "Facet 41 with nodes [37, 38, 90, 89] → elements [24]\n",
      "Facet 42 with nodes [38, 37, 124, 123] → elements [24]\n",
      "Facet 43 with nodes [28, 3, 29, 76] → elements [25]\n",
      "Facet 44 with nodes [3, 37, 89, 29] → elements [25]\n",
      "Facet 45 with nodes [37, 3, 28, 124] → elements [25]\n",
      "Facet 46 with nodes [24, 57, 61, 23] → elements [26]\n",
      "Facet 47 with nodes [108, 24, 23, 112] → elements [26]\n",
      "Facet 48 with nodes [57, 58, 62, 61] → elements [27]\n",
      "Facet 49 with nodes [58, 59, 63, 62] → elements [28]\n",
      "Facet 50 with nodes [59, 60, 64, 63] → elements [29]\n",
      "Facet 51 with nodes [60, 13, 14, 64] → elements [30]\n",
      "Facet 52 with nodes [13, 73, 77, 14] → elements [30]\n",
      "Facet 53 with nodes [107, 108, 112, 111] → elements [31]\n",
      "Facet 54 with nodes [73, 74, 78, 77] → elements [35]\n",
      "Facet 55 with nodes [106, 107, 111, 110] → elements [36]\n",
      "Facet 56 with nodes [74, 75, 79, 78] → elements [40]\n",
      "Facet 57 with nodes [105, 106, 110, 109] → elements [41]\n",
      "Facet 58 with nodes [75, 76, 80, 79] → elements [45]\n",
      "Facet 59 with nodes [92, 41, 42, 96] → elements [46]\n",
      "Facet 60 with nodes [41, 105, 109, 42] → elements [46]\n",
      "Facet 61 with nodes [91, 92, 96, 95] → elements [47]\n",
      "Facet 62 with nodes [90, 91, 95, 94] → elements [48]\n",
      "Facet 63 with nodes [89, 90, 94, 93] → elements [49]\n",
      "Facet 64 with nodes [76, 29, 30, 80] → elements [50]\n",
      "Facet 65 with nodes [29, 89, 93, 30] → elements [50]\n",
      "Facet 66 with nodes [23, 61, 65, 22] → elements [51]\n",
      "Facet 67 with nodes [112, 23, 22, 116] → elements [51]\n",
      "Facet 68 with nodes [61, 62, 66, 65] → elements [52]\n",
      "Facet 69 with nodes [62, 63, 67, 66] → elements [53]\n",
      "Facet 70 with nodes [63, 64, 68, 67] → elements [54]\n",
      "Facet 71 with nodes [64, 14, 15, 68] → elements [55]\n",
      "Facet 72 with nodes [14, 77, 81, 15] → elements [55]\n",
      "Facet 73 with nodes [111, 112, 116, 115] → elements [56]\n",
      "Facet 74 with nodes [77, 78, 82, 81] → elements [60]\n",
      "Facet 75 with nodes [110, 111, 115, 114] → elements [61]\n",
      "Facet 76 with nodes [78, 79, 83, 82] → elements [65]\n",
      "Facet 77 with nodes [109, 110, 114, 113] → elements [66]\n",
      "Facet 78 with nodes [79, 80, 84, 83] → elements [70]\n",
      "Facet 79 with nodes [96, 42, 43, 100] → elements [71]\n",
      "Facet 80 with nodes [42, 109, 113, 43] → elements [71]\n",
      "Facet 81 with nodes [95, 96, 100, 99] → elements [72]\n",
      "Facet 82 with nodes [94, 95, 99, 98] → elements [73]\n",
      "Facet 83 with nodes [93, 94, 98, 97] → elements [74]\n",
      "Facet 84 with nodes [80, 30, 31, 84] → elements [75]\n",
      "Facet 85 with nodes [30, 93, 97, 31] → elements [75]\n",
      "Facet 86 with nodes [22, 65, 69, 21] → elements [76]\n",
      "Facet 87 with nodes [116, 22, 21, 120] → elements [76]\n",
      "Facet 88 with nodes [65, 66, 70, 69] → elements [77]\n",
      "Facet 89 with nodes [66, 67, 71, 70] → elements [78]\n",
      "Facet 90 with nodes [67, 68, 72, 71] → elements [79]\n",
      "Facet 91 with nodes [68, 15, 16, 72] → elements [80]\n",
      "Facet 92 with nodes [15, 81, 85, 16] → elements [80]\n",
      "Facet 93 with nodes [115, 116, 120, 119] → elements [81]\n",
      "Facet 94 with nodes [81, 82, 86, 85] → elements [85]\n",
      "Facet 95 with nodes [114, 115, 119, 118] → elements [86]\n",
      "Facet 96 with nodes [82, 83, 87, 86] → elements [90]\n",
      "Facet 97 with nodes [113, 114, 118, 117] → elements [91]\n",
      "Facet 98 with nodes [83, 84, 88, 87] → elements [95]\n",
      "Facet 99 with nodes [100, 43, 44, 104] → elements [96]\n",
      "Facet 100 with nodes [43, 113, 117, 44] → elements [96]\n",
      "Facet 101 with nodes [99, 100, 104, 103] → elements [97]\n",
      "Facet 102 with nodes [98, 99, 103, 102] → elements [98]\n",
      "Facet 103 with nodes [97, 98, 102, 101] → elements [99]\n",
      "Facet 104 with nodes [84, 31, 32, 88] → elements [100]\n",
      "Facet 105 with nodes [31, 97, 101, 32] → elements [100]\n",
      "Facet 106 with nodes [21, 69, 20, 5] → elements [101]\n",
      "Facet 107 with nodes [120, 21, 5, 53] → elements [101]\n",
      "Facet 108 with nodes [5, 20, 137, 53] → elements [101]\n",
      "Facet 109 with nodes [69, 70, 19, 20] → elements [102]\n",
      "Facet 110 with nodes [20, 19, 138, 137] → elements [102]\n",
      "Facet 111 with nodes [70, 71, 18, 19] → elements [103]\n",
      "Facet 112 with nodes [19, 18, 139, 138] → elements [103]\n",
      "Facet 113 with nodes [71, 72, 17, 18] → elements [104]\n",
      "Facet 114 with nodes [18, 17, 140, 139] → elements [104]\n",
      "Facet 115 with nodes [72, 16, 6, 17] → elements [105]\n",
      "Facet 116 with nodes [16, 85, 36, 6] → elements [105]\n",
      "Facet 117 with nodes [17, 6, 36, 140] → elements [105]\n",
      "Facet 118 with nodes [119, 120, 53, 54] → elements [106]\n",
      "Facet 119 with nodes [53, 137, 141, 54] → elements [106]\n",
      "Facet 120 with nodes [137, 138, 142, 141] → elements [107]\n",
      "Facet 121 with nodes [138, 139, 143, 142] → elements [108]\n",
      "Facet 122 with nodes [139, 140, 144, 143] → elements [109]\n",
      "Facet 123 with nodes [85, 86, 35, 36] → elements [110]\n",
      "Facet 124 with nodes [140, 36, 35, 144] → elements [110]\n",
      "Facet 125 with nodes [118, 119, 54, 55] → elements [111]\n",
      "Facet 126 with nodes [54, 141, 145, 55] → elements [111]\n",
      "Facet 127 with nodes [141, 142, 146, 145] → elements [112]\n",
      "Facet 128 with nodes [142, 143, 147, 146] → elements [113]\n",
      "Facet 129 with nodes [143, 144, 148, 147] → elements [114]\n",
      "Facet 130 with nodes [86, 87, 34, 35] → elements [115]\n",
      "Facet 131 with nodes [144, 35, 34, 148] → elements [115]\n",
      "Facet 132 with nodes [117, 118, 55, 56] → elements [116]\n",
      "Facet 133 with nodes [55, 145, 149, 56] → elements [116]\n",
      "Facet 134 with nodes [145, 146, 150, 149] → elements [117]\n",
      "Facet 135 with nodes [146, 147, 151, 150] → elements [118]\n",
      "Facet 136 with nodes [147, 148, 152, 151] → elements [119]\n",
      "Facet 137 with nodes [87, 88, 33, 34] → elements [120]\n",
      "Facet 138 with nodes [148, 34, 33, 152] → elements [120]\n",
      "Facet 139 with nodes [104, 44, 8, 45] → elements [121]\n",
      "Facet 140 with nodes [44, 117, 56, 8] → elements [121]\n",
      "Facet 141 with nodes [56, 149, 45, 8] → elements [121]\n",
      "Facet 142 with nodes [103, 104, 45, 46] → elements [122]\n",
      "Facet 143 with nodes [149, 150, 46, 45] → elements [122]\n",
      "Facet 144 with nodes [102, 103, 46, 47] → elements [123]\n",
      "Facet 145 with nodes [150, 151, 47, 46] → elements [123]\n",
      "Facet 146 with nodes [101, 102, 47, 48] → elements [124]\n",
      "Facet 147 with nodes [151, 152, 48, 47] → elements [124]\n",
      "Facet 148 with nodes [88, 32, 7, 33] → elements [125]\n",
      "Facet 149 with nodes [32, 101, 48, 7] → elements [125]\n",
      "Facet 150 with nodes [152, 33, 7, 48] → elements [125]\n"
     ]
    }
   ],
   "source": [
    "facet2elems = map_facets_to_elements(connectivity_list, facet_connectivity_list)\n",
    "for fid, info in facet2elems.items():\n",
    "    print(f\"Facet {fid} with nodes {info['facet_nodes']} → elements {info['element_ids']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: [4, 5],\n",
       " 3: [6, 7],\n",
       " 4: [8, 9],\n",
       " 5: [10, 11, 12],\n",
       " 6: [13, 14],\n",
       " 7: [15],\n",
       " 8: [16],\n",
       " 9: [17],\n",
       " 10: [18, 19],\n",
       " 11: [20, 21],\n",
       " 12: [22],\n",
       " 13: [23],\n",
       " 14: [24],\n",
       " 15: [25, 26],\n",
       " 16: [27, 28],\n",
       " 17: [29],\n",
       " 18: [30],\n",
       " 19: [31],\n",
       " 20: [32, 33],\n",
       " 21: [34, 35, 36],\n",
       " 22: [37, 38],\n",
       " 23: [39, 40],\n",
       " 24: [41, 42],\n",
       " 25: [43, 44, 45],\n",
       " 26: [46, 47],\n",
       " 27: [48],\n",
       " 28: [49],\n",
       " 29: [50],\n",
       " 30: [51, 52],\n",
       " 31: [53],\n",
       " 35: [54],\n",
       " 36: [55],\n",
       " 40: [56],\n",
       " 41: [57],\n",
       " 45: [58],\n",
       " 46: [59, 60],\n",
       " 47: [61],\n",
       " 48: [62],\n",
       " 49: [63],\n",
       " 50: [64, 65],\n",
       " 51: [66, 67],\n",
       " 52: [68],\n",
       " 53: [69],\n",
       " 54: [70],\n",
       " 55: [71, 72],\n",
       " 56: [73],\n",
       " 60: [74],\n",
       " 61: [75],\n",
       " 65: [76],\n",
       " 66: [77],\n",
       " 70: [78],\n",
       " 71: [79, 80],\n",
       " 72: [81],\n",
       " 73: [82],\n",
       " 74: [83],\n",
       " 75: [84, 85],\n",
       " 76: [86, 87],\n",
       " 77: [88],\n",
       " 78: [89],\n",
       " 79: [90],\n",
       " 80: [91, 92],\n",
       " 81: [93],\n",
       " 85: [94],\n",
       " 86: [95],\n",
       " 90: [96],\n",
       " 91: [97],\n",
       " 95: [98],\n",
       " 96: [99, 100],\n",
       " 97: [101],\n",
       " 98: [102],\n",
       " 99: [103],\n",
       " 100: [104, 105],\n",
       " 101: [106, 107, 108],\n",
       " 102: [109, 110],\n",
       " 103: [111, 112],\n",
       " 104: [113, 114],\n",
       " 105: [115, 116, 117],\n",
       " 106: [118, 119],\n",
       " 107: [120],\n",
       " 108: [121],\n",
       " 109: [122],\n",
       " 110: [123, 124],\n",
       " 111: [125, 126],\n",
       " 112: [127],\n",
       " 113: [128],\n",
       " 114: [129],\n",
       " 115: [130, 131],\n",
       " 116: [132, 133],\n",
       " 117: [134],\n",
       " 118: [135],\n",
       " 119: [136],\n",
       " 120: [137, 138],\n",
       " 121: [139, 140, 141],\n",
       " 122: [142, 143],\n",
       " 123: [144, 145],\n",
       " 124: [146, 147],\n",
       " 125: [148, 149, 150]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element2facets = {}\n",
    "for facet_id, info in facet2elems.items():\n",
    "    for eid in info['element_ids']:\n",
    "        element2facets.setdefault(eid, []).append(facet_id) \n",
    "element2facets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125,\n",
       " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eid, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) select only the pressured elements\n",
    "pressure_elements_facets = {\n",
    "    eid-1: element2facets[eid] #minus one to account for python indexing\n",
    "    for eid in pressure_element_IDs\n",
    "    if eid in element2facets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element 101:\n",
      "  all_nodes:       [21, 69, 201, 120, 5, 20, 137, 53]\n",
      "  pressure_nodes:  [5, 20, 137, 53]\n",
      "  facet_ids:       [108]\n",
      "Element 102:\n",
      "  all_nodes:       [69, 70, 202, 201, 20, 19, 138, 137]\n",
      "  pressure_nodes:  [20, 19, 138, 137]\n",
      "  facet_ids:       [110]\n",
      "Element 103:\n",
      "  all_nodes:       [70, 71, 203, 202, 19, 18, 139, 138]\n",
      "  pressure_nodes:  [19, 18, 139, 138]\n",
      "  facet_ids:       [112]\n",
      "Element 104:\n",
      "  all_nodes:       [71, 72, 204, 203, 18, 17, 140, 139]\n",
      "  pressure_nodes:  [18, 17, 140, 139]\n",
      "  facet_ids:       [114]\n",
      "Element 105:\n",
      "  all_nodes:       [72, 16, 85, 204, 17, 6, 36, 140]\n",
      "  pressure_nodes:  [17, 6, 36, 140]\n",
      "  facet_ids:       [117]\n",
      "Element 106:\n",
      "  all_nodes:       [120, 201, 205, 119, 53, 137, 141, 54]\n",
      "  pressure_nodes:  [53, 137, 141, 54]\n",
      "  facet_ids:       [119]\n",
      "Element 107:\n",
      "  all_nodes:       [201, 202, 206, 205, 137, 138, 142, 141]\n",
      "  pressure_nodes:  [137, 138, 142, 141]\n",
      "  facet_ids:       [120]\n",
      "Element 108:\n",
      "  all_nodes:       [202, 203, 207, 206, 138, 139, 143, 142]\n",
      "  pressure_nodes:  [138, 139, 143, 142]\n",
      "  facet_ids:       [121]\n",
      "Element 109:\n",
      "  all_nodes:       [203, 204, 208, 207, 139, 140, 144, 143]\n",
      "  pressure_nodes:  [139, 140, 144, 143]\n",
      "  facet_ids:       [122]\n",
      "Element 110:\n",
      "  all_nodes:       [204, 85, 86, 208, 140, 36, 35, 144]\n",
      "  pressure_nodes:  [140, 36, 35, 144]\n",
      "  facet_ids:       [124]\n",
      "Element 111:\n",
      "  all_nodes:       [119, 205, 209, 118, 54, 141, 145, 55]\n",
      "  pressure_nodes:  [54, 141, 145, 55]\n",
      "  facet_ids:       [126]\n",
      "Element 112:\n",
      "  all_nodes:       [205, 206, 210, 209, 141, 142, 146, 145]\n",
      "  pressure_nodes:  [141, 142, 146, 145]\n",
      "  facet_ids:       [127]\n",
      "Element 113:\n",
      "  all_nodes:       [206, 207, 211, 210, 142, 143, 147, 146]\n",
      "  pressure_nodes:  [142, 143, 147, 146]\n",
      "  facet_ids:       [128]\n",
      "Element 114:\n",
      "  all_nodes:       [207, 208, 212, 211, 143, 144, 148, 147]\n",
      "  pressure_nodes:  [143, 144, 148, 147]\n",
      "  facet_ids:       [129]\n",
      "Element 115:\n",
      "  all_nodes:       [208, 86, 87, 212, 144, 35, 34, 148]\n",
      "  pressure_nodes:  [144, 35, 34, 148]\n",
      "  facet_ids:       [131]\n",
      "Element 116:\n",
      "  all_nodes:       [118, 209, 213, 117, 55, 145, 149, 56]\n",
      "  pressure_nodes:  [55, 145, 149, 56]\n",
      "  facet_ids:       [133]\n",
      "Element 117:\n",
      "  all_nodes:       [209, 210, 214, 213, 145, 146, 150, 149]\n",
      "  pressure_nodes:  [145, 146, 150, 149]\n",
      "  facet_ids:       [134]\n",
      "Element 118:\n",
      "  all_nodes:       [210, 211, 215, 214, 146, 147, 151, 150]\n",
      "  pressure_nodes:  [146, 147, 151, 150]\n",
      "  facet_ids:       [135]\n",
      "Element 119:\n",
      "  all_nodes:       [211, 212, 216, 215, 147, 148, 152, 151]\n",
      "  pressure_nodes:  [147, 148, 152, 151]\n",
      "  facet_ids:       [136]\n",
      "Element 120:\n",
      "  all_nodes:       [212, 87, 88, 216, 148, 34, 33, 152]\n",
      "  pressure_nodes:  [148, 34, 33, 152]\n",
      "  facet_ids:       [138]\n",
      "Element 121:\n",
      "  all_nodes:       [117, 213, 104, 44, 56, 149, 45, 8]\n",
      "  pressure_nodes:  [56, 149, 45, 8]\n",
      "  facet_ids:       [141]\n",
      "Element 122:\n",
      "  all_nodes:       [213, 214, 103, 104, 149, 150, 46, 45]\n",
      "  pressure_nodes:  [149, 150, 46, 45]\n",
      "  facet_ids:       [143]\n",
      "Element 123:\n",
      "  all_nodes:       [214, 215, 102, 103, 150, 151, 47, 46]\n",
      "  pressure_nodes:  [150, 151, 47, 46]\n",
      "  facet_ids:       [145]\n",
      "Element 124:\n",
      "  all_nodes:       [215, 216, 101, 102, 151, 152, 48, 47]\n",
      "  pressure_nodes:  [151, 152, 48, 47]\n",
      "  facet_ids:       [147]\n",
      "Element 125:\n",
      "  all_nodes:       [216, 88, 32, 101, 152, 33, 7, 48]\n",
      "  pressure_nodes:  [152, 33, 7, 48]\n",
      "  facet_ids:       [150]\n"
     ]
    }
   ],
   "source": [
    "for eid, info in mapping_element_pressure.items():\n",
    "    pset = set(info['pressure_nodes'])\n",
    "    # find the facet(s) whose node-set exactly matches the pressure nodes\n",
    "    facet_ids = [\n",
    "        fid\n",
    "        for fid, n1, n2, n3, n4 in facet_connectivity_list\n",
    "        if set((n1, n2, n3, n4)) == pset\n",
    "    ]\n",
    "    info['facet_ids'] = facet_ids\n",
    "\n",
    "# inspect\n",
    "for eid, info in mapping_element_pressure.items():\n",
    "    print(f\"Element {eid}:\")\n",
    "    print(\"  all_nodes:      \", info['all_nodes'])\n",
    "    print(\"  pressure_nodes: \", info['pressure_nodes'])\n",
    "    print(\"  facet_ids:      \", info.get('facet_ids', []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element 2:\n",
      "  all_nodes:       [9, 10, 134, 133, 57, 58, 154, 153]\n",
      "  pressure_nodes:  [9, 10, 134, 133]\n",
      "  facet_ids:       [5]\n",
      "Element 3:\n",
      "  all_nodes:       [10, 11, 135, 134, 58, 59, 155, 154]\n",
      "  pressure_nodes:  [10, 11, 135, 134]\n",
      "  facet_ids:       [7]\n",
      "Element 4:\n",
      "  all_nodes:       [11, 12, 136, 135, 59, 60, 156, 155]\n",
      "  pressure_nodes:  [11, 12, 136, 135]\n",
      "  facet_ids:       [9]\n",
      "Element 5:\n",
      "  all_nodes:       [12, 2, 25, 136, 60, 13, 73, 156]\n",
      "  pressure_nodes:  [12, 2, 25, 136]\n",
      "  facet_ids:       [12]\n",
      "Element 6:\n",
      "  all_nodes:       [52, 133, 129, 51, 108, 153, 157, 107]\n",
      "  pressure_nodes:  [52, 133, 129, 51]\n",
      "  facet_ids:       [14]\n",
      "Element 7:\n",
      "  all_nodes:       [133, 134, 130, 129, 153, 154, 158, 157]\n",
      "  pressure_nodes:  [133, 134, 130, 129]\n",
      "  facet_ids:       [15]\n",
      "Element 8:\n",
      "  all_nodes:       [134, 135, 131, 130, 154, 155, 159, 158]\n",
      "  pressure_nodes:  [134, 135, 131, 130]\n",
      "  facet_ids:       [16]\n",
      "Element 9:\n",
      "  all_nodes:       [135, 136, 132, 131, 155, 156, 160, 159]\n",
      "  pressure_nodes:  [135, 136, 132, 131]\n",
      "  facet_ids:       [17]\n",
      "Element 10:\n",
      "  all_nodes:       [136, 25, 26, 132, 156, 73, 74, 160]\n",
      "  pressure_nodes:  [136, 25, 26, 132]\n",
      "  facet_ids:       [19]\n",
      "Element 11:\n",
      "  all_nodes:       [51, 129, 125, 50, 107, 157, 161, 106]\n",
      "  pressure_nodes:  [51, 129, 125, 50]\n",
      "  facet_ids:       [21]\n",
      "Element 12:\n",
      "  all_nodes:       [129, 130, 126, 125, 157, 158, 162, 161]\n",
      "  pressure_nodes:  [129, 130, 126, 125]\n",
      "  facet_ids:       [22]\n",
      "Element 13:\n",
      "  all_nodes:       [130, 131, 127, 126, 158, 159, 163, 162]\n",
      "  pressure_nodes:  [130, 131, 127, 126]\n",
      "  facet_ids:       [23]\n",
      "Element 14:\n",
      "  all_nodes:       [131, 132, 128, 127, 159, 160, 164, 163]\n",
      "  pressure_nodes:  [131, 132, 128, 127]\n",
      "  facet_ids:       [24]\n",
      "Element 15:\n",
      "  all_nodes:       [132, 26, 27, 128, 160, 74, 75, 164]\n",
      "  pressure_nodes:  [132, 26, 27, 128]\n",
      "  facet_ids:       [26]\n",
      "Element 16:\n",
      "  all_nodes:       [50, 125, 121, 49, 106, 161, 165, 105]\n",
      "  pressure_nodes:  [50, 125, 121, 49]\n",
      "  facet_ids:       [28]\n",
      "Element 17:\n",
      "  all_nodes:       [125, 126, 122, 121, 161, 162, 166, 165]\n",
      "  pressure_nodes:  [125, 126, 122, 121]\n",
      "  facet_ids:       [29]\n",
      "Element 18:\n",
      "  all_nodes:       [126, 127, 123, 122, 162, 163, 167, 166]\n",
      "  pressure_nodes:  [126, 127, 123, 122]\n",
      "  facet_ids:       [30]\n",
      "Element 19:\n",
      "  all_nodes:       [127, 128, 124, 123, 163, 164, 168, 167]\n",
      "  pressure_nodes:  [127, 128, 124, 123]\n",
      "  facet_ids:       [31]\n",
      "Element 20:\n",
      "  all_nodes:       [128, 27, 28, 124, 164, 75, 76, 168]\n",
      "  pressure_nodes:  [128, 27, 28, 124]\n",
      "  facet_ids:       [33]\n",
      "Element 21:\n",
      "  all_nodes:       [49, 121, 40, 4, 105, 165, 92, 41]\n",
      "  pressure_nodes:  [49, 121, 40, 4]\n",
      "  facet_ids:       [36]\n",
      "Element 22:\n",
      "  all_nodes:       [121, 122, 39, 40, 165, 166, 91, 92]\n",
      "  pressure_nodes:  [121, 122, 39, 40]\n",
      "  facet_ids:       [38]\n",
      "Element 23:\n",
      "  all_nodes:       [122, 123, 38, 39, 166, 167, 90, 91]\n",
      "  pressure_nodes:  [122, 123, 38, 39]\n",
      "  facet_ids:       [40]\n",
      "Element 24:\n",
      "  all_nodes:       [123, 124, 37, 38, 167, 168, 89, 90]\n",
      "  pressure_nodes:  [123, 124, 37, 38]\n",
      "  facet_ids:       [42]\n",
      "Element 25:\n",
      "  all_nodes:       [124, 28, 3, 37, 168, 76, 29, 89]\n",
      "  pressure_nodes:  [124, 28, 3, 37]\n",
      "  facet_ids:       [45]\n"
     ]
    }
   ],
   "source": [
    "for eid, info in mapping_element_ZD.items():\n",
    "    pset = set(info['pressure_nodes'])\n",
    "    # find the facet(s) whose node-set exactly matches the pressure nodes\n",
    "    facet_ids = [\n",
    "        fid\n",
    "        for fid, n1, n2, n3, n4 in facet_connectivity_list\n",
    "        if set((n1, n2, n3, n4)) == pset\n",
    "    ]\n",
    "    info['facet_ids'] = facet_ids\n",
    "\n",
    "# inspect\n",
    "for eid, info in mapping_element_ZD.items():\n",
    "    print(f\"Element {eid}:\")\n",
    "    print(\"  all_nodes:      \", info['all_nodes'])\n",
    "    print(\"  pressure_nodes: \", info['pressure_nodes'])\n",
    "    print(\"  facet_ids:      \", info.get('facet_ids', []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 107)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pressure_elem_facets_indexes = [\n",
    "    (eid-1, fid-1)\n",
    "    for eid, info in mapping_element_pressure.items()\n",
    "    for fid in info.get('facet_ids', [])\n",
    "]\n",
    "pressure_elem_facets_indexes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ZD_elem_facets_indexes = [\n",
    "    (eid-1, fid-1)\n",
    "    for eid, info in mapping_element_ZD.items()\n",
    "    for fid in info.get('facet_ids', [])\n",
    "]\n",
    "ZD_elem_facets_indexes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Extract index lists\n",
    "elem_idxs  = torch.tensor([e for e, f in pressure_elem_facets_indexes], dtype=torch.long)\n",
    "facet_idxs = torch.tensor([f for e, f in pressure_elem_facets_indexes], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Extract index lists\n",
    "ZD_elem_idxs  = torch.tensor([e for e, f in ZD_elem_facets_indexes], dtype=torch.long)\n",
    "ZD_facet_idxs = torch.tensor([f for e, f in ZD_elem_facets_indexes], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
       "         114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124]),\n",
       " tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "         19, 20, 21, 22, 23, 24]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elem_idxs, ZD_elem_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([107, 109, 111, 113, 116, 118, 119, 120, 121, 123, 125, 126, 127, 128,\n",
       "        130, 132, 133, 134, 135, 137, 140, 142, 144, 146, 149])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facet_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "\n",
    "vf_number=2 #linear elastic is 2 parameters\n",
    "model = Taylor_with_heads(n_input=3,\n",
    "                n_hidden=[128,128,128],\n",
    "                n_output=30,\n",
    "                use_dropout=True,\n",
    "                dropout_rate=0.2,\n",
    "                centroids=False, p_fields=vf_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from model import *\n",
    "\n",
    "vf_number=2 #linear elastic is 2 parameters\n",
    "model = ICNN3D_Taylor_multifield_with_neg(n_input=3,\n",
    "                n_hidden=[128,128,128],\n",
    "                n_output=30,\n",
    "                use_dropout=True,\n",
    "                dropout_rate=0.2,\n",
    "                centroids=True, p_fields=vf_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ICNN3D_WithResidualBranches              --\n",
       "├─ResidualBranch: 1-1                    --\n",
       "│    └─ModuleDict: 2-1                   --\n",
       "│    │    └─Linear: 3-1                  256\n",
       "│    │    └─convexLinear: 3-2            4,096\n",
       "│    │    └─convexLinear: 3-3            64\n",
       "│    └─ModuleDict: 2-2                   --\n",
       "│    │    └─Linear: 3-4                  256\n",
       "│    │    └─convexLinear: 3-5            3\n",
       "├─ResidualBranch: 1-2                    --\n",
       "│    └─ModuleDict: 2-3                   --\n",
       "│    │    └─Linear: 3-6                  256\n",
       "│    │    └─convexLinear: 3-7            4,096\n",
       "│    │    └─convexLinear: 3-8            64\n",
       "│    └─ModuleDict: 2-4                   --\n",
       "│    │    └─Linear: 3-9                  256\n",
       "│    │    └─convexLinear: 3-10           3\n",
       "├─Sequential: 1-3                        --\n",
       "│    └─convexLinear: 2-5                 4,096\n",
       "│    └─Softplus: 2-6                     --\n",
       "│    └─convexLinear: 2-7                 3,840\n",
       "├─ModuleList: 1-4                        --\n",
       "│    └─Linear: 2-8                       930\n",
       "│    └─Linear: 2-9                       930\n",
       "=================================================================\n",
       "Total params: 19,146\n",
       "Trainable params: 19,146\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "model = model.to(device)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([125, 9, 11]), torch.Size([125, 6, 11]), torch.Size([125, 3, 11]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_tensor.shape, stress_tensor.shape, centroids_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([125, 9, 11])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input= torch.cat(( F_tensor.to(device),centroids_tensor.to(device)), dim=1)\n",
    "x_input= F_tensor.to(device)\n",
    "x_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V2\n",
      "V2\n"
     ]
    }
   ],
   "source": [
    "stress_tensor_3d=Voigt_to_3d_v2(stress_tensor)\n",
    "strain_tensor_3d=Voigt_to_3d_v2(strain_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ICNN3D_WithResidualBranches(\n",
       "  (branch1): ResidualBranch(\n",
       "    (layers): ModuleDict(\n",
       "      (0): Linear(in_features=3, out_features=32, bias=True)\n",
       "      (1): convexLinear()\n",
       "    )\n",
       "    (skip_layers): ModuleDict(\n",
       "      (1): Linear(in_features=3, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (branch2): ResidualBranch(\n",
       "    (layers): ModuleDict(\n",
       "      (0): Linear(in_features=3, out_features=32, bias=True)\n",
       "      (1): convexLinear()\n",
       "    )\n",
       "    (skip_layers): ModuleDict(\n",
       "      (1): Linear(in_features=3, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (trunk): Sequential(\n",
       "    (0): convexLinear()\n",
       "    (1): Softplus(beta=1.0, threshold=20.0)\n",
       "    (2): convexLinear()\n",
       "  )\n",
       "  (heads): ModuleList(\n",
       "    (0-1): 2 x Linear(in_features=30, out_features=30, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "If we keep the strain pointwise throughout the solid we can get a map of parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PER ELEMENT....\n",
    "epoch=500\n",
    "# Adam with a learning rate:\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "#Number of states:\n",
    "\n",
    "states=F_tensor.shape[2]\n",
    "N_pressure_dofs=len(pressure_element_IDs_final)\n",
    "N_ZD_dofs=len(ZD_element_IDs_final)\n",
    "loss_list=[]\n",
    "keys = ['Internal', 'External', 'ZD','Special']\n",
    "work_dict = { key: [] for key in keys }\n",
    "P_max  = 100000.0            # negative = compression\n",
    "# make a “linear ramp” of 11 pressures from 0 → P_max\n",
    "pressure_curve = torch.linspace(0.0, P_max, steps=states, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triple branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0 │ W_int (internal work): -2.75e+10 │ W_ext (external work): -1.22e+11 │ Loss:  3.06e+11\n",
      "Epoch   50 │ W_int (internal work): -7.48e+09 │ W_ext (external work): -7.28e+09 │ Loss:  3.07e+06\n",
      "Epoch  100 │ W_int (internal work):  1.86e+07 │ W_ext (external work): -9.59e+07 │ Loss:  4.57e+05\n",
      "Epoch  150 │ W_int (internal work): -7.68e+06 │ W_ext (external work): -3.92e+06 │ Loss:  5.15e+02\n",
      "Epoch  200 │ W_int (internal work):  2.62e+06 │ W_ext (external work):  6.47e+05 │ Loss:  1.44e+02\n",
      "Epoch  250 │ W_int (internal work): -1.79e+05 │ W_ext (external work):  5.61e+05 │ Loss:  1.86e+01\n",
      "Epoch  300 │ W_int (internal work): -2.62e+05 │ W_ext (external work):  3.61e+05 │ Loss:  1.30e+01\n",
      "Epoch  350 │ W_int (internal work):  1.37e+05 │ W_ext (external work): -3.85e+05 │ Loss:  9.60e+00\n",
      "Epoch  400 │ W_int (internal work): -4.59e+05 │ W_ext (external work):  2.55e+05 │ Loss:  1.76e+01\n",
      "Epoch  450 │ W_int (internal work): -4.24e+05 │ W_ext (external work):  1.45e+05 │ Loss:  1.13e+01\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    \n",
    "    optimizer.zero_grad()#reset gradients\n",
    "\n",
    "    loss = torch.zeros((), device=device)    # scalar, same dtype/device\n",
    "    #Estimate\n",
    "    for s in range(1,states):\n",
    "        V_NN   = model(invariants[:,:,s], centroids_tensor[:,:,s])     # → [125, 2, 30]\n",
    "        #print(f'V_NN shape: {V_NN.shape}')\n",
    "        \n",
    "        delta_xyz= calculate_point(centroids_tensor, s) #This is N,3\n",
    "        #print(f'delta_xyz shape: {delta_xyz.shape}')\n",
    "\n",
    "        VF_values = evaluate_vf_values_per_element(V_NN, delta_xyz) #This is [125, 2, 3]\n",
    "        #print(f'VF_values shape: {VF_values.shape}')\n",
    "\n",
    "        grad_VF= construct_vf_gradients_per_element(V_NN, delta_xyz) #This is [125, 2, 3, 3] \n",
    "        #print(f'grad_VF shape: {grad_VF.shape}')\n",
    "\n",
    "        #Strain\n",
    "        virtual_strain=0.5*(grad_VF+grad_VF.transpose(2,3))\n",
    "        #print(f'virtual_strain shape: {virtual_strain.shape}')\n",
    "\n",
    "        #Volume integral:\n",
    "        # element‐wise inner product σ^e : ∇v^e\n",
    "        integrand = torch.sum(stress_tensor_3d[:,:,:,s].unsqueeze(1) * virtual_strain, dim=(2, 3)) # → shape [p,N]\n",
    "        #print(f'Integrand shape: {integrand.shape}')\n",
    "    \n",
    "        W_int = torch.sum(integrand * volume_tensor[:,:,s] ,dim=(0,1)) #/(Nelements*vf_number) \n",
    "        #print(f'W_int shape: {W_int.shape}')\n",
    "\n",
    "        #Surface integral\n",
    "        #Adding negative to the pressure becuase it is applied downwards...\n",
    "        t_surface=-surface_normal_tensor[facet_idxs,:,s]*(pressure_curve[s]) #*area_tensor[facet_idxs,:,s] #t_surface is N_pressure,3 (elements x xyz), add area because pressure is not force\n",
    "        #print(f't_surface shape: {t_surface.shape}')\n",
    "   \n",
    "        dot = (VF_values[elem_idxs,:,:]* t_surface.unsqueeze(1)).sum(dim=2)  # shape: [3, 100]\n",
    "        #print(f'dot shape: {dot.shape}')\n",
    "\n",
    "        W_ext=torch.sum(dot*area_tensor[facet_idxs,:,s],dim=(0,1)) #/(N_pressure_dofs*vf_number)\n",
    "        #print(f'W_ext shape: {W_ext.shape}')\n",
    "\n",
    "        loss+=((W_int-W_ext)**2)*1e-10\n",
    "        \n",
    "    loss/=states\n",
    "    loss_list.append(loss.item())\n",
    "    work_dict['Internal'].append(W_int.item())\n",
    "    work_dict['External'].append(W_ext.item())\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        W_int_item = W_int.item()\n",
    "        W_ext_item = W_ext.item()\n",
    "        L_item    = loss.item()\n",
    "        print(f\"Epoch {i:4d} │ \"\n",
    "            f\"W_int (internal work): {W_int_item: .2e} │ \"\n",
    "            f\"W_ext (external work): {W_ext_item: .2e} │ \"\n",
    "            f\"Loss: {L_item: .2e}\")\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch1.layers.0.weight        grad 7.73e-11\n",
      "branch1.layers.0.bias          grad 5.55e-09\n",
      "branch1.layers.1.weights       grad 2.17e-10\n",
      "branch1.layers.2.weights       has no grad\n",
      "branch1.skip_layers.1.weight   grad 2.20e-12\n",
      "branch1.skip_layers.1.bias     grad 1.58e-10\n",
      "branch1.skip_layers.2.weights  has no grad\n",
      "branch2.layers.0.weight        grad 4.18e-09\n",
      "branch2.layers.0.bias          grad 5.58e-09\n",
      "branch2.layers.1.weights       grad 5.04e-10\n",
      "branch2.layers.2.weights       has no grad\n",
      "branch2.skip_layers.1.weight   grad 1.20e-10\n",
      "branch2.skip_layers.1.bias     grad 1.59e-10\n",
      "branch2.skip_layers.2.weights  has no grad\n",
      "trunk.0.weights                grad 1.48e-11\n",
      "trunk.2.weights                grad 2.86e-02\n",
      "heads.0.weight                 grad 7.19e-01\n",
      "heads.0.bias                   grad 4.63e-03\n",
      "heads.1.weight                 grad 6.94e-01\n",
      "heads.1.bias                   grad 4.63e-03\n"
     ]
    }
   ],
   "source": [
    "# after loss.backward()\n",
    "for name, p in model.named_parameters():\n",
    "    if p.grad is None:\n",
    "        print(f\"{name:30s} has no grad\")\n",
    "    else:\n",
    "        g = p.grad.data.norm().item()\n",
    "        if g==0.0:\n",
    "            print(f\"{name:30s} grad ZERO\")\n",
    "        else:\n",
    "            print(f\"{name:30s} grad {g:.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch1.layers.0.weight        | grad norm = 7.73e-11\n",
      "branch1.layers.0.bias          | grad norm = 5.55e-09\n",
      "branch1.layers.1.weights       | grad norm = 2.17e-10\n",
      "branch1.layers.2.weights       | grad is None\n",
      "branch1.skip_layers.1.weight   | grad norm = 2.20e-12\n",
      "branch1.skip_layers.1.bias     | grad norm = 1.58e-10\n",
      "branch1.skip_layers.2.weights  | grad is None\n",
      "branch2.layers.0.weight        | grad norm = 4.18e-09\n",
      "branch2.layers.0.bias          | grad norm = 5.58e-09\n",
      "branch2.layers.1.weights       | grad norm = 5.04e-10\n",
      "branch2.layers.2.weights       | grad is None\n",
      "branch2.skip_layers.1.weight   | grad norm = 1.20e-10\n",
      "branch2.skip_layers.1.bias     | grad norm = 1.59e-10\n",
      "branch2.skip_layers.2.weights  | grad is None\n",
      "trunk.0.weights                | grad norm = 1.48e-11\n",
      "trunk.2.weights                | grad norm = 2.86e-02\n",
      "heads.0.weight                 | grad norm = 7.19e-01\n",
      "heads.0.bias                   | grad norm = 4.63e-03\n",
      "heads.1.weight                 | grad norm = 6.94e-01\n",
      "heads.1.bias                   | grad norm = 4.63e-03\n"
     ]
    }
   ],
   "source": [
    "for name, p in model.named_parameters():\n",
    "    if not p.requires_grad:\n",
    "        continue\n",
    "    if p.grad is None:\n",
    "        print(f\"{name:30s} | grad is None\")\n",
    "    else:\n",
    "        print(f\"{name:30s} | grad norm = {p.grad.norm().item():.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vx(x,y,z) = -43.925*1 + +26.100*x + -22.722*y + -44.607*z + +38.609*x**2 + +62.025*x*y + -47.112*x*z + +13.485*y**2 + +23.662*y*z + -1.452*z**2\n",
      "Vy(x,y,z) = -9.182*1 + +61.109*x + -80.828*y + +83.875*z + -52.027*x**2 + -9.157*x*y + +128.540*x*z + -45.733*y**2 + +41.243*y*z + +12.651*z**2\n",
      "Vz(x,y,z) = -44.672*1 + -19.085*x + -17.819*y + +40.768*z + +64.958*x**2 + -42.549*x*y + -55.780*x*z + +19.247*y**2 + -16.363*y*z + -59.370*z**2\n"
     ]
    }
   ],
   "source": [
    "print_vf_equations(V_NN[:,0,:].mean(dim=0), fmt=\"{:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vx(x,y,z) = +3.808*1 + +50.808*x + -28.369*y + +13.109*z + +82.539*x**2 + +11.439*x*y + +42.528*x*z + -10.755*y**2 + +5.965*y*z + -10.061*z**2\n",
      "Vy(x,y,z) = -33.166*1 + -42.747*x + +7.495*y + +52.666*z + +94.517*x**2 + +1.738*x*y + +33.979*x*z + -25.949*y**2 + +9.170*y*z + -13.161*z**2\n",
      "Vz(x,y,z) = +6.753*1 + -21.892*x + -22.513*y + +4.790*z + -31.826*x**2 + +49.347*x*y + +16.915*x*z + -23.798*y**2 + +39.685*y*z + +20.426*z**2\n"
     ]
    }
   ],
   "source": [
    "print_vf_equations(V_NN[:,1,:].mean(dim=0), fmt=\"{:+.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VF heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0 │ W_int (internal work): -4.86e+03 │ W_ext (external work): -6.91e+03 │ Loss:  1.54e+07\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    optimizer.zero_grad()#reset gradients\n",
    "    loss = torch.zeros((), device=device)    # scalar, same dtype/device\n",
    "    #Estimate\n",
    "    for s in range(1,states):\n",
    "        V_NN=model(x_input[:,:,s]) #This is [125, 2, 30]\n",
    "        #print(f'V_NN shape: {V_NN.shape}')\n",
    "\n",
    "        delta_xyz=calculate_point(centroids_tensor, s) #This is N,3\n",
    "        #print(f'delta_xyz shape: {delta_xyz.shape}')\n",
    "\n",
    "        VF_values = evaluate_vf_values_per_element(V_NN, delta_xyz) #This is [125, 2, 3]\n",
    "        #print(f'VF_values shape: {VF_values.shape}')\n",
    "\n",
    "\n",
    "        grad_VF= construct_vf_gradients_per_element(V_NN, delta_xyz) #This is [125, 2, 3, 3] \n",
    "        #print(f'grad_VF shape: {grad_VF.shape}')\n",
    "\n",
    "\n",
    "        #Strain\n",
    "        virtual_strain=0.5*(grad_VF+grad_VF.transpose(2,3))\n",
    "        #print(f'virtual_strain shape: {virtual_strain.shape}')\n",
    "\n",
    "\n",
    "        #Volume integral:\n",
    "        # element‐wise inner product σ^e : ∇v^e\n",
    "        integrand = torch.sum(stress_tensor_3d[:,:,:,s].unsqueeze(1) * virtual_strain, dim=(2, 3)) # → shape [p,N]\n",
    "        #print(f'Integrand shape: {integrand.shape}')\n",
    "    \n",
    "        W_int = torch.sum(integrand * volume_tensor[:,:,s] ,dim=(0,1)) #/(Nelements*vf_number) \n",
    "        #print(f'W_int shape: {W_int.shape}')\n",
    "\n",
    "        #Surface integral\n",
    "        #Adding negative to the pressure becuase it is applied downwards...\n",
    "        t_surface=-surface_normal_tensor[facet_idxs,:,s]*(pressure_curve[s]) #*area_tensor[facet_idxs,:,s] #t_surface is N_pressure,3 (elements x xyz), add area because pressure is not force\n",
    "        #print(f't_surface shape: {t_surface.shape}')\n",
    "   \n",
    "        dot = (VF_values[elem_idxs,:,:]* t_surface.unsqueeze(1)).sum(dim=2)  # shape: [3, 100]\n",
    "        #print(f'dot shape: {dot.shape}')\n",
    "\n",
    "        W_ext=torch.sum(dot*area_tensor[facet_idxs,:,s],dim=(0,1)) #/(N_pressure_dofs*vf_number)\n",
    "        #print(f'W_ext shape: {W_ext.shape}')\n",
    "\n",
    "        loss+=((W_int-W_ext)**2)\n",
    "        \n",
    "    #loss/=states\n",
    "    loss_list.append(loss.item())\n",
    "    work_dict['Internal'].append(W_int.item())\n",
    "    work_dict['External'].append(W_ext.item())\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        W_int_item = W_int.item()\n",
    "        W_ext_item = W_ext.item()\n",
    "        L_item    = loss.item()\n",
    "        print(f\"Epoch {i:4d} │ \"\n",
    "            f\"W_int (internal work): {W_int_item: .2e} │ \"\n",
    "            f\"W_ext (external work): {W_ext_item: .2e} │ \"\n",
    "            f\"Loss: {L_item: .2e}\")\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([125, 2, 30])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_NN.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ORIG"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "epoch=750\n",
    "# Adam with a learning rate:\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "#Number of states:\n",
    "states=x_input.shape[2]\n",
    "N_pressure_dofs=len(pressure_element_IDs_final)\n",
    "N_ZD_dofs=len(ZD_element_IDs_final)\n",
    "loss_list=[]\n",
    "keys = ['Internal', 'External', 'ZD','Special']\n",
    "work_dict = { key: [] for key in keys }\n",
    "P_max  = 100000.0            # negative = compression\n",
    "# make a “linear ramp” of 11 pressures from 0 → P_max\n",
    "pressure_curve = torch.linspace(0.0, P_max, steps=states, device=device)\n",
    "# pressure_curve.shape == (11,)\n",
    "#new_lr = 1e-1\n",
    "#for pg in optimizer.param_groups:\n",
    "   # pg['lr'] = new_lr\n",
    "\n",
    "for i in range(epoch):\n",
    "    optimizer.zero_grad()#reset gradients\n",
    "    loss = torch.zeros((), device=device)    # scalar, same dtype/device\n",
    "    #Estimate\n",
    "    for s in range(1,states):\n",
    "        V_NN=model(x_input[:,:,s]) #This is numVF,30\n",
    "\n",
    "        delta_xyz=calculate_point(centroids_tensor, s) #This is N elements x3\n",
    "        #delta_xyz=\n",
    "        VF_values = evaluate_vf_values(V_NN, delta_xyz) #This is p, N, 3 \n",
    "        \n",
    "        grad_VF= construct_VF_gradients_batch(V_NN, delta_xyz) #This is p,N,3,3 . \n",
    "\n",
    "        #Strain\n",
    "        virtual_strain=0.5*(grad_VF+grad_VF.transpose(2,3))\n",
    "\n",
    "        #Volume integral:\n",
    "        \n",
    "        # element‐wise inner product σ^e : ∇v^e\n",
    "        integrand = torch.sum(stress_tensor_3d[:,:,:,s].unsqueeze(0) * virtual_strain, dim=(2, 3)) # → shape [p,N]\n",
    "       # print(f'Integrand shape: {integrand.shape}')\n",
    "        W_int = torch.sum(integrand * volume_tensor[:,0,s].unsqueeze(0) ,dim=(0,1)) #/(Nelements*vf_number)\n",
    "\n",
    "       # print(f'W_int shape: {W_int.shape}')\n",
    "        #Surface integral\n",
    "        #Adding negative to the pressure becuase it is applied downwards...\n",
    "        t_surface=-surface_normal_tensor[facet_idxs,:,s]*(pressure_curve[s]) #*area_tensor[facet_idxs,:,s] #t_surface is N_pressure,3 (elements x xyz), add area because pressure is not force\n",
    "     #   print(f'W_int shape: {W_int.shape}')\n",
    "\n",
    "        dot = (VF_values[:,elem_idxs,:]* t_surface.unsqueeze(0)).sum(dim=2)  # shape: [3, 100]\n",
    "\n",
    "        W_ext=torch.sum(dot*area_tensor[facet_idxs,:,s].T,dim=(0,1)) #/(N_pressure_dofs*vf_number)\n",
    "\n",
    "        ## Add ZD term:\n",
    "        #Elements\n",
    "        #ZD_regularization=torch.sum(VF_values[:,ZD_element_IDs_final,:]**2, dim=(0,1,2))/(N_ZD_dofs*vf_number)\n",
    "        #Nodes\n",
    "        #VF_values_NODES = evaluate_vf_values(V_NN, position_tensor[ZD_idx,:,s]) #This is p, N, 3 \n",
    "        #ZD_regularization=torch.sum(VF_values_NODES[:,ZD_idx,:]**2, dim=(0,1,2))/(len(ZD_idx)*vf_number)\n",
    "        #Facets\n",
    "        #ZD_regularization=torch.sum(VF_values[:,ZD_facet_idxs,:]**2, dim=(0,1,2))/(len(ZD_idx)*vf_number)\n",
    "\n",
    "\n",
    "        ## SPECIAL VIRTUAL FIELDS\n",
    "        # volumetric term:  ∑e  tr(Ereal)[e] * tr(Vvirt)[k,e] * vol_s[e]\n",
    "        A1 = torch.einsum('eii,kejj,e->ke',\n",
    "                        strain_tensor_3d[:,:,:,s],    # <-- must be first, shape [125,3,3]\n",
    "                        virtual_strain,      # <-- second, shape [2,125,3,3]\n",
    "                        volume_tensor[:,0,s])# <-- third, shape [125]\n",
    "       # A1.shape == [vf_number, Nelements] == [2,125]\n",
    "\n",
    "        # deviatoric (full inner‐product) term:\n",
    "        A2 = torch.einsum('eij,keij,e->ke',\n",
    "                        strain_tensor_3d[:,:,:,s],    # [125,3,3]\n",
    "                        virtual_strain,      # [2,125,3,3]|\n",
    "                        volume_tensor[:,0,s])# [125]\n",
    "\n",
    "\n",
    "        A = torch.stack([A1, A2], dim=1)       # → [2, n_vf, Ne]\n",
    "        #M = A.mean(dim=2)      \n",
    "        #M2= M / M.sum(dim=0, keepdim=True)                # → [2, n_vf]\n",
    "        diag = A[0,0] + A[1,1]          # shape [125]\n",
    "        scale = diag * 0.5              # shape [125]\n",
    "        scale = scale.clamp(min=1e-8)   # avoid div0\n",
    "        scale = scale.unsqueeze(0).unsqueeze(0)  # [1,1,125]\n",
    "\n",
    "        # normalized A\n",
    "        A_norm = A / scale              # [2,2,125]\n",
    "        I = torch.eye(2, device=A.device).unsqueeze(2)  \n",
    "\n",
    "        special_loss = torch.sum((A_norm-I) ** 2) #.sum(dim=(0,1))  # [125]\n",
    "        #special_loss = frobenius_per_matrix.mean()\n",
    "        \n",
    "        #special_loss = ((M / (M.sum(dim=0, keepdim=True) + 1e-8) #Norm \n",
    "                #  - torch.eye(vf_number, device=M.device, dtype=M.dtype))**2).sum()\n",
    "\n",
    "\n",
    "        # 1) build Gram matrix G_{kl} = ∫ ε*:ε* dV\n",
    "        G = torch.einsum(\n",
    "            'keij,leij,e->kl',\n",
    "            virtual_strain,    # [m,Ne,3,3]\n",
    "            virtual_strain,    # [m,Ne,3,3]\n",
    "            volume_tensor[:,0,s]  # [Ne]\n",
    "        )  # → [m,m]\n",
    "\n",
    "        # 2) special loss = ||G - I||^2\n",
    "        I_m = torch.eye(vf_number, device=G.device, dtype=G.dtype)\n",
    "        gram_loss = torch.norm(G - I_m)**2\n",
    "        #Loss:\n",
    "        loss+=(((W_int-W_ext)**2)*1e-3 +special_loss*0.01) #+ZD_regularization+special_loss +gram_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #loss/=states\n",
    "    loss_list.append(loss.item())\n",
    "    work_dict['Internal'].append(W_int.item())\n",
    "    work_dict['External'].append(W_ext.item())\n",
    "   # work_dict['ZD'].append(ZD_regularization.item())\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        W_int_item = W_int.item()\n",
    "        W_ext_item = W_ext.item()\n",
    "       # ZD_regularization_item= ZD_regularization.item()*10\n",
    "        special_loss_item= special_loss.item()\n",
    "        L_item    = loss.item()\n",
    "        print(\n",
    "            f\"Epoch {i:4d} │ \"\n",
    "            f\"W_int (internal work): {W_int_item: .2e} │ \"\n",
    "            f\"W_ext (external work): {W_ext_item: .2e} │ \"\n",
    "          #  f\"Zero Displacement term: {ZD_regularization_item: .2e} │ \"\n",
    "            f\"Special Loss term: {special_loss_item: .4e} │ \"\n",
    "           # f\"Gram Loss: {gram_loss.item(): .4e} │ \"\n",
    "            f\"Loss: {L_item: .2e}\"\n",
    "        )\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch1.0.weights 9343270.0\n",
      "branch1.2.weights 179741440.0\n",
      "branch2.0.weights 83003664.0\n",
      "branch2.2.weights 150401280.0\n",
      "trunk.0.weights 489544096.0\n",
      "trunk.2.weights 1223596160.0\n",
      "heads.0.0.weights 3230477056.0\n",
      "heads.0.1.weight 4377327104.0\n",
      "heads.0.1.bias 110864880.0\n",
      "heads.1.0.weights 2595565568.0\n",
      "heads.1.1.weight 4098146048.0\n",
      "heads.1.1.bias 110864880.0\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        print(name, param.grad.norm().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m M \u001b[38;5;241m=\u001b[39m \u001b[43mA\u001b[49m\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      2\u001b[0m M, A_norm\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'A' is not defined"
     ]
    }
   ],
   "source": [
    "M = A.mean(dim=2)\n",
    "M, A_norm.mean(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-1.9999, grad_fn=<MeanBackward0>),\n",
       " tensor(3.8750, dtype=torch.float32, grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.stack([A1, A2], dim=1)       # → [2, n_vf, Ne]\n",
    "M = A.mean(dim=2)      \n",
    "#M2= M / M.sum(dim=0, keepdim=True)                # → [2, n_vf]\n",
    "\n",
    "I = torch.eye(2, device=A.device).unsqueeze(2)  #2,2,1\n",
    "\n",
    "frobenius_per_matrix = (A-I ** 2).sum(dim=(0,1))  # [125]\n",
    "special_loss = frobenius_per_matrix.mean()\n",
    "\n",
    "special_loss1 = ((M / (M.sum(dim=0, keepdim=True) + 1e-8) #Norm \n",
    "                  - torch.eye(vf_number, device=M.device, dtype=M.dtype))**2).sum()\n",
    "special_loss, special_loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2, 125]), torch.Size([2, 2, 1]), torch.Size([2, 2, 125]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.stack([A1, A2], dim=1)       # → [2, n_vf, Ne]\n",
    "#M = A.mean(dim=2)      \n",
    "#M2= M / M.sum(dim=0, keepdim=True)                # → [2, n_vf]\n",
    "\n",
    "I = torch.eye(2, device=A.device).unsqueeze(2)  \n",
    "\n",
    "A.shape, I.shape, (A-I).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0052,  0.1668],\n",
       "        [-0.0052,  0.8332]], dtype=torch.float32, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M /M.sum(dim=0, keepdim=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 30 coefficients, got 60",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[132], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprint_vf_equations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mV_NN\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{:+.3f}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/EUCLID-hyperelasticity-NN/my_drivers/VF_helper.py:304\u001b[0m, in \u001b[0;36mprint_vf_equations\u001b[0;34m(V_NN, fmt)\u001b[0m\n\u001b[1;32m    302\u001b[0m     coeffs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(V_NN)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coeffs\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m30\u001b[39m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 30 coefficients, got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m coeffs\u001b[38;5;241m.\u001b[39msize)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# split into three 10‐length rows\u001b[39;00m\n\u001b[1;32m    307\u001b[0m comps \u001b[38;5;241m=\u001b[39m coeffs\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 30 coefficients, got 60"
     ]
    }
   ],
   "source": [
    "print_vf_equations(V_NN[0], fmt=\"{:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vx(x,y,z) = +0.062*1 + +0.074*x + +0.031*y + -0.049*z + -0.050*x**2 + +0.031*x*y + +0.066*x*z + -0.118*y**2 + -0.068*y*z + +0.112*z**2\n",
      "Vy(x,y,z) = +0.044*1 + +0.117*x + +0.159*y + -0.038*z + -0.097*x**2 + +0.069*x*y + +0.066*x*z + -0.143*y**2 + +0.136*y*z + -0.106*z**2\n",
      "Vz(x,y,z) = -0.018*1 + -0.006*x + -0.119*y + -0.103*z + +0.127*x**2 + +0.149*x*y + +0.075*x*z + +0.036*y**2 + +0.124*y*z + +0.067*z**2\n"
     ]
    }
   ],
   "source": [
    "print_vf_equations(V_NN[1], fmt=\"{:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# assume work_dict already exists, with lists of length N for each key\n",
    "epochs = list(range(1, len(work_dict['Internal']) + 1))\n",
    "# turn your lists into arrays\n",
    "internal = np.array(work_dict['Internal'])\n",
    "external = np.array(work_dict['External'])\n",
    "\n",
    "# now subtraction works element‐wise\n",
    "diff = internal - external\n",
    "plt.figure()\n",
    "plt.plot(epochs, work_dict['Internal'], label='Internal')\n",
    "plt.plot(epochs, work_dict['External'], label='External')\n",
    "plt.plot(epochs,diff, label='Internal-External')\n",
    "#plt.plot(epochs, work_dict['ZD'], label='ZD')\n",
    "#plt.plot(epochs, work_dict['Special'], label='Special')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Work & ZD Regularization vs. Epoch')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "time_idx=10\n",
    "\n",
    "V_NN=model(x_input[:,:,time_idx]) #This is N elements x12 , output is 30,1\n",
    "\n",
    "delta_xyz=calculate_point(centroids_tensor, time_idx) #This is N elements x3\n",
    "\n",
    "#Vx=construct_VF_gradients_batch(V_NN[0:10],delta_xyz)\n",
    "VF_values = evaluate_vf_values(V_NN, delta_xyz) #This is p, N, 3 (V_NN[10:20],delta_xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(vf_number):\n",
    "    tensor1 = VF_values[i,:,:].cpu()        # shape [1000,3]\n",
    "\n",
    "    name='multi_VF_'+str(i)+'.txt'\n",
    "    with open(name,'w') as f:\n",
    "        for i, (x, y, z) in enumerate(tensor1.tolist(), start=1):\n",
    "            f.write(f\"{i},{x},{y},{z}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (250x30 and 10x125)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m delta_xyz\u001b[38;5;241m=\u001b[39mcalculate_point(centroids_tensor, time_idx) \u001b[38;5;66;03m#This is N elements x3\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#Vx=construct_VF_gradients_batch(V_NN[0:10],delta_xyz)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m VF_values \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_vf_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mV_NN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta_xyz\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#This is p, N, 3 (V_NN[10:20],delta_xyz)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#Vz=construct_VF(V_NN[20:30],delta_xyz)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#VF=torch.cat((Vx.unsqueeze(1),Vy.unsqueeze(1),Vz.unsqueeze(1)), dim=1)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m grad_VF\u001b[38;5;241m=\u001b[39m construct_VF_gradients_batch(V_NN, delta_xyz)\n",
      "File \u001b[0;32m~/Desktop/EUCLID-hyperelasticity-NN/my_drivers/VF_helper.py:438\u001b[0m, in \u001b[0;36mevaluate_vf_values\u001b[0;34m(V_NN, delta_xyz)\u001b[0m\n\u001b[1;32m    430\u001b[0m B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\n\u001b[1;32m    431\u001b[0m     torch\u001b[38;5;241m.\u001b[39mones_like(x),\n\u001b[1;32m    432\u001b[0m     x, y, z,\n\u001b[1;32m    433\u001b[0m     x\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, y\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, z\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    434\u001b[0m     x\u001b[38;5;241m*\u001b[39my, x\u001b[38;5;241m*\u001b[39mz, y\u001b[38;5;241m*\u001b[39mz\n\u001b[1;32m    435\u001b[0m ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [N,10]\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;66;03m# Multiply coefficients by monomials: (p×10) @ (10×N) → (p×N)\u001b[39;00m\n\u001b[0;32m--> 438\u001b[0m Vx_vals \u001b[38;5;241m=\u001b[39m \u001b[43mVx_coeff\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\n\u001b[1;32m    439\u001b[0m Vy_vals \u001b[38;5;241m=\u001b[39m Vy_coeff \u001b[38;5;241m@\u001b[39m B\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    440\u001b[0m Vz_vals \u001b[38;5;241m=\u001b[39m Vz_coeff \u001b[38;5;241m@\u001b[39m B\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (250x30 and 10x125)"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "time_idx=10\n",
    "\n",
    "V_NN=model(x_input[:,:,time_idx]) #This is N elements x12 , output is 30,1\n",
    "\n",
    "delta_xyz=calculate_point(centroids_tensor, time_idx) #This is N elements x3\n",
    "\n",
    "#Vx=construct_VF_gradients_batch(V_NN[0:10],delta_xyz)\n",
    "VF_values = evaluate_vf_values(V_NN, delta_xyz) #This is p, N, 3 (V_NN[10:20],delta_xyz)\n",
    "#Vz=construct_VF(V_NN[20:30],delta_xyz)\n",
    "\n",
    "#VF=torch.cat((Vx.unsqueeze(1),Vy.unsqueeze(1),Vz.unsqueeze(1)), dim=1)\n",
    "grad_VF= construct_VF_gradients_batch(V_NN, delta_xyz)\n",
    "\n",
    "#Strain\n",
    "virtual_strain=0.5*(grad_VF+grad_VF.transpose(2,3)) #.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# volumetric term:  ∑e  tr(Ereal)[e] * tr(Vvirt)[k,e] * vol_s[e]\n",
    "A1 = torch.einsum('eii,kejj,e->ke',\n",
    "                strain_tensor_3d[:,:,:,time_idx],    # <-- must be first, shape [125,3,3]\n",
    "                virtual_strain,      # <-- second, shape [2,125,3,3]\n",
    "                volume_tensor[:,0,time_idx])# <-- third, shape [125]\n",
    "# A1.shape == [vf_number, Nelements] == [2,125]\n",
    "\n",
    "# deviatoric (full inner‐product) term:\n",
    "A2 = torch.einsum('eij,keij,e->ke',\n",
    "                strain_tensor_3d[:,:,:,time_idx],    # [125,3,3]\n",
    "                virtual_strain,      # [2,125,3,3]|\n",
    "                volume_tensor[:,0,time_idx])# [125]\n",
    "\n",
    "\n",
    "A = torch.stack([A1, A2], dim=1)       # → [2, n_vf, Ne]\n",
    "M = A.mean(dim=2) \n",
    "M_mean=M /M.sum(dim=0, keepdim=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4013, -0.1617],\n",
       "        [ 1.4013,  1.1617]], dtype=torch.float32, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M /M.sum(dim=0, keepdim=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding negative to the pressure becuase it is applied downwards...\n",
    "t_surface=surface_normal_tensor[facet_idxs,:,s]*(-100000)*area_tensor[facet_idxs,:,s] #t_surface is N_pressure,3 (elements x xyz), add area because pressure is not force\n",
    "#   print(f'W_int shape: {W_int.shape}')\n",
    "dot = (VF_values[:,elem_idxs,:]* t_surface.unsqueeze(0)).sum(dim=2)  # shape: [3, 100]\n",
    "\n",
    "W_ext=torch.sum(dot*area_tensor[facet_idxs,:,s].T,dim=(1))/(N_pressure_dofs*vf_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3887538.,  545551.], dtype=float32)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parameters\n",
    "torch.matmul(W_ext,torch.inverse(M)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0849,  1.8176],\n",
       "        [ 0.0108,  2.0849]], dtype=torch.float32, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_norm.mean(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-91054.984, 108899.5  ], dtype=float32)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns a namedtuple with .solution\n",
    "res = torch.linalg.lstsq(M, W_ext)\n",
    "x   = res.solution              # → shape (2,) or (2,1)\n",
    "x_np = x.detach().cpu().numpy()\n",
    "x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vx(x,y,z) = +0.163*1 + -0.071*x + -0.032*y + +0.035*z + -0.332*x**2 + -0.386*x*y + +0.108*x*z + -0.125*y**2 + +0.085*y*z + -0.077*z**2\n",
      "Vy(x,y,z) = +0.231*1 + -0.026*x + -0.036*y + -0.097*z + -0.120*x**2 + +0.000*x*y + +0.021*x*z + +0.029*y**2 + +0.037*y*z + -0.019*z**2\n",
      "Vz(x,y,z) = -0.060*1 + -0.002*x + +0.057*y + -0.116*z + +0.006*x**2 + -0.040*x*y + -0.021*x*z + +0.111*y**2 + -0.044*y*z + +0.031*z**2\n"
     ]
    }
   ],
   "source": [
    "print_vf_equations(V_NN[0], fmt=\"{:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vx(x,y,z) = +0.267*1 + +0.043*x + -0.150*y + -0.051*z + -0.275*x**2 + -0.238*x*y + +0.162*x*z + +0.014*y**2 + +0.073*y*z + -0.021*z**2\n",
      "Vy(x,y,z) = +0.456*1 + -0.033*x + +0.073*y + -0.084*z + -0.056*x**2 + +0.019*x*y + +0.045*x*z + -0.004*y**2 + +0.060*y*z + +0.099*z**2\n",
      "Vz(x,y,z) = -0.066*1 + -0.072*x + +0.010*y + -0.014*z + -0.019*x**2 + +0.011*x*y + -0.039*x*z + -0.080*y**2 + -0.117*y*z + +0.031*z**2\n"
     ]
    }
   ],
   "source": [
    "print_vf_equations(V_NN[1], fmt=\"{:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When VFs are per element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "time_idx=10\n",
    "\n",
    "V_NN=model(x_input[:,:,time_idx]) #This is N elements x12 , output is 30,1\n",
    "\n",
    "delta_xyz=calculate_point(centroids_tensor, time_idx) #This is N elements x3\n",
    "\n",
    "#Vx=construct_VF_gradients_batch(V_NN[0:10],delta_xyz)\n",
    "VF_values = evaluate_vf_values_per_element(V_NN, delta_xyz) #This is p, N, 3 (V_NN[10:20],delta_xyz)\n",
    "#Vz=construct_VF(V_NN[20:30],delta_xyz)\n",
    "\n",
    "#VF=torch.cat((Vx.unsqueeze(1),Vy.unsqueeze(1),Vz.unsqueeze(1)), dim=1)\n",
    "grad_VF= construct_vf_gradients_per_element(V_NN, delta_xyz)\n",
    "\n",
    "#Strain\n",
    "virtual_strain=0.5*(grad_VF+grad_VF.transpose(2,3)) #.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([125, 2, 3]),\n",
       " torch.Size([125, 2, 3, 3]),\n",
       " torch.Size([2, 125, 3, 3]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VF_values.shape, virtual_strain.shape, virtual_strain.transpose(0,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_ext shape: torch.Size([25, 2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Surface integral\n",
    "#But what if we do it in all the cube... IDT we can because febio only gives normals from surfaces...\n",
    "\n",
    "\n",
    "#Adding negative to the pressure becuase it is applied downwards...\n",
    "t_surface=-surface_normal_tensor[facet_idxs,:,s]*(pressure_curve[s]) # shape: [25, 3] #*area_tensor[facet_idxs,:,s] #t_surface is N_pressure,3 (elements x xyz), add area because pressure is not force\n",
    "#print(f't_surface shape: {t_surface.shape}')\n",
    "\n",
    "dot = (VF_values[elem_idxs,:,:]* t_surface.unsqueeze(1)).sum(dim=2)  #shape: [25,2,3]@ [25,1,3] = shape: [25, 2]. Broadcast along 2nd dim (1st dim in t index)\n",
    "#print(f'dot shape: {dot.shape}')\n",
    "\n",
    "W_ext=dot*area_tensor[facet_idxs,:,time_idx]  #shape: [25,2]@ [25,1] = shape: [25, 2]\n",
    "print(f'W_ext shape: {W_ext.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([25, 2, 3]),\n",
       " torch.Size([25, 3]),\n",
       " torch.Size([25, 1, 3]),\n",
       " torch.Size([25, 2, 3]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VF_values[elem_idxs,:,:].shape, t_surface.shape, t_surface.unsqueeze(1).shape, (VF_values[elem_idxs,:,:]*t_surface.unsqueeze(1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_ext_all = torch.zeros(Nelements, 2, device=device, dtype=torch.float32) # assign\n",
    "W_ext_all[elem_idxs,:] = W_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# volumetric term:  ∑e  tr(Ereal)[e] * tr(Vvirt)[k,e] * vol_s[e]\n",
    "A1 = torch.einsum('eii,kejj,e->ke',\n",
    "                strain_tensor_3d[:,:,:,time_idx],    # <-- must be first, shape [125,3,3]\n",
    "                virtual_strain.transpose(0,1),      # <-- second, shape [2,125,3,3]\n",
    "                volume_tensor[:,0,time_idx])# <-- third, shape [125]\n",
    "# A1.shape == [vf_number, Nelements] == [2,125]\n",
    "\n",
    "# deviatoric (full inner‐product) term:\n",
    "A2 = torch.einsum('eij,keij,e->ke',\n",
    "                strain_tensor_3d[:,:,:,time_idx],    # [125,3,3]\n",
    "                virtual_strain.transpose(0,1),      # [2,125,3,3]|\n",
    "                volume_tensor[:,0,time_idx])# [125]\n",
    "\n",
    "\n",
    "A = torch.stack([A1[:,elem_idxs], A2[:,elem_idxs]], dim=1)       # → [2, n_vf, Ne]\n",
    "M = A.mean(dim=2) \n",
    "M_mean=M /M.sum(dim=0, keepdim=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 125]),\n",
       " torch.Size([2, 125]),\n",
       " torch.Size([2, 2, 25]),\n",
       " torch.Size([125, 2]),\n",
       " torch.Size([2, 2, 25]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1.shape, A2.shape, A.shape, W_ext_all.shape, A.transpose(0,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.8410e+09, -7.9470e+08], dtype=torch.float32,\n",
       "        grad_fn=<MeanBackward1>),\n",
       " torch.Size([25, 2]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params=torch.matmul(W_ext,torch.inverse(M)) #.detach().cpu().numpy()\n",
    "params.mean(dim=0), params.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using all elements..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.stack([A1, A2], dim=1)       # → [2, n_vf, Ne]\n",
    "\n",
    "# 1) Turn it into (125, 2, 2) by swapping dims\n",
    "M_batched = A.permute(2, 0, 1)        # → (125, 2, 2)\n",
    "\n",
    "# 2) Invert each 2×2 in one go\n",
    "#   — you can use torch.inverse or torch.linalg.inv interchangeably here\n",
    "M_inv_batched = torch.inverse(M_batched)  # works, double checked\n",
    "# (or: M_inv_batched = torch.linalg.inv(M_batched))\n",
    "\n",
    "# 3) Turn your W_ext into a column‐vector per batch\n",
    "W_col   = W_ext_all.unsqueeze(1)      # → (125,1,2)\n",
    "\n",
    "# 4) Batch‐matrix multiply: (1×2) @ (2×2) → (1×2), per batch\n",
    "params  = torch.bmm(W_col, M_inv_batched)  # → (125,1,2)\n",
    "\n",
    "# 5) Squeeze off the middle dim to get (125,2)\n",
    "params  = params.squeeze(1)        # → (125,2)\n",
    "\n",
    "# 6) If you only need NumPy:\n",
    "params_np = params.detach().cpu().numpy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank(M) = 2/2,  cond(M) = 9.34e+00\n"
     ]
    }
   ],
   "source": [
    "# Assemble M  (n_VF × n_param) for one element or block\n",
    "#   M[k,m] = ∫_Ω   ε_v^(k) : ε_m   dV               (example isotropic case)\n",
    "rank   = torch.linalg.matrix_rank(M_batched[0])\n",
    "cond   = torch.linalg.cond(M_batched[0])\n",
    "\n",
    "print(f\"rank(M) = {rank}/{M.shape[1]},  cond(M) = {cond:.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.], dtype=torch.float32, grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(W_ext_all[0],M_inv_batched[0]) #.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-172094.5781, -163205.7812],\n",
       "         [  78378.8672,   35196.0664]], dtype=torch.float32,\n",
       "        grad_fn=<SelectBackward0>),\n",
       " tensor([0., 0.], dtype=torch.float32, grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_inv_batched[0], W_ext_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 4.87728064e+08,  2.14596944e+08],\n",
       "       [ 1.89391053e+09,  7.95954880e+08],\n",
       "       [-9.06048192e+08, -3.55759520e+08],\n",
       "       [-3.56782464e+08, -1.29576440e+08],\n",
       "       [-2.22682896e+08, -7.65126160e+07],\n",
       "       [ 4.43467616e+08,  2.04196144e+08],\n",
       "       [ 1.34932762e+09,  5.90419584e+08],\n",
       "       [-1.17893171e+09, -4.81867776e+08],\n",
       "       [-3.93769824e+08, -1.48150944e+08],\n",
       "       [-2.33561840e+08, -8.11347360e+07],\n",
       "       [ 3.83562336e+08,  1.86286960e+08],\n",
       "       [ 9.07874048e+08,  4.20257184e+08],\n",
       "       [-2.03300160e+09, -8.79598080e+08],\n",
       "       [-4.57136864e+08, -1.81937344e+08],\n",
       "       [-2.50853744e+08, -9.14268640e+07],\n",
       "       [ 3.22452640e+08,  1.66922864e+08],\n",
       "       [ 6.36973568e+08,  3.14714176e+08],\n",
       "       [-1.90555505e+10, -8.80888422e+09],\n",
       "       [-5.60059456e+08, -2.38150592e+08],\n",
       "       [-2.78932256e+08, -1.08773304e+08],\n",
       "       [ 2.72265632e+08,  1.49121392e+08],\n",
       "       [ 4.90367616e+08,  2.56841168e+08],\n",
       "       [ 2.46176230e+09,  1.21413286e+09],\n",
       "       [-6.93416064e+08, -3.13137792e+08],\n",
       "       [-2.92233632e+08, -1.19853784e+08]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_np"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NNEUCLID",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
