{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post process script with visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------\n",
      "Setting device to:  0\n",
      "Test:  cuda:0\n",
      "-----------------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------------\n",
      "Setting device to:  0\n",
      "Test:  cuda:0\n",
      "-----------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/feolalab/anaconda3/envs/NNEUCLID/lib/python3.9/site-packages/torch/__init__.py:1144: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647380992/work/torch/csrc/tensor/python_tensor.cpp:432.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import matplotlib\n",
    "sys.path.insert(0, '../')\n",
    "from core import *\n",
    "#config\n",
    "from config import *\n",
    "#CUDA\n",
    "initCUDA(cuda)\n",
    "#supporting files\n",
    "from model import *\n",
    "from helper import *\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "matplotlib.pyplot.rcParams['font.family'] = 'serif'\n",
    "matplotlib.pyplot.rcParams['mathtext.fontset'] = 'dejavuserif'\n",
    "\n",
    "from post_process import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fem_material='Isihara'\n",
    "noise_level='low'\n",
    "output_dir='/home/feolalab/Downloads/VFM_compare/normal/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build architecture from config\n",
    "model = ICNN(n_input=n_input,\n",
    "                 n_hidden=n_hidden,\n",
    "                 n_output=n_output,\n",
    "                 use_dropout=use_dropout,\n",
    "                 dropout_rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/feolalab/Downloads/VFM_compare/normal//Isihara/loss_history_noise=low_ID=0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m final_losses \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((ensemble_size,\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ensemble_iter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ensemble_size):\n\u001b[0;32m----> 4\u001b[0m     final_losses[ensemble_iter] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mfem_material\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/loss_history_noise=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mnoise_level\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_ID=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mensemble_iter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      6\u001b[0m final_losses_ratio \u001b[38;5;241m=\u001b[39m final_losses \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mmin(final_losses)\n\u001b[1;32m      7\u001b[0m num_models_remove \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(final_losses_ratio \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m accept_ratio)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/NNEUCLID/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/NNEUCLID/lib/python3.9/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/NNEUCLID/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/NNEUCLID/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/NNEUCLID/lib/python3.9/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/feolalab/Downloads/VFM_compare/normal//Isihara/loss_history_noise=low_ID=0.csv'"
     ]
    }
   ],
   "source": [
    "#Evaluation based on losses \n",
    "final_losses = torch.zeros((ensemble_size,1))\n",
    "for ensemble_iter in range(ensemble_size):\n",
    "    final_losses[ensemble_iter] = pd.read_csv(output_dir+'/'+fem_material+'/loss_history_noise='+noise_level+'_ID='+str(ensemble_iter)+'.csv', header=None).values[-1][1]\n",
    "\n",
    "final_losses_ratio = final_losses / torch.min(final_losses)\n",
    "num_models_remove = torch.where(final_losses_ratio >= accept_ratio)[0].shape[0]\n",
    "num_models_keep = ensemble_size - num_models_remove\n",
    "\n",
    "idx_best_models = torch.topk(-final_losses.flatten(),num_models_keep).indices\n",
    "idx_worst_models = torch.topk(final_losses.flatten(),num_models_remove).indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.3287],\n",
       "         [ 0.4879],\n",
       "         [58.5678],\n",
       "         [ 0.2588],\n",
       "         [ 0.1904],\n",
       "         [ 0.1996],\n",
       "         [ 0.2036],\n",
       "         [ 0.1570],\n",
       "         [ 0.1787],\n",
       "         [ 0.2081],\n",
       "         [ 0.1481],\n",
       "         [ 0.1808],\n",
       "         [ 0.1889],\n",
       "         [ 0.1551],\n",
       "         [ 0.1637]]),\n",
       " tensor(4.5745),\n",
       " tensor(15.0491))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_losses, final_losses.mean(), final_losses.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the true models\n",
    "for path_count, strain_path in enumerate(strain_paths):\n",
    "\t\t\tif strain_path == 'UT':\n",
    "\t\t\t\tP_idx = 0\n",
    "\t\t\telif strain_path == 'SS':\n",
    "\t\t\t\tP_idx = 1\n",
    "\t\t\telif strain_path == 'PS':\n",
    "\t\t\t\tP_idx = 3\n",
    "\t\t\telif strain_path == 'UC':\n",
    "\t\t\t\tP_idx = 0\n",
    "\t\t\telif strain_path == 'BT':\n",
    "\t\t\t\tP_idx = 0\n",
    "\t\t\telif strain_path == 'BC':\n",
    "\t\t\t\tP_idx = 0\n",
    "\n",
    "gamma=np.linspace(g_min,g_max,gamma_steps)\n",
    "F, xlabel = getStrainPathDeformationGradient(strain_path, gamma_steps, gamma)\n",
    "\n",
    "# Get components of F\n",
    "F11 = F[:,0:1]\n",
    "F12 = F[:,1:2]\n",
    "F21 = F[:,2:3]\n",
    "F22 = F[:,3:4]\n",
    "\n",
    "F11.requires_grad = True\n",
    "F12.requires_grad = True\n",
    "F21.requires_grad = True\n",
    "F22.requires_grad = True\n",
    "\n",
    "#computing detF\n",
    "J = computeJacobian(torch.cat((F11,F12,F21,F22),dim=1))\n",
    "\n",
    "#computing Cauchy-Green strain: C = F^T F\n",
    "C = computeCauchyGreenStrain(torch.cat((F11,F12,F21,F22),dim=1))\n",
    "\n",
    "#computing strain invariants\n",
    "I1, I2, I3 = computeStrainInvariants(C)\n",
    "\n",
    "#Get true model of fem_material\n",
    "W_truth = get_true_W(fem_material,J,C,I1,I2,I3)\n",
    "\n",
    "dW_truth_dF11 = torch.autograd.grad(W_truth,F11,torch.ones(F11.shape[0],1),create_graph=True)[0]\n",
    "dW_truth_dF12 = torch.autograd.grad(W_truth,F12,torch.ones(F12.shape[0],1),create_graph=True)[0]\n",
    "dW_truth_dF21 = torch.autograd.grad(W_truth,F21,torch.ones(F21.shape[0],1),create_graph=True)[0]\n",
    "dW_truth_dF22 = torch.autograd.grad(W_truth,F22,torch.ones(F22.shape[0],1),create_graph=True)[0]\n",
    "\n",
    "P_truth = torch.cat((dW_truth_dF11,dW_truth_dF12,dW_truth_dF21,dW_truth_dF22),dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load models for inference:\n",
    "W_predictions = torch.zeros((gamma_steps,ensemble_size))\n",
    "P_predictions = torch.zeros((gamma_steps,4,ensemble_size))\n",
    "\n",
    "for ensemble_iter in range(ensemble_size):\n",
    "    model.load_state_dict(torch.load(output_dir+'/'+fem_material+'/noise='+noise_level+'_ID='+str(ensemble_iter)+'.pth'))\n",
    "\n",
    "\n",
    "    W_predictions[:,ensemble_iter:ensemble_iter+1], P_predictions[:,:,ensemble_iter:ensemble_iter+1] = compute_corrected_W(F)\n",
    "\n",
    "P_accepted = P_predictions[:,:,idx_best_models]\n",
    "P_rejected = P_predictions[:,:,idx_worst_models]\n",
    "\n",
    "W_accepted = W_predictions[:,idx_best_models]\n",
    "W_rejected = W_predictions[:,idx_worst_models]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aux functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_true_W(fem_material,J,C,I1,I2,I3):\n",
    "    \"\"\"\n",
    "\n",
    "    Analytical description of benchmark hyperelastic material models.\n",
    "    Input:\t\tStrain invariants and Cauchy-Green deformation matrix.\n",
    "    Output:\t\tStrain energy density of the specified material\n",
    "\n",
    "    \"\"\"\n",
    "    if fem_material == 'NeoHookean':\n",
    "        I1_tilde = J**(-2/3)*I1\n",
    "        W_truth = 0.5000*(I1_tilde - 3) + 1.5000*(J - 1)**2\n",
    "    elif fem_material == 'Anisotropy45':\n",
    "        I1_tilde = J**(-2/3)*I1\n",
    "        alpha = torch.tensor([np.pi/4])\n",
    "        C11 = C[:,0:1]\n",
    "        C12 = C[:,1:2]\n",
    "        C21 = C[:,2:3]\n",
    "        C22 = C[:,3:4]\n",
    "        Ia = torch.cos(alpha)*(C11*torch.cos(alpha)+C12*torch.sin(alpha)) + torch.sin(alpha)*(C21*torch.cos(alpha)+C22*torch.sin(alpha))\n",
    "        Ia_tilde = Ia * J**(-2/3)\n",
    "        W_truth = 0.5*(I1_tilde - 3.) + 0.75*(J - 1.)**2 + 0.5*(Ia_tilde - 1.)**2\n",
    "    elif fem_material == 'Anisotropy60':\n",
    "        I1_tilde = J**(-2/3)*I1\n",
    "        alpha = torch.tensor([np.pi/3])\n",
    "        C11 = C[:,0:1]\n",
    "        C12 = C[:,1:2]\n",
    "        C21 = C[:,2:3]\n",
    "        C22 = C[:,3:4]\n",
    "        Ia = torch.cos(alpha)*(C11*torch.cos(alpha)+C12*torch.sin(alpha)) + torch.sin(alpha)*(C21*torch.cos(alpha)+C22*torch.sin(alpha))\n",
    "        Ia_tilde = Ia * J**(-2/3)\n",
    "        W_truth = 0.5*(I1_tilde - 3.) + 0.75*(J - 1.)**2 + 0.5*(Ia_tilde - 1.)**2\n",
    "    elif fem_material == 'Isihara':\n",
    "        I1_tilde = J**(-2/3)*I1\n",
    "        I2_tilde = J**(-4/3)*I2\n",
    "        W_truth = 0.5000*(I1_tilde - 3) + 1.0000*(I2_tilde - 3) + 1.0000*(I1_tilde - 3)**2 + 1.5000*(J - 1)**2\n",
    "    elif fem_material == 'HainesWilson':\n",
    "        I1_tilde = J**(-2/3)*I1\n",
    "        I2_tilde = J**(-4/3)*I2\n",
    "        W_truth = 0.5000*(I1_tilde - 3) + 1.0000*(I2_tilde - 3) + 0.7000*(I1_tilde - 3)*(I2_tilde - 3) + 0.2000*(I1_tilde - 3)**3 + 1.5000*(J - 1)**2\n",
    "    elif fem_material == 'GentThomas':\n",
    "        I1_tilde = J**(-2/3)*I1\n",
    "        I2_tilde = J**(-4/3)*I2\n",
    "        W_truth = 0.5000*(I1_tilde - 3) + 1.5000*(J - 1)**2 + 1.0000*torch.log(I2_tilde/3)\n",
    "    elif fem_material == 'ArrudaBoyce':\n",
    "        shear_modulus = 2.5\n",
    "        chain_length = 28\n",
    "        kappa = 1.5\n",
    "        shearModulus = torch.tensor([shear_modulus])\n",
    "        N = torch.tensor([chain_length])\n",
    "        sqrt_N = torch.sqrt(N)\n",
    "        W_truth = torch.zeros((gamma_steps,1))\n",
    "        I1_tilde = J**(-2/3)*I1\n",
    "        lambda_chain = 1\n",
    "        x = lambda_chain / torch.sqrt(N)\n",
    "        beta_chain = 0.0\n",
    "        if torch.abs(x)<0.841:\n",
    "            beta_chain = 1.31*torch.tan(1.59*x)+0.91*x\n",
    "        else:\n",
    "            beta_chain = 1./((x+0.00000001/(torch.abs(x)+0.00000001))-x)\n",
    "        W_truth_offset = shearModulus * sqrt_N * (beta_chain*lambda_chain+sqrt_N*torch.log(beta_chain/torch.sinh(beta_chain)))\n",
    "        for step in range(gamma_steps):\n",
    "            lambda_chain = torch.sqrt(I1_tilde[step:step+1]/3.)\n",
    "            x = lambda_chain / torch.sqrt(N)\n",
    "            beta_chain = 0.0\n",
    "            if torch.abs(x)<0.841:\n",
    "                beta_chain = 1.31*torch.tan(1.59*x)+0.91*x\n",
    "            else:\n",
    "                beta_chain = 1./((x+0.00000001/(torch.abs(x)+0.00000001))-x)\n",
    "            #% Final output\n",
    "            W_truth[step:step+1,:] = shearModulus * sqrt_N * (beta_chain*lambda_chain+sqrt_N*torch.log(beta_chain/torch.sinh(beta_chain))) - W_truth_offset + kappa*(J[step:step+1]-1)**2\n",
    "\n",
    "    elif fem_material == 'Ogden':\n",
    "        kappa_ogden = 1.5\n",
    "        mu_ogden = 0.65\n",
    "        alpha_ogden = 0.65\n",
    "        I1_tilde = J**(-2/3)*I1 + 1e-13\n",
    "        I1t_0 =torch.tensor([3]) + 1e-13\n",
    "        J_0 = torch.tensor([1]) + 1e-13\n",
    "        W_offset = kappa_ogden*(J_0-1)**2 + 1/alpha_ogden * 2. * (0.5**alpha_ogden*(I1t_0  +  torch.sqrt(  (I1t_0-1/(J_0**(2./3.)))**2 - 4*J_0**(2./3.)) - 1/(J_0**(2./3.)) )**alpha_ogden+( 0.5*I1t_0 - 0.5*torch.sqrt(  (I1t_0-1/(J_0**(2./3.)))**2 - 4*J_0**(2./3.))  - 0.5/(J_0**(2./3.)) )**alpha_ogden + J_0**(-alpha_ogden*2./3.) ) * mu_ogden\n",
    "        #% Final output\n",
    "        W_truth = kappa_ogden*(J-1)**2 + 1/alpha_ogden * 2. * (0.5**alpha_ogden*(I1_tilde  +  torch.sqrt(  (I1_tilde-1/(J**(2./3.)))**2 - 4*J**(2./3.)) - 1/(J**(2./3.)) )**alpha_ogden+( 0.5*I1_tilde - 0.5*torch.sqrt(  (I1_tilde-1/(J**(2./3.)))**2 - 4*J**(2./3.))  - 0.5/(J**(2./3.)) )**alpha_ogden + J**(-alpha_ogden*2./3.) ) * mu_ogden - W_offset\n",
    "\n",
    "    elif fem_material == 'Holzapfel':\n",
    "        I1_tilde = J**(-2/3)*I1\n",
    "        alpha = torch.tensor([np.pi/6])\n",
    "        beta = -1.*alpha\n",
    "        C11 = C[:,0:1]\n",
    "        C12 = C[:,1:2]\n",
    "        C21 = C[:,2:3]\n",
    "        C22 = C[:,3:4]\n",
    "        Ia = torch.cos(alpha)*(C11*torch.cos(alpha)+C12*torch.sin(alpha)) + torch.sin(alpha)*(C21*torch.cos(alpha)+C22*torch.sin(alpha))\n",
    "        Ib = torch.cos(beta)*(C11*torch.cos(beta)+C12*torch.sin(beta)) + torch.sin(beta)*(C21*torch.cos(beta)+C22*torch.sin(beta))\n",
    "        Ia_tilde = Ia * J**(-2/3)\n",
    "        Ib_tilde = Ib * J**(-2/3)\n",
    "        k1h = 0.9\n",
    "        k2h = 0.8\n",
    "        HAa = k1h/2./k2h*(torch.exp(k2h*torch.pow(Ia_tilde - 1.,2.))-1.)\n",
    "        HAb = k1h/2./k2h*(torch.exp(k2h*torch.pow(Ib_tilde - 1.,2.))-1.)\n",
    "        #% Final output\n",
    "        W_truth = 0.5*(I1_tilde-3) + 1.0*(J-1)**2 + HAa + HAb\n",
    "\n",
    "    return W_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_corrected_W(F):\n",
    "    \"\"\"\n",
    "    Compute the strain energy density according to Ansatz (Eq. 8).\n",
    "\n",
    "    Input: \t\tDeformation gradient F in form (F11,F12,F21,F22)\n",
    "    Output: \tStrain energy density according to Ansatz (Eq. 8)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    F_0 = torch.zeros((1,4))\n",
    "    F_0[:,0] = 1\n",
    "    F_0[:,3] = 1\n",
    "\n",
    "    F11_0 = F_0[:,0:1]\n",
    "    F12_0 = F_0[:,1:2]\n",
    "    F21_0 = F_0[:,2:3]\n",
    "    F22_0 = F_0[:,3:4]\n",
    "\n",
    "    F11_0.requires_grad = True\n",
    "    F12_0.requires_grad = True\n",
    "    F21_0.requires_grad = True\n",
    "    F22_0.requires_grad = True\n",
    "\n",
    "    # Get components of F\n",
    "    F11 = F[:,0:1]\n",
    "    F12 = F[:,1:2]\n",
    "    F21 = F[:,2:3]\n",
    "    F22 = F[:,3:4]\n",
    "\n",
    "    F11.requires_grad = True\n",
    "    F12.requires_grad = True\n",
    "    F21.requires_grad = True\n",
    "    F22.requires_grad = True\n",
    "\n",
    "    W_NN = model(torch.cat((F11,F12,F21,F22),dim=1))\n",
    "\n",
    "    dW_NN_dF11 = torch.autograd.grad(W_NN,F11,torch.ones(F11.shape[0],1),create_graph=True)[0]\n",
    "    dW_NN_dF12 = torch.autograd.grad(W_NN,F12,torch.ones(F12.shape[0],1),create_graph=True)[0]\n",
    "    dW_NN_dF21 = torch.autograd.grad(W_NN,F21,torch.ones(F21.shape[0],1),create_graph=True)[0]\n",
    "    dW_NN_dF22 = torch.autograd.grad(W_NN,F22,torch.ones(F22.shape[0],1),create_graph=True)[0]\n",
    "\n",
    "    P_NN = torch.cat((dW_NN_dF11,dW_NN_dF12,dW_NN_dF21,dW_NN_dF22),dim=1)\n",
    "\n",
    "    # Derivative of volumetric term\n",
    "    J_F_inv_T = torch.cat((F22,-F21,-F12,F11),1)\n",
    "    C = computeCauchyGreenStrain(torch.cat((F11,F12,F21,F22),dim=1))\n",
    "    _,_,I3 = computeStrainInvariants(C)\n",
    "\n",
    "    # Zero deformation input data\n",
    "    W_NN_0 = model(torch.cat((F11_0,F12_0,F21_0,F22_0),dim=1))\n",
    "\n",
    "    dW_NN_dF11_0 = torch.autograd.grad(W_NN_0,F11_0,torch.ones(F11_0.shape[0],1),create_graph=True)[0]\n",
    "    dW_NN_dF12_0 = torch.autograd.grad(W_NN_0,F12_0,torch.ones(F12_0.shape[0],1),create_graph=True)[0]\n",
    "    dW_NN_dF21_0 = torch.autograd.grad(W_NN_0,F21_0,torch.ones(F21_0.shape[0],1),create_graph=True)[0]\n",
    "    dW_NN_dF22_0 = torch.autograd.grad(W_NN_0,F22_0,torch.ones(F22_0.shape[0],1),create_graph=True)[0]\n",
    "\n",
    "    P_NN_0 = torch.cat((dW_NN_dF11_0,dW_NN_dF12_0,dW_NN_dF21_0,dW_NN_dF22_0),dim=1)\n",
    "\n",
    "    P_cor = torch.zeros_like(P_NN)\n",
    "\n",
    "    P_cor[:,0:1] = F11*-P_NN_0[:,0:1] + F12*-P_NN_0[:,2:3]\n",
    "    P_cor[:,1:2] = F11*-P_NN_0[:,1:2] + F12*-P_NN_0[:,3:4]\n",
    "    P_cor[:,2:3] = F21*-P_NN_0[:,0:1] + F22*-P_NN_0[:,2:3]\n",
    "    P_cor[:,3:4] = F21*-P_NN_0[:,1:2] + F22*-P_NN_0[:,3:4]\n",
    "\n",
    "    P = P_NN + P_cor\n",
    "    E = torch.zeros_like(F)\n",
    "\n",
    "    E[:,0:1] = 0.5*(C[:,0:1]-1.)\n",
    "    E[:,1:2] = 0.5*(C[:,1:2])\n",
    "    E[:,2:3] = 0.5*(C[:,2:3])\n",
    "    E[:,3:4] = 0.5*(C[:,3:4]-1.)\n",
    "\n",
    "    W_cor = torch.sum(-P_NN_0*E, 1, keepdim=True)\n",
    "\n",
    "    # The actual offset of the NN output is W_NN_0 (NN ouput at F=I) and H:E\n",
    "    W_offset = W_NN_0\n",
    "    # W is sum of NN output, the volumetric correction term and subtracting NN output at F=I and H:E\n",
    "    W = W_NN + W_cor - W_offset\n",
    "\n",
    "    P = P.view(-1,4,1)\n",
    "\n",
    "    return W, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NNEUCLID",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
